{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3156a16",
   "metadata": {},
   "source": [
    "## Introduction to Text Mining and NLP: Term Paper\n",
    "\n",
    "---------------------------\n",
    "Ramón Talvi\n",
    "\n",
    "David Vallmanya\n",
    "\n",
    "Irene Villalonga\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc928607",
   "metadata": {},
   "source": [
    "In this term paper we will use Reddit's API to extract a huge number of users opinions in response to the prompt \"Donald Trump has not made a single lasting positive impact on the USA during his term as president\", which is included in a very popular reddit community called \"Change my views\". \n",
    "\n",
    "The project aims to analyze how the public, as represented by Reddit comments, perceive the performance of Trump's presidency in various political areas such as the economy, foreign affairs, COVID, gender, etc. The goal is to propose a logistic model that measures the relationship between a given political topic (for instance, gender) and the overall sentiment of the public on that specific topic: the idea is to measure Trump's perceived presidency performance on different political areas (topics). The model would use the topics as a covariates and the overall sentiment as the dependent variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d0387",
   "metadata": {},
   "source": [
    "### 1) WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2e828890",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseException",
     "evalue": "received 401 HTTP response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m submission \u001b[39m=\u001b[39m reddit\u001b[39m.\u001b[39msubmission(\u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39miq41dt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m submission\u001b[39m.\u001b[39mcomment_sort \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m submission\u001b[39m.\u001b[39;49mcomments\u001b[39m.\u001b[39mreplace_more(limit\u001b[39m=\u001b[39m\u001b[39m1500\u001b[39m)\n\u001b[1;32m     22\u001b[0m count_comments\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m comment \u001b[39min\u001b[39;00m submission\u001b[39m.\u001b[39mcomments:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/praw/models/reddit/base.py:34\u001b[0m, in \u001b[0;36mRedditBase.__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the value of ``attribute``.\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m attribute\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetched:\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch()\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attribute)\n\u001b[1;32m     36\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m{\u001b[39;00mattribute\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/praw/models/reddit/submission.py:634\u001b[0m, in \u001b[0;36mSubmission._fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_data()\n\u001b[1;32m    635\u001b[0m     submission_listing, comment_listing \u001b[39m=\u001b[39m data\n\u001b[1;32m    636\u001b[0m     comment_listing \u001b[39m=\u001b[39m Listing(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reddit, _data\u001b[39m=\u001b[39mcomment_listing[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/praw/models/reddit/submission.py:631\u001b[0m, in \u001b[0;36mSubmission._fetch_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m name, fields, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetch_info()\n\u001b[1;32m    630\u001b[0m path \u001b[39m=\u001b[39m API_PATH[name]\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfields)\n\u001b[0;32m--> 631\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reddit\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams, path\u001b[39m=\u001b[39;49mpath)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/praw/util/deprecate_args.py:43\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     arg_string \u001b[39m=\u001b[39m _generate_arg_string(_old_args[: \u001b[39mlen\u001b[39m(args)])\n\u001b[1;32m     37\u001b[0m     warn(\n\u001b[1;32m     38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPositional arguments for \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m will no longer be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m supported in PRAW 8.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCall this function with \u001b[39m\u001b[39m{\u001b[39;00marg_string\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(_old_args, args)), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/praw/reddit.py:941\u001b[0m, in \u001b[0;36mReddit.request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[39mraise\u001b[39;00m ClientException(\u001b[39m\"\u001b[39m\u001b[39mAt most one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    940\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_core\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    942\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    943\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    944\u001b[0m         json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    945\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    946\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    947\u001b[0m         path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    948\u001b[0m     )\n\u001b[1;32m    949\u001b[0m \u001b[39mexcept\u001b[39;00m BadRequest \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m    950\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/prawcore/sessions.py:330\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    328\u001b[0m     json[\u001b[39m\"\u001b[39m\u001b[39mapi_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m url \u001b[39m=\u001b[39m urljoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requestor\u001b[39m.\u001b[39moauth_url, path)\n\u001b[0;32m--> 330\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_with_retries(\n\u001b[1;32m    331\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    332\u001b[0m     files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    333\u001b[0m     json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    334\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    335\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    336\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    337\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    338\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/prawcore/sessions.py:228\u001b[0m, in \u001b[0;36mSession._request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    226\u001b[0m retry_strategy_state\u001b[39m.\u001b[39msleep()\n\u001b[1;32m    227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_request(data, method, params, url)\n\u001b[0;32m--> 228\u001b[0m response, saved_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    229\u001b[0m     data,\n\u001b[1;32m    230\u001b[0m     files,\n\u001b[1;32m    231\u001b[0m     json,\n\u001b[1;32m    232\u001b[0m     method,\n\u001b[1;32m    233\u001b[0m     params,\n\u001b[1;32m    234\u001b[0m     retry_strategy_state,\n\u001b[1;32m    235\u001b[0m     timeout,\n\u001b[1;32m    236\u001b[0m     url,\n\u001b[1;32m    237\u001b[0m )\n\u001b[1;32m    239\u001b[0m do_retry \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    241\u001b[0m     response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m codes[\u001b[39m\"\u001b[39m\u001b[39munauthorized\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    243\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/prawcore/sessions.py:185\u001b[0m, in \u001b[0;36mSession._make_request\u001b[0;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    175\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     url,\n\u001b[1;32m    183\u001b[0m ):\n\u001b[1;32m    184\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rate_limiter\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m    186\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requestor\u001b[39m.\u001b[39;49mrequest,\n\u001b[1;32m    187\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_header_callback,\n\u001b[1;32m    188\u001b[0m             method,\n\u001b[1;32m    189\u001b[0m             url,\n\u001b[1;32m    190\u001b[0m             allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    191\u001b[0m             data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    192\u001b[0m             files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    193\u001b[0m             json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    194\u001b[0m             params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    195\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    196\u001b[0m         )\n\u001b[1;32m    197\u001b[0m         log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    198\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mResponse: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcontent-length\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m bytes)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/prawcore/rate_limit.py:33\u001b[0m, in \u001b[0;36mRateLimiter.call\u001b[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Rate limit the call to request_function.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[39m:param request_function: A function call that returns an HTTP response object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay()\n\u001b[0;32m---> 33\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m set_header_callback()\n\u001b[1;32m     34\u001b[0m response \u001b[39m=\u001b[39m request_function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(response\u001b[39m.\u001b[39mheaders)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/prawcore/sessions.py:283\u001b[0m, in \u001b[0;36mSession._set_header_callback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_header_callback\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_authorizer\u001b[39m.\u001b[39mis_valid() \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_authorizer, \u001b[39m\"\u001b[39m\u001b[39mrefresh\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     ):\n\u001b[0;32m--> 283\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_authorizer\u001b[39m.\u001b[39;49mrefresh()\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbearer \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_authorizer\u001b[39m.\u001b[39maccess_token\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/prawcore/auth.py:314\u001b[0m, in \u001b[0;36mDeviceIDAuthorizer.refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m     additional_kwargs[\u001b[39m\"\u001b[39m\u001b[39mscope\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scopes)\n\u001b[1;32m    313\u001b[0m grant_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://oauth.reddit.com/grants/installed_client\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 314\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_token(\n\u001b[1;32m    315\u001b[0m     grant_type\u001b[39m=\u001b[39;49mgrant_type,\n\u001b[1;32m    316\u001b[0m     device_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_device_id,\n\u001b[1;32m    317\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49madditional_kwargs,\n\u001b[1;32m    318\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/prawcore/auth.py:155\u001b[0m, in \u001b[0;36mBaseAuthorizer._request_token\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    151\u001b[0m url \u001b[39m=\u001b[39m (\n\u001b[1;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_authenticator\u001b[39m.\u001b[39m_requestor\u001b[39m.\u001b[39mreddit_url \u001b[39m+\u001b[39m const\u001b[39m.\u001b[39mACCESS_TOKEN_PATH\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m pre_request_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 155\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_authenticator\u001b[39m.\u001b[39;49m_post(url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    156\u001b[0m payload \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m payload:  \u001b[39m# Why are these OKAY responses?\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/prawcore/auth.py:38\u001b[0m, in \u001b[0;36mBaseAuthenticator._post\u001b[0;34m(self, url, success_status, **data)\u001b[0m\n\u001b[1;32m     30\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mConnection\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m success_status:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mraise\u001b[39;00m ResponseException(response)\n\u001b[1;32m     39\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mResponseException\u001b[0m: received 401 HTTP response"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from praw.models import MoreComments\n",
    "\n",
    "secret_token = \"\"\n",
    "client_id = \"\"\n",
    "username = \"\"\n",
    "password = \"\"\n",
    "\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=secret_token, password=password,\n",
    "                     user_agent='MyBot/0.0.1', username=username)\n",
    "\n",
    "df = []\n",
    "\n",
    "submission = reddit.submission(id='iq41dt')\n",
    "\n",
    "submission.comment_sort = \"best\"\n",
    "submission.comments.replace_more(limit=1500)\n",
    "\n",
    "count_comments=0\n",
    "\n",
    "for comment in submission.comments:\n",
    "\n",
    "    if isinstance(comment, MoreComments):\n",
    "        continue\n",
    "\n",
    "    if comment.stickied == False:\n",
    "\n",
    "        c_author = comment.author\n",
    "        if c_author == None: \n",
    "            c_author = \"NA\"\n",
    "        else:\n",
    "            c_author = c_author.name\n",
    "\n",
    "        c_replies = 0\n",
    "        for reply in comment.replies:\n",
    "            c_replies += 1\n",
    "\n",
    "        c_awards = 0\n",
    "        for award in comment.all_awardings:\n",
    "            c_awards += 1\n",
    "\n",
    "        df_comment = pd.DataFrame({\n",
    "            'post_id': submission.id,\n",
    "            'comment_id': comment.id,\n",
    "            'subreddit': submission.subreddit.display_name,\n",
    "            'post_title': submission.title,\n",
    "            'post_ups': submission.ups,\n",
    "            'post_upvote_ratio': submission.upvote_ratio,\n",
    "            'post_num_comments': submission.num_comments,\n",
    "            'post_time': datetime.datetime.fromtimestamp(submission.created_utc),\n",
    "            'post_text': submission.selftext,\n",
    "            'post_downs': submission.downs,\n",
    "            'post_score': submission.score,\n",
    "            'post_awards': p_awards,\n",
    "            'comment_awards': c_awards,\n",
    "            'comment_author': c_author,\n",
    "            'body': comment.body,\n",
    "            'comment_replies': c_replies,\n",
    "            'comment_ups': comment.ups,\n",
    "            'comment_downs': comment.downs,\n",
    "            'comment_time' : datetime.datetime.fromtimestamp(comment.created_utc),\n",
    "            'comment_score': comment.score\n",
    "        }, index=[count_comments])\n",
    "\n",
    "        df = pd.concat([df, df_comment])\n",
    "\n",
    "        print(\"Post: \"+str(count_posts) + \"    Comment:\"+ str(count_comments) + \"    Inpost comment:\" + str(i))\n",
    "\n",
    "        count_comments += 1\n",
    "\n",
    "df.to_csv(\"cmv_extract.csv\", sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99a606",
   "metadata": {},
   "source": [
    "### 2) PRE PROCESSING \n",
    "In this section we are going to first load and clean the Data Frame. Then we will carry out the usual steps in Text Mining preprocessing: tokenization, lemmatizing, remove punctuation, unify, remove stopwords, stemming. Finally we will obtain the Document Term Matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "c74f9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "42606686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 849 entries, 0 to 848\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         849 non-null    int64  \n",
      " 1   post_id            849 non-null    object \n",
      " 2   comment_id         849 non-null    object \n",
      " 3   subreddit          849 non-null    object \n",
      " 4   post_title         849 non-null    object \n",
      " 5   post_ups           849 non-null    int64  \n",
      " 6   post_upvote_ratio  849 non-null    float64\n",
      " 7   post_num_comments  849 non-null    int64  \n",
      " 8   post_time          849 non-null    object \n",
      " 9   post_text          849 non-null    object \n",
      " 10  post_downs         849 non-null    int64  \n",
      " 11  post_score         849 non-null    int64  \n",
      " 12  post_awards        849 non-null    int64  \n",
      " 13  comment_awards     849 non-null    int64  \n",
      " 14  comment_author     647 non-null    object \n",
      " 15  body               849 non-null    object \n",
      " 16  comment_replies    849 non-null    int64  \n",
      " 17  comment_ups        849 non-null    int64  \n",
      " 18  comment_downs      849 non-null    int64  \n",
      " 19  comment_time       849 non-null    object \n",
      " 20  comment_score      849 non-null    int64  \n",
      "dtypes: float64(1), int64(11), object(9)\n",
      "memory usage: 139.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataframe\n",
    "readin = '/Users/Ramon/Documents/Estudio/BSE/Term_2/Intro_Text_Analysis/Project/writingprompts-lda-project'\n",
    "filename =\"cmv_extract.csv\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(readin, filename), sep=';', encoding='utf-8')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "f35740e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 736 entries, 0 to 735\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         736 non-null    int64  \n",
      " 1   post_id            736 non-null    object \n",
      " 2   comment_id         736 non-null    object \n",
      " 3   subreddit          736 non-null    object \n",
      " 4   post_title         736 non-null    object \n",
      " 5   post_ups           736 non-null    int64  \n",
      " 6   post_upvote_ratio  736 non-null    float64\n",
      " 7   post_num_comments  736 non-null    int64  \n",
      " 8   post_time          736 non-null    object \n",
      " 9   post_text          736 non-null    object \n",
      " 10  post_downs         736 non-null    int64  \n",
      " 11  post_score         736 non-null    int64  \n",
      " 12  post_awards        736 non-null    int64  \n",
      " 13  comment_awards     736 non-null    int64  \n",
      " 14  comment_author     647 non-null    object \n",
      " 15  body               736 non-null    object \n",
      " 16  comment_replies    736 non-null    int64  \n",
      " 17  comment_ups        736 non-null    int64  \n",
      " 18  comment_downs      736 non-null    int64  \n",
      " 19  comment_time       736 non-null    object \n",
      " 20  comment_score      736 non-null    int64  \n",
      "dtypes: float64(1), int64(11), object(9)\n",
      "memory usage: 120.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Remove NA \n",
    "df = df.loc[df['body'] != '[removed]']\n",
    "df = df.dropna(subset=['body']) \n",
    "\n",
    "df = df.reset_index(drop=True) \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "c4f09f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Title: \n",
      " CMV: Donald Trump has not made a single lasting positive impact on the USA during his term as president.\n",
      "   \n",
      "Text 1 : \n",
      " How about his signing into law of \"right-to-try\" legislation, allowing gravely ill patients access to experimental drugs?\n",
      "   \n",
      "Text 2 : \n",
      " I haven't seen this posted yet - but by far his most important accomplishment has been keeping America out of any new foreign conflicts. [According to this article](https://www.theelders.org/news/only-us-president-who-didnt-wage-war), the only other president who managed to keep the US out of new foreign conflicts was Jimmy Carter. Thus if this holds through the rest of his term, Trump will be only the second to manage that.\n",
      "\n",
      "For all the talk about Trump being an idiot, and dangerous, and in over his head, I'd submit that keeping the US out of other people's wars is not an easy thing to do. I think he deserves an enormous amount of respect for having pulled this off.\n"
     ]
    }
   ],
   "source": [
    "print(\"Post Title: \\n\", df.post_title[0])\n",
    "print(\"   \")\n",
    "print(\"Text 1 : \\n\", df.body[0])\n",
    "print(\"   \")\n",
    "print(\"Text 2 : \\n\", df.body[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c2646",
   "metadata": {},
   "source": [
    "Note that from a unique post title: \" Donald Trump has not made a single lasting positive impact on the USA during his term as president\" we have extracted 736 user's opinions. \n",
    "\n",
    "First, we are going to preprocess this texts and obtain the document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "0b2e826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk           \n",
    "\n",
    "# Natural language Toolkit\n",
    "from nltk.stem import SnowballStemmer                                   # Porter's II Stemmer\n",
    "from nltk import word_tokenize                                          # Document tokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "porter=SnowballStemmer(\"english\")\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    clean_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(clean_words)\n",
    "        \n",
    "def abbr_or_lower(word):\n",
    "    if re.match('([A-Z]+[a-z]*){2,}', word):\n",
    "        return word\n",
    "    else:\n",
    "        return word.lower()\n",
    "\n",
    "def tokenize(text, modulation):\n",
    "    tokens = re.split(r'\\W+', text)\n",
    "    stems = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        lowers=abbr_or_lower(token)\n",
    "        if lowers not in stop_words:\n",
    "            if re.search('[a-zA-Z]', lowers):\n",
    "                if modulation==1:\n",
    "                    stems.append(porter.stem(lowers))\n",
    "                if modulation==2:\n",
    "                    stems.append(lmtzr.lemmatize(lowers))\n",
    "                if modulation==0:\n",
    "                    stems.append(lowers)\n",
    "                stems.append(\" \")\n",
    "    return \"\".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "ab70564b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 736/736 [00:00<00:00, 2385.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "my_stopwords = ['com', 'reddit', 'http', 'wiki', 'www', 'im', 'trump', 'lol', 'people', 'expand',\n",
    "                'really', 'deal','u', 'much', 'get', 'good', 'act', 'put', 'man', 'a', 'think', 'one',\n",
    "                'say', 'like', 'go', 'do', 'head', 'yet', 'wall', 'guess', 'keep', 'oh', 'north', 'oil',\n",
    "                'prize', 'involved', 'might', 'medium''among', 'might', 'make', 'do', 'may', 'year', 'give',\n",
    "                'also', 'law', 'etc', 'wait', 'prove', 'mean', 'thing', 'rest', 'middle','rnr','u','fuck','make',\n",
    "                'would', 'know', 'lot', 'see', 'president', 'done', 'even', 'many', 'ever', 'want', 'made',\n",
    "                'got', 'going', 'need', 'view', 'something', 'lasting', 'still', 'way', 'every', 'anyone', \n",
    "                'first', 'look', 'medium', 'time', 'since', 'life', 'probably', 'anything', 'come', \n",
    "                'long', 'could', 'anything', 'donald', 'back', 'sure', 'last', 'nothing', 'rate', 'well',\n",
    "                'left', 'le', 'someone', 'example', 'seen', 'day', 'said', 'world', 'making', 'far', 'care',\n",
    "                'shit','america','issue','new', 'actually','never','whole','exposed','imapct','side','single']\n",
    "stop_words.update(my_stopwords)\n",
    "\n",
    "df['body'] = df['body'].apply(remove_stopwords)\n",
    "\n",
    "\n",
    "# lemmatizing / stemming\n",
    "mod=2 #=1 means stemming, =2 means lemmatizing, =0 just lowercase\n",
    "\n",
    "text_preproc = (\n",
    "    df.body\n",
    "    .astype(str)\n",
    "    .progress_apply(lambda row: tokenize(row, mod))\n",
    ")\n",
    "\n",
    "df_proc = df\n",
    "df_proc[\"text_preproc\"]=text_preproc\n",
    "\n",
    "\n",
    "# again stopwords\n",
    "df['text_preproc'] = df['text_preproc'].apply(remove_stopwords)\n",
    "\n",
    "\n",
    "print(\"done with text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "6be5ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signing right try legislation allowing gravely ill patient access experimental drug\n"
     ]
    }
   ],
   "source": [
    "for article in df.text_preproc[:1]:\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "672462b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Texts = df_proc.text_preproc.tolist()\n",
    "\n",
    "for text in Texts:\n",
    "    remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "024cc1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of DT matrix are (736, 21732)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Without tf-idf \n",
    "cv = CountVectorizer(ngram_range = (1,2))\n",
    "cv.fit(Texts)\n",
    "vectorized_text=cv.transform(Texts)\n",
    "names=np.array(cv.get_feature_names())\n",
    "print(\"dimensions of DT matrix are\", vectorized_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "af1683d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21722</th>\n",
       "      <th>21723</th>\n",
       "      <th>21724</th>\n",
       "      <th>21725</th>\n",
       "      <th>21726</th>\n",
       "      <th>21727</th>\n",
       "      <th>21728</th>\n",
       "      <th>21729</th>\n",
       "      <th>21730</th>\n",
       "      <th>21731</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "2      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "3      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "4      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   21722  21723  21724  21725  21726  21727  21728  21729  21730  21731  \n",
       "0      0      0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 21732 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = pd.DataFrame.sparse.from_spmatrix(vectorized_text)\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "a693269a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Heat matrix from Document Term Matrix\n",
    "sns.heatmap(dtm.iloc[:100, :100], cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df219b97",
   "metadata": {},
   "source": [
    "### 3) POST PROCESSING\n",
    "In this section we are going to use both the term frequency and the inverse document frequency to reweight the terms in the document term matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "ab4bb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try if tf-idf \n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# cv = TfidfVectorizer(ngram_range = (1,2), norm=None)\n",
    "# cv.fit(Texts)\n",
    "# vectorized_text=cv.transform(Texts)\n",
    "# vectorized_text=vectorized_text.todense()\n",
    "# print(\"document term matrix has size\", vectorized_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f5eb0",
   "metadata": {},
   "source": [
    "### 4A) LDA IMPLEMENTATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "38446022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "2e195a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Ramon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "corp = [nltk.word_tokenize(text) for text in Texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "8276528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5243"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(corp)\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "f7f883ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "3d258d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = [dictionary.doc2bow(line) for line in corp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "3d0cca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "def viz_model(model, modeldict):\n",
    "    ntopics = model.num_topics\n",
    "    # top words associated with the resulting topics\n",
    "    topics = ['Topic {}: {}'.format(t,modeldict[w]) \n",
    "              for t in range(ntopics) \n",
    "              for w,p in model.get_topic_terms(t, topn=1)]\n",
    "              \n",
    "    terms = [modeldict[w] for w in modeldict.keys()]\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.imshow(model.get_topics())  # plot the numpy matrix\n",
    "    ax.set_xticks(modeldict.keys())  # set up the x-axis\n",
    "    ax.set_xticklabels(terms, rotation=90)\n",
    "    ax.set_yticks(np.arange(ntopics))  # set up the y-axis\n",
    "    ax.set_yticklabels(topics)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "c691480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eta(eta, dictionary, ntopics, print_topics=True, print_dist=True):\n",
    "    np.random.seed(42) # set the random seed for repeatability\n",
    "    bow = [dictionary.doc2bow(line) for line in corp] # get the bow-format lines with the set dictionary\n",
    "    with (np.errstate(divide='ignore')):  # ignore divide-by-zero warnings\n",
    "        model = gensim.models.ldamodel.LdaModel(\n",
    "            corpus=bow, id2word=dictionary, num_topics=ntopics,\n",
    "            random_state=42, chunksize=100, eta=eta,\n",
    "            eval_every=-1, update_every=1,\n",
    "            passes=150, alpha=0.8, per_word_topics=True)\n",
    "    # visuzlize the model term topics\n",
    "    #viz_model(model, dictionary)\n",
    "    print('Perplexity: {:.2f}'.format(model.log_perplexity(bow)))\n",
    "    if print_topics:\n",
    "        # display the top terms for each topic\n",
    "        for topic in range(ntopics):\n",
    "            print('Topic {}: {}'.format(topic, [dictionary[w] for w,p in model.get_topic_terms(topic, topn=8)]))\n",
    "    if print_dist:\n",
    "        # display the topic probabilities for each document\n",
    "        doc_topics_list = []\n",
    "        for idx, (line,bag) in enumerate(zip(Texts,bow)):\n",
    "            doc_topics = model.get_document_topics(bag)\n",
    "            doc_topics_list.append({'document': idx, 'probabilities': dict(doc_topics)})\n",
    "            print('{}: {}'.format(idx, doc_topics))\n",
    "    return model, doc_topics_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "a50a4cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {0: 0.17317405, 1: 0.44439787, 2: 0.074084274, 3: 0.07408405, 4: 0.16017509, 5: 0.074084684}\n",
      "1 {0: 0.051969163, 1: 0.13446696, 2: 0.26544872, 3: 0.0388504, 4: 0.041127976, 5: 0.46813676}\n",
      "2 {0: 0.06510327, 1: 0.16806704, 2: 0.10711836, 3: 0.18069981, 4: 0.1957498, 5: 0.28326175}\n",
      "3 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.3102946}\n",
      "4 {0: 0.3138841, 1: 0.110043325, 2: 0.02879721, 3: 0.20460083, 4: 0.18268412, 5: 0.15999041}\n",
      "5 {0: 0.25720853, 1: 0.6681237, 2: 0.015318271, 3: 0.027475372, 4: 0.02085282, 5: 0.011021274}\n",
      "6 {0: 0.30857617, 1: 0.24363668, 2: 0.10232356, 3: 0.042564258, 4: 0.2510836, 5: 0.05181572}\n",
      "7 {0: 0.15528442, 1: 0.13793384, 2: 0.13793513, 3: 0.137935, 4: 0.29297638, 5: 0.13793519}\n",
      "8 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.31029457}\n",
      "9 {0: 0.022522895, 1: 0.030139081, 2: 0.13980484, 3: 0.13400652, 4: 0.5239044, 5: 0.1496223}\n",
      "10 {0: 0.07408568, 1: 0.07639652, 2: 0.07408566, 3: 0.2592391, 4: 0.34953597, 5: 0.16665708}\n",
      "11 {0: 0.1244525, 1: 0.02362735, 2: 0.15909538, 3: 0.26745796, 4: 0.20550728, 5: 0.21985959}\n",
      "12 {0: 0.07286704, 1: 0.082048155, 2: 0.38649967, 3: 0.16706747, 4: 0.110720694, 5: 0.18079698}\n",
      "13 {0: 0.06250779, 1: 0.22307368, 2: 0.14060667, 3: 0.36473197, 4: 0.1465716, 5: 0.06250827}\n",
      "14 {0: 0.10973491, 1: 0.10747922, 2: 0.04762991, 3: 0.048878435, 4: 0.5721889, 5: 0.11408857}\n",
      "15 {0: 0.10109451, 1: 0.1618709, 2: 0.1439716, 3: 0.15188928, 4: 0.18682839, 5: 0.2543453}\n",
      "16 {0: 0.18894927, 1: 0.16656326, 2: 0.074091, 3: 0.16670364, 4: 0.32960147, 5: 0.074091315}\n",
      "17 {0: 0.4738847, 1: 0.09386843, 2: 0.08449866, 3: 0.14222163, 4: 0.08131561, 5: 0.12421097}\n",
      "18 {0: 0.044645566, 1: 0.07602517, 2: 0.11316577, 3: 0.14314148, 4: 0.15316032, 5: 0.4698617}\n",
      "19 {0: 0.46938172, 1: 0.09397639, 2: 0.045452714, 3: 0.024327233, 4: 0.024254797, 5: 0.3426071}\n",
      "20 {0: 0.20671766, 1: 0.2567594, 2: 0.09737604, 3: 0.08873188, 4: 0.087052025, 5: 0.263363}\n",
      "21 {0: 0.35618758, 1: 0.50735015, 2: 0.018049603, 3: 0.031115437, 4: 0.041223858, 5: 0.04607335}\n",
      "22 {0: 0.04495028, 1: 0.101114474, 2: 0.15729316, 3: 0.044950385, 4: 0.15726452, 5: 0.49442726}\n",
      "23 {0: 0.08785857, 1: 0.03999664, 2: 0.31953403, 3: 0.24672985, 4: 0.16890533, 5: 0.13697557}\n",
      "24 {0: 0.16298118, 1: 0.012718958, 2: 0.2631284, 3: 0.19236887, 4: 0.18469884, 5: 0.18410377}\n",
      "25 {0: 0.142048, 1: 0.04779021, 2: 0.20158201, 3: 0.29773012, 4: 0.16782917, 5: 0.14302042}\n",
      "26 {0: 0.10712552, 1: 0.24096899, 2: 0.022541638, 3: 0.01786084, 4: 0.08858592, 5: 0.5229171}\n",
      "27 {0: 0.13485456, 1: 0.19985692, 2: 0.16704904, 3: 0.09540377, 4: 0.28360343, 5: 0.11923231}\n",
      "28 {0: 0.13793209, 1: 0.13793176, 2: 0.13793212, 3: 0.13793209, 4: 0.13793206, 5: 0.31033984}\n",
      "29 {0: 0.12503867, 1: 0.80746144, 2: 0.022395946, 4: 0.019145887, 5: 0.02053904}\n",
      "30 {0: 0.1506311, 1: 0.086118385, 2: 0.33970982, 3: 0.12953217, 4: 0.25759676, 5: 0.036411796}\n",
      "31 {0: 0.19011945, 1: 0.08244788, 2: 0.15844421, 3: 0.021534517, 4: 0.29608372, 5: 0.25137025}\n",
      "32 {0: 0.045299962, 1: 0.08987865, 2: 0.28143328, 3: 0.122773886, 4: 0.07762369, 5: 0.38299054}\n",
      "33 {0: 0.075149134, 1: 0.32155484, 2: 0.08818672, 3: 0.07408617, 4: 0.2582177, 5: 0.18280546}\n",
      "34 {0: 0.07558729, 1: 0.5652075, 2: 0.05797969, 3: 0.18526623, 4: 0.05797926, 5: 0.057980064}\n",
      "35 {0: 0.07643513, 1: 0.076395094, 2: 0.07408429, 3: 0.16664268, 4: 0.34956184, 5: 0.25688097}\n",
      "36 {0: 0.13793218, 1: 0.13793184, 2: 0.29798508, 3: 0.13793218, 4: 0.13793217, 5: 0.15028653}\n",
      "37 {0: 0.17661686, 1: 0.13793209, 2: 0.13793258, 3: 0.27165332, 4: 0.13793251, 5: 0.13793264}\n",
      "38 {0: 0.1973598, 1: 0.073424414, 2: 0.0374785, 3: 0.48622444, 4: 0.15842992, 5: 0.04708295}\n",
      "39 {0: 0.6056761, 1: 0.25283536, 2: 0.06376419, 3: 0.018162057, 4: 0.03688848, 5: 0.02267378}\n",
      "40 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.31029454}\n",
      "41 {0: 0.14672974, 1: 0.052357636, 2: 0.36882132, 3: 0.17320019, 4: 0.15926279, 5: 0.09962834}\n",
      "42 {0: 0.1176533, 1: 0.397221, 2: 0.13216588, 3: 0.11765316, 4: 0.11765311, 5: 0.11765357}\n",
      "43 {0: 0.22781311, 1: 0.058703445, 2: 0.15241605, 3: 0.16406666, 4: 0.10203984, 5: 0.29496086}\n",
      "44 {0: 0.37513435, 1: 0.24777475, 2: 0.16315871, 3: 0.0151661495, 4: 0.13504772, 5: 0.06371835}\n",
      "45 {0: 0.026851699, 1: 0.026849873, 2: 0.09657383, 3: 0.12746494, 4: 0.62217295, 5: 0.10008671}\n",
      "46 {0: 0.48716566, 1: 0.10256618, 2: 0.10256707, 3: 0.10256698, 4: 0.1025669, 5: 0.10256719}\n",
      "47 {0: 0.41175526, 1: 0.11764845, 2: 0.11764908, 3: 0.117649026, 4: 0.117649, 5: 0.117649175}\n",
      "48 {0: 0.08537707, 1: 0.17221522, 2: 0.1665954, 3: 0.25374132, 4: 0.24798071, 5: 0.07409032}\n",
      "49 {0: 0.1324696, 1: 0.26463524, 2: 0.11766115, 3: 0.11766107, 4: 0.24991053, 5: 0.11766242}\n",
      "50 {0: 0.11764984, 1: 0.117649, 2: 0.117649876, 3: 0.11764985, 4: 0.11764982, 5: 0.41175163}\n",
      "51 {0: 0.11765338, 1: 0.1176515, 2: 0.117653735, 3: 0.4117343, 4: 0.11765325, 5: 0.117653795}\n",
      "52 {0: 0.14056523, 1: 0.06250626, 2: 0.21871956, 3: 0.06250889, 4: 0.06250874, 5: 0.4531913}\n",
      "53 {0: 0.121332414, 1: 0.3181306, 2: 0.20456532, 3: 0.09092052, 4: 0.17413026, 5: 0.09092087}\n",
      "54 {0: 0.16657531, 1: 0.16661376, 2: 0.07408673, 3: 0.07408652, 4: 0.07408634, 5: 0.4445513}\n",
      "55 {0: 0.18729319, 1: 0.038970567, 2: 0.18208551, 3: 0.039050158, 4: 0.0514902, 5: 0.50111043}\n",
      "56 {0: 0.10958432, 1: 0.090921335, 2: 0.30608377, 3: 0.09092624, 4: 0.20451474, 5: 0.19796957}\n",
      "57 {0: 0.13793565, 1: 0.13793416, 2: 0.31032324, 3: 0.13793562, 4: 0.13793541, 5: 0.13793594}\n",
      "58 {0: 0.33328566, 1: 0.18521057, 2: 0.2592607, 3: 0.07408095, 4: 0.07408075, 5: 0.07408132}\n",
      "59 {0: 0.08164116, 1: 0.08163855, 2: 0.1836584, 3: 0.28570566, 4: 0.28571445, 5: 0.08164175}\n",
      "60 {0: 0.117655404, 1: 0.12384111, 2: 0.25851065, 3: 0.117655575, 4: 0.26468134, 5: 0.117655896}\n",
      "61 {0: 0.333738, 1: 0.10257092, 2: 0.102573894, 3: 0.25596923, 4: 0.10257359, 5: 0.10257438}\n",
      "62 {0: 0.26468208, 1: 0.11765537, 2: 0.11765914, 3: 0.11765893, 4: 0.26468483, 5: 0.117659636}\n",
      "63 {0: 0.1379382, 1: 0.13793604, 2: 0.1379385, 3: 0.31031042, 4: 0.13793802, 5: 0.13793877}\n",
      "64 {0: 0.08541403, 1: 0.08475473, 2: 0.28569016, 3: 0.081638254, 4: 0.08163799, 5: 0.3808648}\n",
      "65 {0: 0.49158278, 1: 0.22302979, 2: 0.081972465, 3: 0.067804925, 4: 0.067804776, 5: 0.06780526}\n",
      "66 {0: 0.057983108, 1: 0.05797936, 2: 0.20285827, 3: 0.3478492, 4: 0.057982773, 5: 0.27534732}\n",
      "67 {0: 0.10257625, 1: 0.10257255, 2: 0.23072535, 3: 0.19669007, 4: 0.26485863, 5: 0.102577135}\n",
      "68 {0: 0.102568515, 1: 0.10256711, 2: 0.23074114, 3: 0.102568515, 4: 0.35898593, 5: 0.10256879}\n",
      "69 {0: 0.05169169, 1: 0.047625583, 2: 0.27429354, 3: 0.28247282, 4: 0.047627985, 5: 0.29628837}\n",
      "70 {0: 0.11764865, 1: 0.11764817, 2: 0.2541337, 3: 0.117648676, 4: 0.26470467, 5: 0.1282161}\n",
      "71 {0: 0.10257572, 1: 0.10405715, 2: 0.23072144, 3: 0.2956616, 4: 0.15489382, 5: 0.11209024}\n",
      "72 {0: 0.10257016, 1: 0.10664007, 2: 0.102570266, 3: 0.22669573, 4: 0.11790027, 5: 0.34362352}\n",
      "73 {0: 0.137936, 1: 0.14924443, 2: 0.29901183, 3: 0.13793589, 4: 0.13793573, 5: 0.13793615}\n",
      "74 {0: 0.13793634, 1: 0.1379348, 2: 0.13793652, 3: 0.31031954, 4: 0.13793623, 5: 0.1379366}\n",
      "75 {0: 0.15252888, 1: 0.06780149, 2: 0.07524699, 3: 0.06780367, 4: 0.15250027, 5: 0.48411873}\n",
      "76 {0: 0.090918675, 1: 0.09091581, 2: 0.47985277, 3: 0.090918966, 4: 0.15647429, 5: 0.090919465}\n",
      "77 {0: 0.11765345, 1: 0.11765153, 2: 0.11765356, 3: 0.26469058, 4: 0.26469705, 5: 0.11765388}\n",
      "78 {0: 0.23093696, 1: 0.22731407, 2: 0.11552941, 3: 0.06712761, 4: 0.1377565, 5: 0.22133546}\n",
      "79 {0: 0.14485204, 1: 0.34010887, 2: 0.091626145, 3: 0.10231365, 4: 0.074044734, 5: 0.24705458}\n",
      "80 {0: 0.18365699, 1: 0.18425223, 2: 0.16453138, 3: 0.09087365, 4: 0.2659765, 5: 0.110709235}\n",
      "81 {0: 0.22373529, 1: 0.30547562, 2: 0.12501597, 3: 0.034397457, 4: 0.048373487, 5: 0.26300213}\n",
      "82 {0: 0.20455514, 1: 0.09091643, 2: 0.31818923, 3: 0.20449975, 4: 0.09091922, 5: 0.09092019}\n",
      "83 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.31029457}\n",
      "84 {0: 0.10256778, 1: 0.48716155, 2: 0.10256769, 3: 0.1025676, 4: 0.102567516, 5: 0.10256785}\n",
      "85 {0: 0.22379194, 1: 0.10680634, 2: 0.15584642, 3: 0.18217279, 4: 0.17551962, 5: 0.15586291}\n",
      "86 {0: 0.15077452, 1: 0.3953566, 2: 0.17882533, 3: 0.13484755, 4: 0.06182417, 5: 0.07837186}\n",
      "87 {0: 0.045934763, 1: 0.599865, 2: 0.08262057, 3: 0.1176786, 4: 0.08933997, 5: 0.06456111}\n",
      "88 {0: 0.1985997, 1: 0.038468674, 2: 0.4011457, 3: 0.18263973, 4: 0.038471557, 5: 0.14067462}\n",
      "89 {0: 0.31817785, 1: 0.09091654, 2: 0.090919904, 3: 0.17432702, 4: 0.2347383, 5: 0.0909204}\n",
      "90 {0: 0.0909167, 1: 0.099716865, 2: 0.19693232, 3: 0.39321843, 4: 0.12176623, 5: 0.097449474}\n",
      "91 {0: 0.11765578, 1: 0.41172102, 2: 0.1176561, 3: 0.11765548, 4: 0.11765545, 5: 0.1176562}\n",
      "92 {0: 0.095274895, 1: 0.18082072, 2: 0.029860053, 3: 0.29284668, 4: 0.17154771, 5: 0.22964993}\n",
      "93 {0: 0.2857136, 1: 0.081641585, 2: 0.18364663, 3: 0.18366128, 4: 0.18369058, 5: 0.08164633}\n",
      "94 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.3102946}\n",
      "95 {0: 0.13193372, 1: 0.12054028, 2: 0.39366725, 3: 0.24624527, 4: 0.08750885, 5: 0.020104624}\n",
      "96 {0: 0.12727888, 1: 0.14392631, 2: 0.032239456, 3: 0.24853979, 4: 0.3655, 5: 0.08251555}\n",
      "97 {0: 0.12883665, 1: 0.028862549, 2: 0.058753364, 3: 0.65227807, 4: 0.050602715, 5: 0.08066666}\n",
      "98 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.31029457}\n",
      "99 {0: 0.0678016, 1: 0.15250942, 2: 0.14647652, 3: 0.067801535, 4: 0.4915388, 5: 0.073872104}\n",
      "100 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.3102946}\n",
      "101 {0: 0.2646352, 1: 0.11765698, 2: 0.11766162, 3: 0.11766118, 4: 0.26472226, 5: 0.117662735}\n",
      "102 {0: 0.074086346, 1: 0.1690486, 2: 0.09944898, 3: 0.07408611, 4: 0.16669786, 5: 0.41663206}\n",
      "103 {0: 0.08164017, 1: 0.48978406, 2: 0.08164043, 3: 0.18365464, 4: 0.08164007, 5: 0.081640616}\n",
      "104 {0: 0.118186735, 1: 0.21177381, 2: 0.12152392, 3: 0.1025719, 4: 0.34337133, 5: 0.102572314}\n",
      "105 {0: 0.12989685, 1: 0.07047097, 2: 0.20289056, 3: 0.2028498, 4: 0.33591196, 5: 0.05797985}\n",
      "106 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "107 {0: 0.21877094, 1: 0.29687288, 2: 0.06251062, 3: 0.14059897, 4: 0.21873556, 5: 0.062511034}\n",
      "108 {0: 0.16661112, 1: 0.047625404, 2: 0.3452358, 3: 0.10711032, 4: 0.047627926, 5: 0.2857895}\n",
      "109 {0: 0.20455587, 1: 0.31812933, 2: 0.0909264, 3: 0.09092634, 4: 0.09092574, 5: 0.20453635}\n",
      "110 {0: 0.121510714, 1: 0.12318361, 2: 0.12808917, 3: 0.059305865, 4: 0.06642032, 5: 0.5014903}\n",
      "111 {0: 0.23810405, 1: 0.08164226, 2: 0.1836333, 3: 0.23133406, 4: 0.18363884, 5: 0.08164751}\n",
      "112 {0: 0.14729866, 1: 0.4352527, 2: 0.06251117, 3: 0.08037726, 4: 0.062510714, 5: 0.2120495}\n",
      "113 {0: 0.40274632, 1: 0.22759394, 2: 0.09092305, 3: 0.09092244, 4: 0.090922125, 5: 0.096892156}\n",
      "114 {0: 0.09092241, 1: 0.090918235, 2: 0.20455611, 3: 0.20449537, 4: 0.09092229, 5: 0.3181856}\n",
      "115 {0: 0.10256993, 1: 0.10256815, 2: 0.10256996, 3: 0.23077217, 4: 0.102569856, 5: 0.35894996}\n",
      "116 {0: 0.10256898, 1: 0.10256748, 2: 0.23074983, 3: 0.23076896, 4: 0.10256881, 5: 0.23077592}\n",
      "117 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.3102946}\n",
      "118 {0: 0.10257333, 1: 0.2384695, 2: 0.10257359, 3: 0.35123664, 4: 0.10257303, 5: 0.102573946}\n",
      "119 {0: 0.08257534, 1: 0.041278195, 2: 0.08250704, 3: 0.39982828, 4: 0.35636422, 5: 0.037446905}\n",
      "120 {0: 0.10256785, 1: 0.102566764, 2: 0.10256769, 3: 0.4871622, 4: 0.10256758, 5: 0.10256792}\n",
      "121 {0: 0.28368914, 1: 0.093512185, 2: 0.30442, 3: 0.0678071, 4: 0.06780706, 5: 0.18276453}\n",
      "122 {0: 0.07407796, 1: 0.07407678, 2: 0.07407807, 3: 0.629611, 4: 0.0740779, 5: 0.07407823}\n",
      "123 {0: 0.16661233, 1: 0.035270438, 2: 0.09563406, 3: 0.08530554, 4: 0.043078776, 5: 0.5740988}\n",
      "124 {0: 0.14868677, 1: 0.057975404, 2: 0.27535278, 3: 0.05797732, 4: 0.39143157, 5: 0.06857618}\n",
      "125 {0: 0.1358763, 1: 0.4219865, 2: 0.038689725, 3: 0.025640732, 4: 0.07142715, 5: 0.30637962}\n",
      "126 {0: 0.12161082, 1: 0.121602714, 2: 0.12156257, 3: 0.31351236, 4: 0.2529671, 5: 0.068744466}\n",
      "127 {0: 0.117656924, 1: 0.26471934, 2: 0.2646554, 3: 0.117656104, 4: 0.11765562, 5: 0.11765663}\n",
      "128 {0: 0.1504365, 1: 0.29441047, 2: 0.20217265, 3: 0.11765996, 4: 0.11765963, 5: 0.117660806}\n",
      "129 {0: 0.10257804, 1: 0.23073198, 2: 0.23075733, 3: 0.23077628, 4: 0.10257763, 5: 0.10257874}\n",
      "130 {0: 0.07081743, 1: 0.49913114, 2: 0.037705522, 3: 0.14682457, 4: 0.14687984, 5: 0.098641545}\n",
      "131 {0: 0.03685833, 1: 0.03457846, 2: 0.116637714, 3: 0.032263402, 4: 0.27332067, 5: 0.50634146}\n",
      "132 {0: 0.40141314, 1: 0.059449278, 2: 0.105855435, 3: 0.13040191, 4: 0.17249307, 5: 0.13038717}\n",
      "133 {0: 0.07408376, 1: 0.25922176, 2: 0.07408421, 3: 0.16663444, 4: 0.3518915, 5: 0.07408431}\n",
      "134 {0: 0.3103299, 1: 0.13793324, 2: 0.13793424, 3: 0.13793416, 4: 0.13793409, 5: 0.13793437}\n",
      "135 {0: 0.15249133, 1: 0.08662506, 2: 0.06780369, 3: 0.067803465, 4: 0.0678034, 5: 0.55747306}\n",
      "136 {0: 0.10710125, 1: 0.60362715, 2: 0.0738088, 3: 0.047627475, 4: 0.10711136, 5: 0.060723927}\n",
      "137 {0: 0.19576646, 1: 0.3181627, 2: 0.09974021, 3: 0.20448168, 4: 0.09092359, 5: 0.09092532}\n",
      "138 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "139 {0: 0.13128221, 1: 0.10705978, 2: 0.35444334, 3: 0.20207044, 4: 0.10257174, 5: 0.10257245}\n",
      "140 {0: 0.10257139, 1: 0.35892832, 2: 0.10257129, 3: 0.1025712, 4: 0.23078613, 5: 0.10257167}\n",
      "141 {0: 0.1623175, 1: 0.06780664, 2: 0.32203075, 3: 0.067811005, 4: 0.31222197, 5: 0.067812175}\n",
      "142 {0: 0.067807406, 1: 0.27042645, 2: 0.20407587, 3: 0.06780715, 4: 0.32207525, 5: 0.067807876}\n",
      "143 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "144 {0: 0.12163418, 1: 0.057419036, 2: 0.18919381, 3: 0.18917163, 4: 0.1466206, 5: 0.29596075}\n",
      "145 {0: 0.15250777, 1: 0.069944, 2: 0.06780403, 3: 0.15253061, 4: 0.06780365, 5: 0.48940995}\n",
      "146 {0: 0.11764817, 1: 0.117647834, 2: 0.11764819, 3: 0.11764819, 4: 0.41175938, 5: 0.11764824}\n",
      "147 {0: 0.01709881, 1: 0.7391376, 2: 0.0403401, 3: 0.08114395, 4: 0.019312933, 5: 0.10296667}\n",
      "148 {0: 0.09092562, 1: 0.24933723, 2: 0.30165076, 3: 0.090925194, 4: 0.09092491, 5: 0.17623629}\n",
      "149 {0: 0.1379445, 1: 0.31027865, 2: 0.13794427, 3: 0.13794388, 4: 0.13794377, 5: 0.13794492}\n",
      "150 {0: 0.20290203, 1: 0.22336063, 2: 0.2548902, 3: 0.20288354, 4: 0.057981305, 5: 0.057982292}\n",
      "151 {0: 0.107937045, 1: 0.043650746, 2: 0.20212545, 3: 0.20105883, 4: 0.22226058, 5: 0.22296734}\n",
      "152 {0: 0.07408088, 1: 0.1956697, 2: 0.07408094, 3: 0.33762163, 4: 0.07408058, 5: 0.24446629}\n",
      "153 {0: 0.07408807, 1: 0.16657795, 2: 0.1666784, 3: 0.07408775, 4: 0.35190645, 5: 0.16666141}\n",
      "154 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "155 {0: 0.090921134, 1: 0.09091742, 2: 0.20451568, 3: 0.20451637, 4: 0.090920985, 5: 0.3182084}\n",
      "156 {0: 0.13044319, 1: 0.22754137, 2: 0.05798718, 3: 0.2753775, 4: 0.17820835, 5: 0.13044241}\n",
      "157 {0: 0.05406748, 1: 0.12151163, 2: 0.25680757, 3: 0.18919827, 4: 0.32434714, 5: 0.05406793}\n",
      "158 {0: 0.26472268, 1: 0.11765233, 2: 0.117654644, 3: 0.11765462, 4: 0.117654674, 5: 0.26466107}\n",
      "159 {0: 0.13100728, 1: 0.19976059, 2: 0.2666153, 3: 0.039187, 4: 0.22307886, 5: 0.140351}\n",
      "160 {0: 0.07808656, 1: 0.19398008, 2: 0.06323696, 3: 0.23198467, 4: 0.33199888, 5: 0.10071285}\n",
      "161 {0: 0.318194, 1: 0.1496205, 2: 0.090920135, 3: 0.20450935, 4: 0.090919174, 5: 0.1458368}\n",
      "162 {0: 0.14145769, 1: 0.05189855, 2: 0.17722787, 3: 0.23194696, 4: 0.34304196, 5: 0.054426957}\n",
      "163 {0: 0.3070855, 1: 0.10199966, 2: 0.09091712, 3: 0.09091703, 4: 0.09091678, 5: 0.31816393}\n",
      "164 {0: 0.06780542, 1: 0.06809914, 2: 0.15251645, 3: 0.1630003, 4: 0.4790442, 5: 0.06953452}\n",
      "165 {0: 0.06848539, 1: 0.15251552, 2: 0.23728678, 3: 0.06780716, 4: 0.32142428, 5: 0.15248093}\n",
      "166 {0: 0.17970814, 1: 0.05646012, 2: 0.28455922, 3: 0.3233468, 4: 0.1071159, 5: 0.048809808}\n",
      "167 {0: 0.09091548, 1: 0.09091352, 2: 0.31816915, 3: 0.09091547, 4: 0.090915315, 5: 0.31817105}\n",
      "168 {0: 0.13794456, 1: 0.31027514, 2: 0.13794518, 3: 0.13794495, 4: 0.1379446, 5: 0.13794559}\n",
      "169 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "170 {0: 0.12164134, 1: 0.054060336, 2: 0.054063056, 3: 0.25674418, 4: 0.3918951, 5: 0.12159603}\n",
      "171 {0: 0.104687355, 1: 0.45196027, 2: 0.081640884, 3: 0.096391425, 4: 0.18367888, 5: 0.081641234}\n",
      "172 {0: 0.15707816, 1: 0.17800984, 2: 0.07408726, 3: 0.25927052, 4: 0.24441114, 5: 0.08714306}\n",
      "173 {0: 0.20453075, 1: 0.31815994, 2: 0.090924814, 3: 0.09092451, 4: 0.2045344, 5: 0.09092557}\n",
      "174 {0: 0.117654875, 1: 0.12384835, 2: 0.2585007, 3: 0.2646864, 4: 0.117654584, 5: 0.117655076}\n",
      "175 {0: 0.11764858, 1: 0.11764811, 2: 0.117648594, 3: 0.11764859, 4: 0.41175747, 5: 0.1176487}\n",
      "176 {0: 0.06250187, 1: 0.06250133, 2: 0.06316385, 3: 0.06250191, 4: 0.68030244, 5: 0.06902861}\n",
      "177 {0: 0.13458876, 1: 0.040129386, 2: 0.084917344, 3: 0.34275407, 4: 0.35237345, 5: 0.04523701}\n",
      "178 {0: 0.17582385, 1: 0.09337635, 2: 0.23326589, 3: 0.09091655, 4: 0.20456232, 5: 0.20205508}\n",
      "179 {0: 0.26469064, 1: 0.24384849, 2: 0.11766677, 3: 0.11766635, 4: 0.13845992, 5: 0.11766784}\n",
      "180 {0: 0.06700933, 1: 0.04986979, 2: 0.55990857, 3: 0.10715398, 4: 0.10706709, 5: 0.108991235}\n",
      "181 {0: 0.090921685, 1: 0.090917885, 2: 0.31816444, 3: 0.09092184, 4: 0.31815156, 5: 0.09092259}\n",
      "182 {0: 0.24510323, 1: 0.21340983, 2: 0.09092042, 3: 0.09092025, 4: 0.26872548, 5: 0.09092082}\n",
      "183 {0: 0.09502832, 1: 0.15387449, 2: 0.035234082, 3: 0.20148116, 4: 0.4306752, 5: 0.08370671}\n",
      "184 {0: 0.12836978, 1: 0.08535203, 2: 0.21725202, 3: 0.08256391, 4: 0.03670751, 5: 0.44975471}\n",
      "185 {0: 0.6057786, 1: 0.13062042, 2: 0.059204653, 3: 0.054057736, 4: 0.09628068, 5: 0.054057952}\n",
      "186 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "187 {0: 0.117654264, 1: 0.117652036, 2: 0.41173038, 3: 0.11765436, 4: 0.11765423, 5: 0.1176547}\n",
      "188 {0: 0.33689854, 1: 0.06921827, 2: 0.30808204, 3: 0.020988427, 4: 0.044020455, 5: 0.22079228}\n",
      "189 {0: 0.22828822, 1: 0.41966227, 2: 0.10712607, 3: 0.08164101, 4: 0.081640854, 5: 0.0816416}\n",
      "190 {0: 0.11764869, 1: 0.11764819, 2: 0.11764874, 3: 0.41175693, 4: 0.11764868, 5: 0.11764879}\n",
      "191 {0: 0.06250524, 1: 0.06250367, 2: 0.14495113, 3: 0.14062352, 4: 0.3706481, 5: 0.21876836}\n",
      "192 {0: 0.074082926, 1: 0.078548394, 2: 0.074083045, 3: 0.16664894, 4: 0.35189316, 5: 0.25474352}\n",
      "193 {0: 0.19301288, 1: 0.17469853, 2: 0.16776526, 3: 0.07144703, 4: 0.057988014, 5: 0.3350883}\n",
      "194 {0: 0.09091571, 1: 0.090913706, 2: 0.09091588, 3: 0.09091582, 4: 0.20451535, 5: 0.4318235}\n",
      "195 {0: 0.15662938, 1: 0.15242621, 2: 0.06781016, 3: 0.3220402, 4: 0.19986969, 5: 0.10122433}\n",
      "196 {0: 0.102571614, 1: 0.1025691, 2: 0.10257153, 3: 0.2307715, 4: 0.3589445, 5: 0.10257175}\n",
      "197 {0: 0.06780245, 1: 0.6609875, 2: 0.06780252, 3: 0.06780242, 4: 0.06780231, 5: 0.067802764}\n",
      "198 {0: 0.08164588, 1: 0.085781865, 2: 0.27085078, 3: 0.28566065, 4: 0.08164563, 5: 0.19441521}\n",
      "199 {0: 0.13793485, 1: 0.13793367, 2: 0.31032714, 3: 0.1379347, 4: 0.13793465, 5: 0.13793498}\n",
      "200 {0: 0.10256914, 1: 0.10256756, 2: 0.23074041, 3: 0.10256902, 4: 0.10256892, 5: 0.35898495}\n",
      "201 {0: 0.30928499, 1: 0.12392219, 2: 0.21383543, 3: 0.11765237, 4: 0.11765232, 5: 0.11765271}\n",
      "202 {0: 0.0740807, 1: 0.07407866, 2: 0.16660771, 3: 0.074080765, 4: 0.085294545, 5: 0.5258576}\n",
      "203 {0: 0.08164676, 1: 0.18686752, 2: 0.18365294, 3: 0.35181263, 4: 0.10860714, 5: 0.08741306}\n",
      "204 {0: 0.4795329, 1: 0.05905489, 2: 0.109654635, 3: 0.1426682, 4: 0.100594334, 5: 0.10849509}\n",
      "205 {0: 0.21881731, 1: 0.29685748, 2: 0.140581, 3: 0.14062926, 4: 0.14059317, 5: 0.062521815}\n",
      "206 {0: 0.23355602, 1: 0.25179118, 2: 0.1046458, 3: 0.091903225, 4: 0.25861874, 5: 0.059485074}\n",
      "207 {0: 0.04255955, 1: 0.04413274, 2: 0.6115199, 3: 0.042559505, 4: 0.063848816, 5: 0.19537951}\n",
      "208 {0: 0.27106625, 1: 0.11418492, 2: 0.3070235, 3: 0.10257495, 4: 0.10257469, 5: 0.10257569}\n",
      "209 {0: 0.16026574, 1: 0.10257104, 2: 0.10257416, 3: 0.42944115, 4: 0.10257353, 5: 0.10257437}\n",
      "210 {0: 0.11765115, 1: 0.117649905, 2: 0.117651224, 3: 0.117651194, 4: 0.4117451, 5: 0.117651395}\n",
      "211 {0: 0.05798384, 1: 0.13027523, 2: 0.13041344, 3: 0.5653592, 4: 0.05798372, 5: 0.057984635}\n",
      "212 {0: 0.20454629, 1: 0.09091873, 2: 0.090923, 3: 0.3181476, 4: 0.20454048, 5: 0.09092385}\n",
      "213 {0: 0.20451601, 1: 0.1565633, 2: 0.09092963, 3: 0.20456836, 4: 0.25249228, 5: 0.09093039}\n",
      "214 {0: 0.053997137, 1: 0.0856236, 2: 0.19517593, 3: 0.22670448, 4: 0.11467761, 5: 0.32382128}\n",
      "215 {0: 0.07560793, 1: 0.18071342, 2: 0.20171233, 3: 0.11761886, 4: 0.0849048, 5: 0.33944267}\n",
      "216 {0: 0.102578685, 1: 0.12428499, 2: 0.230784, 3: 0.1025787, 4: 0.20903659, 5: 0.23073702}\n",
      "217 {0: 0.07894181, 1: 0.34222093, 2: 0.2544074, 3: 0.03509687, 4: 0.07887065, 5: 0.21046238}\n",
      "218 {0: 0.2306836, 1: 0.10257133, 2: 0.102574684, 3: 0.10257465, 4: 0.3590206, 5: 0.10257514}\n",
      "219 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "220 {0: 0.11765478, 1: 0.117652446, 2: 0.1176549, 3: 0.26468155, 4: 0.2647012, 5: 0.117655136}\n",
      "221 {0: 0.10714938, 1: 0.05068663, 2: 0.10711804, 3: 0.22618376, 4: 0.3422283, 5: 0.16663383}\n",
      "222 {0: 0.08164135, 1: 0.08163861, 2: 0.18366303, 3: 0.08164114, 4: 0.28567663, 5: 0.2857392}\n",
      "223 {0: 0.038469244, 1: 0.03912744, 2: 0.040387046, 3: 0.19201677, 4: 0.25488478, 5: 0.4351147}\n",
      "224 {0: 0.23069969, 1: 0.10257051, 2: 0.102573425, 3: 0.102573164, 4: 0.23079132, 5: 0.2307919}\n",
      "225 {0: 0.10257535, 1: 0.23076293, 2: 0.10257557, 3: 0.23076555, 4: 0.10257521, 5: 0.2307454}\n",
      "226 {0: 0.062511034, 1: 0.21874048, 2: 0.16199072, 3: 0.0625109, 4: 0.2755193, 5: 0.21872753}\n",
      "227 {0: 0.10257188, 1: 0.10256935, 2: 0.10257179, 3: 0.23071685, 4: 0.10257131, 5: 0.35899878}\n",
      "228 {0: 0.17721105, 1: 0.050637, 2: 0.1139196, 3: 0.5569547, 4: 0.050638612, 5: 0.050639022}\n",
      "229 {0: 0.09164856, 1: 0.090916514, 2: 0.09091639, 3: 0.090916276, 4: 0.5203205, 5: 0.11528178}\n",
      "230 {0: 0.034205392, 1: 0.047007572, 2: 0.37349305, 3: 0.1531784, 4: 0.2298549, 5: 0.16226065}\n",
      "231 {0: 0.050637893, 1: 0.051488232, 2: 0.11390341, 3: 0.34167722, 4: 0.38974282, 5: 0.052550375}\n",
      "232 {0: 0.19377436, 1: 0.30779868, 2: 0.07055428, 3: 0.18915601, 4: 0.18464954, 5: 0.054067113}\n",
      "233 {0: 0.11764927, 1: 0.117648594, 2: 0.11764934, 3: 0.11764931, 4: 0.117649235, 5: 0.41175422}\n",
      "234 {0: 0.13793522, 1: 0.1379339, 2: 0.13793534, 3: 0.13793531, 4: 0.31032473, 5: 0.1379355}\n",
      "235 {0: 0.28576648, 1: 0.28563258, 2: 0.08164799, 3: 0.1836568, 4: 0.081647575, 5: 0.08164857}\n",
      "236 {0: 0.067811705, 1: 0.07582155, 2: 0.22922418, 3: 0.15253823, 4: 0.2372601, 5: 0.23734422}\n",
      "237 {0: 0.046374146, 1: 0.73455065, 2: 0.027288407, 3: 0.072124414, 4: 0.072164126, 5: 0.04749822}\n",
      "238 {0: 0.13794456, 1: 0.3102751, 2: 0.13794518, 3: 0.13794497, 4: 0.1379446, 5: 0.13794559}\n",
      "239 {0: 0.32165363, 1: 0.30374834, 2: 0.05064043, 3: 0.113930635, 4: 0.13098578, 5: 0.07904115}\n",
      "240 {0: 0.057979286, 1: 0.058235556, 2: 0.13042454, 3: 0.45694858, 4: 0.23692153, 5: 0.05949052}\n",
      "241 {0: 0.090921976, 1: 0.31821868, 2: 0.09092228, 3: 0.20452555, 4: 0.09092183, 5: 0.20448975}\n",
      "242 {0: 0.081642434, 1: 0.08386128, 2: 0.08164259, 3: 0.48755482, 4: 0.18365589, 5: 0.08164298}\n",
      "243 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "244 {0: 0.10841102, 1: 0.20445406, 2: 0.0909246, 3: 0.41436145, 4: 0.09092389, 5: 0.090925}\n",
      "245 {0: 0.14147747, 1: 0.137932, 2: 0.13793243, 3: 0.13793242, 4: 0.30679315, 5: 0.1379325}\n",
      "246 {0: 0.10258021, 1: 0.23072809, 2: 0.12911741, 3: 0.10257976, 4: 0.23075944, 5: 0.2042351}\n",
      "247 {0: 0.090915374, 1: 0.09091347, 2: 0.3181542, 3: 0.20454319, 4: 0.20455803, 5: 0.090915754}\n",
      "248 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "249 {0: 0.11765306, 1: 0.11765132, 2: 0.11765316, 3: 0.11765315, 4: 0.41173586, 5: 0.1176535}\n",
      "250 {0: 0.0587655, 1: 0.25635925, 2: 0.05815075, 3: 0.3121189, 4: 0.26965183, 5: 0.044953723}\n",
      "251 {0: 0.06781084, 1: 0.16468325, 2: 0.31821442, 3: 0.06781066, 4: 0.31073835, 5: 0.07074248}\n",
      "252 {0: 0.0206217, 1: 0.022990577, 2: 0.16950524, 3: 0.046307366, 4: 0.022227727, 5: 0.7183474}\n",
      "253 {0: 0.12151741, 1: 0.05406336, 2: 0.0540674, 3: 0.3919612, 4: 0.2567797, 5: 0.12161096}\n",
      "254 {0: 0.13793853, 1: 0.31030703, 2: 0.13793865, 3: 0.13793847, 4: 0.13793825, 5: 0.13793904}\n",
      "255 {0: 0.063781224, 1: 0.06598015, 2: 0.06250843, 3: 0.29688308, 4: 0.29562846, 5: 0.21521863}\n",
      "256 {0: 0.09091288, 1: 0.09452875, 2: 0.09091303, 3: 0.09091288, 4: 0.09762857, 5: 0.53510386}\n",
      "257 {0: 0.11391462, 1: 0.43039352, 2: 0.050644558, 3: 0.24055246, 4: 0.050643988, 5: 0.11385085}\n",
      "258 {0: 0.23753493, 1: 0.5251262, 2: 0.046327855, 3: 0.101111054, 4: 0.04494973, 5: 0.044950236}\n",
      "259 {0: 0.090914845, 1: 0.09195485, 2: 0.19512768, 3: 0.39251077, 4: 0.1213808, 5: 0.1081111}\n",
      "260 {0: 0.11765884, 1: 0.120842166, 2: 0.117658906, 3: 0.26467243, 4: 0.117658116, 5: 0.2615095}\n",
      "261 {0: 0.25957114, 1: 0.036293093, 2: 0.027782377, 3: 0.46310872, 4: 0.08340862, 5: 0.12983607}\n",
      "262 {0: 0.13044676, 1: 0.49274364, 2: 0.057977356, 3: 0.057977155, 4: 0.19291145, 5: 0.06794364}\n",
      "263 {0: 0.10257391, 1: 0.102570765, 2: 0.35897824, 3: 0.23072943, 4: 0.102573305, 5: 0.10257438}\n",
      "264 {0: 0.100171804, 1: 0.20534371, 2: 0.25536895, 3: 0.042568225, 4: 0.17825304, 5: 0.21829426}\n",
      "265 {0: 0.08164549, 1: 0.38775948, 2: 0.08164533, 3: 0.08164517, 4: 0.1836363, 5: 0.18366827}\n",
      "266 {0: 0.24795265, 1: 0.16713826, 2: 0.074130476, 3: 0.3572086, 4: 0.09114616, 5: 0.06242382}\n",
      "267 {0: 0.42994067, 1: 0.10430922, 2: 0.050060667, 3: 0.26967373, 4: 0.10106237, 5: 0.044953316}\n",
      "268 {0: 0.26471266, 1: 0.117656864, 2: 0.11766101, 3: 0.1176609, 4: 0.14833103, 5: 0.23397756}\n",
      "269 {0: 0.43045148, 1: 0.050638404, 2: 0.11390552, 3: 0.050640754, 4: 0.126715, 5: 0.22764887}\n",
      "270 {0: 0.204535, 1: 0.2044601, 2: 0.09092714, 3: 0.090926796, 4: 0.09092647, 5: 0.3182245}\n",
      "271 {0: 0.07965496, 1: 0.5392866, 2: 0.09296875, 3: 0.1524762, 4: 0.06780639, 5: 0.067807116}\n",
      "272 {0: 0.10257615, 1: 0.23072828, 2: 0.102576286, 3: 0.23075044, 4: 0.13600408, 5: 0.19736478}\n",
      "273 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "274 {0: 0.08164877, 1: 0.18362711, 2: 0.28572217, 3: 0.18370497, 4: 0.18364725, 5: 0.081649765}\n",
      "275 {0: 0.38347834, 1: 0.08163867, 2: 0.0859283, 3: 0.28567183, 4: 0.081641115, 5: 0.08164171}\n",
      "276 {0: 0.09091219, 1: 0.09091124, 2: 0.09091221, 3: 0.09091217, 4: 0.090912126, 5: 0.5454401}\n",
      "277 {0: 0.26274914, 1: 0.15246964, 2: 0.29660228, 3: 0.06780649, 4: 0.067806326, 5: 0.15256613}\n",
      "278 {0: 0.09092077, 1: 0.09091724, 2: 0.20446452, 3: 0.09092078, 4: 0.43185535, 5: 0.09092135}\n",
      "279 {0: 0.031293098, 1: 0.034015216, 2: 0.32420528, 3: 0.32719874, 4: 0.17889155, 5: 0.10439605}\n",
      "280 {0: 0.067807235, 1: 0.06780406, 2: 0.06780746, 3: 0.3220333, 4: 0.15247732, 5: 0.32207066}\n",
      "281 {0: 0.16934606, 1: 0.047624588, 2: 0.049307607, 3: 0.047627006, 4: 0.2261872, 5: 0.45990756}\n",
      "282 {0: 0.081640646, 1: 0.0852244, 2: 0.2821225, 3: 0.08164051, 4: 0.38773096, 5: 0.08164101}\n",
      "283 {0: 0.13793486, 1: 0.1379336, 2: 0.31032708, 3: 0.13793479, 4: 0.13793471, 5: 0.13793495}\n",
      "284 {0: 0.081644185, 1: 0.2133349, 2: 0.18367597, 3: 0.35805616, 4: 0.081643865, 5: 0.08164498}\n",
      "285 {0: 0.090918206, 1: 0.43179536, 2: 0.09091846, 3: 0.09091816, 4: 0.09091783, 5: 0.20453201}\n",
      "286 {0: 0.15361677, 1: 0.28353804, 2: 0.17972887, 3: 0.22624248, 4: 0.049774442, 5: 0.10709943}\n",
      "287 {0: 0.090916425, 1: 0.5454178, 2: 0.090916544, 3: 0.090916306, 4: 0.090916164, 5: 0.0909168}\n",
      "288 {0: 0.1525022, 1: 0.18082185, 2: 0.06781005, 3: 0.29375666, 4: 0.23729853, 5: 0.06781071}\n",
      "289 {0: 0.19245353, 1: 0.32860607, 2: 0.067803666, 3: 0.13282534, 4: 0.15146558, 5: 0.12684584}\n",
      "290 {0: 0.26053512, 1: 0.09091585, 2: 0.25964883, 3: 0.093467556, 4: 0.09091875, 5: 0.20451385}\n",
      "291 {0: 0.061519444, 1: 0.042694043, 2: 0.0425591, 3: 0.100383624, 4: 0.28711894, 5: 0.4657249}\n",
      "292 {0: 0.03144105, 1: 0.03994241, 2: 0.2404792, 3: 0.19693612, 4: 0.04101527, 5: 0.45018598}\n",
      "293 {0: 0.13793994, 1: 0.31030026, 2: 0.13794024, 3: 0.13793963, 4: 0.13793959, 5: 0.13794036}\n",
      "294 {0: 0.06252128, 1: 0.18017688, 2: 0.100916184, 3: 0.29697564, 4: 0.21879263, 5: 0.14061736}\n",
      "295 {0: 0.15728435, 1: 0.2789285, 2: 0.046844903, 3: 0.101038925, 4: 0.044954266, 5: 0.37094906}\n",
      "296 {0: 0.13793698, 1: 0.13793522, 2: 0.13793708, 3: 0.31031635, 4: 0.13793701, 5: 0.13793738}\n",
      "297 {0: 0.16662484, 1: 0.17786111, 2: 0.16668147, 3: 0.07408845, 4: 0.24806516, 5: 0.16667897}\n",
      "298 {0: 0.10256896, 1: 0.10256745, 2: 0.10256907, 3: 0.35894707, 4: 0.23077814, 5: 0.102569304}\n",
      "299 {0: 0.10257024, 1: 0.102568574, 2: 0.10257038, 3: 0.10257021, 4: 0.35900083, 5: 0.23071976}\n",
      "300 {0: 0.06780367, 1: 0.32202435, 2: 0.067803755, 3: 0.21788856, 4: 0.25667563, 5: 0.06780405}\n",
      "301 {0: 0.10257577, 1: 0.10257217, 2: 0.23075327, 3: 0.35894683, 4: 0.10257557, 5: 0.10257639}\n",
      "302 {0: 0.24488746, 1: 0.03846632, 2: 0.18265653, 3: 0.4231069, 4: 0.072414, 5: 0.038468778}\n",
      "303 {0: 0.07554827, 1: 0.42027682, 2: 0.05797977, 3: 0.1852778, 4: 0.05797924, 5: 0.20293806}\n",
      "304 {0: 0.26470575, 1: 0.11765221, 2: 0.11765418, 3: 0.11765412, 4: 0.21963276, 5: 0.16270103}\n",
      "305 {0: 0.074712336, 1: 0.07408179, 2: 0.07408384, 3: 0.1666091, 4: 0.4045586, 5: 0.20595433}\n",
      "306 {0: 0.14145581, 1: 0.13793199, 2: 0.13793243, 3: 0.13793242, 4: 0.30681485, 5: 0.1379325}\n",
      "307 {0: 0.10256777, 1: 0.10256657, 2: 0.102567635, 3: 0.4871627, 4: 0.102567494, 5: 0.102567784}\n",
      "308 {0: 0.21515557, 1: 0.10257081, 2: 0.11817638, 3: 0.10257359, 4: 0.34138384, 5: 0.12013982}\n",
      "309 {0: 0.2044539, 1: 0.09091585, 2: 0.09091895, 3: 0.09091887, 4: 0.09091858, 5: 0.43187386}\n",
      "310 {0: 0.038470358, 1: 0.4338675, 2: 0.13461936, 3: 0.17197312, 4: 0.0864823, 5: 0.13458738}\n",
      "311 {0: 0.11763229, 1: 0.14928983, 2: 0.40350515, 3: 0.117613964, 4: 0.03362324, 5: 0.17833558}\n",
      "312 {0: 0.035959516, 1: 0.18442182, 2: 0.32770845, 3: 0.069760926, 4: 0.031011976, 5: 0.3511373}\n",
      "313 {0: 0.13793176, 1: 0.13793154, 2: 0.13793178, 3: 0.13793178, 4: 0.31034136, 5: 0.13793181}\n",
      "314 {0: 0.21512727, 1: 0.33431423, 2: 0.07093144, 3: 0.11980754, 4: 0.16143066, 5: 0.09838889}\n",
      "315 {0: 0.06780307, 1: 0.40676773, 2: 0.06780303, 3: 0.06780294, 4: 0.32201985, 5: 0.06780337}\n",
      "316 {0: 0.09092209, 1: 0.101356275, 2: 0.1940565, 3: 0.0909218, 4: 0.31822264, 5: 0.20452075}\n",
      "317 {0: 0.06251081, 1: 0.063462034, 2: 0.2088958, 3: 0.29591316, 4: 0.21876329, 5: 0.15045488}\n",
      "318 {0: 0.090911, 1: 0.09091041, 2: 0.09091103, 3: 0.090911, 4: 0.09091098, 5: 0.54544556}\n",
      "319 {0: 0.0816439, 1: 0.2755897, 2: 0.09171834, 3: 0.18368116, 4: 0.28572223, 5: 0.08164464}\n",
      "320 {0: 0.117660716, 1: 0.11765642, 2: 0.11766153, 3: 0.2646881, 4: 0.2646716, 5: 0.11766164}\n",
      "321 {0: 0.179778, 1: 0.4841574, 2: 0.035727885, 3: 0.013438634, 4: 0.02212469, 5: 0.26477334}\n",
      "322 {0: 0.11556187, 1: 0.06411492, 2: 0.12659952, 3: 0.054860797, 4: 0.02508891, 5: 0.61377394}\n",
      "323 {0: 0.11765593, 1: 0.11765329, 2: 0.2541433, 3: 0.26465374, 4: 0.117655784, 5: 0.12823793}\n",
      "324 {0: 0.17046863, 1: 0.03358801, 2: 0.31638804, 3: 0.30236325, 4: 0.14617725, 5: 0.031014822}\n",
      "325 {0: 0.017472435, 1: 0.047806043, 2: 0.2172385, 3: 0.16850254, 4: 0.2254981, 5: 0.32348242}\n",
      "326 {0: 0.41175526, 1: 0.11764845, 2: 0.11764908, 3: 0.11764903, 4: 0.117649, 5: 0.117649175}\n",
      "327 {0: 0.120834604, 1: 0.05063897, 2: 0.4234066, 3: 0.050641354, 4: 0.050641075, 5: 0.30383736}\n",
      "328 {0: 0.05406573, 1: 0.05995802, 2: 0.32242516, 3: 0.2083892, 4: 0.23125431, 5: 0.12390762}\n",
      "329 {0: 0.07408401, 1: 0.16796929, 2: 0.074084304, 3: 0.07819251, 4: 0.43071955, 5: 0.17495035}\n",
      "330 {0: 0.43187845, 1: 0.20444256, 2: 0.09091981, 3: 0.090919495, 4: 0.09091939, 5: 0.09092032}\n",
      "331 {0: 0.08164443, 1: 0.0816408, 2: 0.28566688, 3: 0.38775814, 4: 0.081644215, 5: 0.081645474}\n",
      "332 {0: 0.13793455, 1: 0.310327, 2: 0.13793461, 3: 0.13793458, 4: 0.13793448, 5: 0.1379348}\n",
      "333 {0: 0.17066923, 1: 0.35291618, 2: 0.16833003, 3: 0.07893209, 4: 0.16133761, 5: 0.06781488}\n",
      "334 {0: 0.06960971, 1: 0.32259616, 2: 0.14598672, 3: 0.06250448, 4: 0.26375046, 5: 0.13555251}\n",
      "335 {0: 0.20457418, 1: 0.09091713, 2: 0.10224384, 3: 0.20452489, 4: 0.09092049, 5: 0.3068195}\n",
      "336 {0: 0.11765989, 1: 0.2646835, 2: 0.117659554, 3: 0.11765938, 4: 0.2646774, 5: 0.11766021}\n",
      "337 {0: 0.08163612, 1: 0.08521587, 2: 0.2821056, 3: 0.08163616, 4: 0.38777, 5: 0.08163628}\n",
      "338 {0: 0.1379327, 1: 0.13793218, 2: 0.13793275, 3: 0.3103369, 4: 0.13793269, 5: 0.13793279}\n",
      "339 {0: 0.08163962, 1: 0.08493597, 2: 0.18032274, 3: 0.08163968, 4: 0.48982203, 5: 0.08163998}\n",
      "340 {0: 0.102576464, 1: 0.10486866, 2: 0.35669535, 3: 0.23070596, 4: 0.10257623, 5: 0.10257732}\n",
      "341 {0: 0.064145006, 1: 0.0628933, 2: 0.2744697, 3: 0.062504895, 4: 0.06250474, 5: 0.4734824}\n",
      "342 {0: 0.14064199, 1: 0.06250573, 2: 0.25216624, 3: 0.107837014, 4: 0.25152582, 5: 0.1853232}\n",
      "343 {0: 0.15145122, 1: 0.044261705, 2: 0.09391662, 3: 0.04596811, 4: 0.30625206, 5: 0.35815027}\n",
      "344 {0: 0.07407923, 1: 0.07579064, 2: 0.07407912, 3: 0.16663088, 4: 0.07407892, 5: 0.53534126}\n",
      "345 {0: 0.11765963, 1: 0.11765583, 2: 0.26466087, 3: 0.26470357, 4: 0.11765945, 5: 0.117660604}\n",
      "346 {0: 0.20446472, 1: 0.09091516, 2: 0.090917915, 3: 0.09091766, 4: 0.09091742, 5: 0.43186712}\n",
      "347 {0: 0.20455453, 1: 0.090917654, 2: 0.09092177, 3: 0.09092162, 4: 0.2045085, 5: 0.318176}\n",
      "348 {0: 0.14796866, 1: 0.22320127, 2: 0.1406005, 3: 0.07112324, 4: 0.3499319, 5: 0.0671744}\n",
      "349 {0: 0.14140426, 1: 0.040766478, 2: 0.24241847, 3: 0.14135242, 4: 0.34319246, 5: 0.090865955}\n",
      "350 {0: 0.2630017, 1: 0.17794918, 2: 0.18625356, 3: 0.15015629, 4: 0.04881353, 5: 0.17382577}\n",
      "351 {0: 0.21877477, 1: 0.06598637, 2: 0.21870027, 3: 0.2952015, 4: 0.06251282, 5: 0.13882427}\n",
      "352 {0: 0.11765428, 1: 0.41172814, 2: 0.1176546, 3: 0.11765425, 4: 0.11765405, 5: 0.11765472}\n",
      "353 {0: 0.09123657, 1: 0.41318807, 2: 0.25065002, 3: 0.081641704, 4: 0.08164143, 5: 0.08164225}\n",
      "354 {0: 0.13793369, 1: 0.13793291, 2: 0.31033248, 3: 0.13793364, 4: 0.13793354, 5: 0.13793378}\n",
      "355 {0: 0.35933098, 1: 0.068363406, 2: 0.38400745, 3: 0.06250757, 4: 0.062507346, 5: 0.06328323}\n",
      "356 {0: 0.12485911, 1: 0.1302831, 2: 0.06359375, 3: 0.20290703, 4: 0.2029148, 5: 0.2754422}\n",
      "357 {0: 0.102571934, 1: 0.10256952, 2: 0.35894328, 3: 0.10257183, 4: 0.10257174, 5: 0.23077169}\n",
      "358 {0: 0.074087225, 1: 0.0740832, 2: 0.25922817, 3: 0.16667596, 4: 0.25931257, 5: 0.16661282}\n",
      "359 {0: 0.25375348, 1: 0.151297, 2: 0.12345677, 3: 0.057623018, 4: 0.09011392, 5: 0.32375583}\n",
      "360 {0: 0.15256245, 1: 0.07081606, 2: 0.17887133, 3: 0.0678052, 4: 0.46213916, 5: 0.06780579}\n",
      "361 {0: 0.074079946, 1: 0.07463404, 2: 0.0740797, 3: 0.07998317, 4: 0.21465133, 5: 0.48257184}\n",
      "362 {0: 0.18369265, 1: 0.08163868, 2: 0.18366407, 3: 0.3877216, 4: 0.08164109, 5: 0.08164192}\n",
      "363 {0: 0.16244528, 1: 0.57265174, 2: 0.03361994, 3: 0.0352833, 4: 0.15684123, 5: 0.039158538}\n",
      "364 {0: 0.08298785, 1: 0.07796271, 2: 0.07408377, 3: 0.25532135, 4: 0.43556008, 5: 0.074084185}\n",
      "365 {0: 0.10257795, 1: 0.11435475, 2: 0.3589416, 3: 0.10257779, 4: 0.10257763, 5: 0.21897024}\n",
      "366 {0: 0.08728399, 1: 0.074079365, 2: 0.44443902, 3: 0.07408162, 4: 0.074081406, 5: 0.24603458}\n",
      "367 {0: 0.18450554, 1: 0.32938778, 2: 0.23187807, 3: 0.054064706, 4: 0.054064356, 5: 0.14609954}\n",
      "368 {0: 0.08284309, 1: 0.05512076, 2: 0.056932848, 3: 0.35523838, 4: 0.25451058, 5: 0.19535433}\n",
      "369 {0: 0.21749571, 1: 0.28213966, 2: 0.017358845, 3: 0.21518019, 4: 0.11969042, 5: 0.14813516}\n",
      "370 {0: 0.117665194, 1: 0.12917623, 2: 0.2531564, 3: 0.26467115, 4: 0.11766481, 5: 0.11766622}\n",
      "371 {0: 0.05863855, 1: 0.20284897, 2: 0.05798236, 3: 0.20290188, 4: 0.24656163, 5: 0.23106661}\n",
      "372 {0: 0.13793711, 1: 0.3103145, 2: 0.13793707, 3: 0.13793693, 4: 0.13793696, 5: 0.13793737}\n",
      "373 {0: 0.20292623, 1: 0.3478295, 2: 0.16991052, 3: 0.13040598, 4: 0.057981834, 5: 0.0909459}\n",
      "374 {0: 0.16659962, 1: 0.07408272, 2: 0.35183892, 3: 0.074086145, 4: 0.22384423, 5: 0.109548345}\n",
      "375 {0: 0.102567054, 1: 0.10256615, 2: 0.102567114, 3: 0.102567084, 4: 0.23077191, 5: 0.35896066}\n",
      "376 {0: 0.07408084, 1: 0.07447525, 2: 0.07408118, 3: 0.3875045, 4: 0.31344438, 5: 0.076413855}\n",
      "377 {0: 0.19456474, 1: 0.17512135, 2: 0.21871784, 3: 0.13027912, 4: 0.21880332, 5: 0.062513605}\n",
      "378 {0: 0.14145671, 1: 0.13793199, 2: 0.13793243, 3: 0.13793242, 4: 0.30681396, 5: 0.1379325}\n",
      "379 {0: 0.13793522, 1: 0.13793395, 2: 0.13793534, 3: 0.29619184, 4: 0.15206803, 5: 0.13793556}\n",
      "380 {0: 0.25528818, 1: 0.06434646, 2: 0.18034483, 3: 0.14059736, 4: 0.29690802, 5: 0.062515154}\n",
      "381 {0: 0.0816437, 1: 0.18355764, 2: 0.08164396, 3: 0.08164354, 4: 0.18368815, 5: 0.38782305}\n",
      "382 {0: 0.32742608, 1: 0.47839636, 2: 0.02378313, 3: 0.02321555, 4: 0.038021576, 5: 0.109157376}\n",
      "383 {0: 0.09091535, 1: 0.54542315, 2: 0.09091548, 3: 0.09091526, 4: 0.09091507, 5: 0.09091567}\n",
      "384 {0: 0.1176548, 1: 0.12302992, 2: 0.117654674, 3: 0.11765451, 4: 0.4063511, 5: 0.117655024}\n",
      "385 {0: 0.3182, 1: 0.090919584, 2: 0.11222463, 3: 0.090923965, 4: 0.24828678, 5: 0.13944502}\n",
      "386 {0: 0.204523, 1: 0.09091399, 2: 0.43181455, 3: 0.09091619, 4: 0.09091588, 5: 0.09091641}\n",
      "387 {0: 0.10465424, 1: 0.10256483, 2: 0.10256517, 3: 0.102565154, 4: 0.4850854, 5: 0.102565214}\n",
      "388 {0: 0.059545733, 1: 0.13619919, 2: 0.17762356, 3: 0.20754318, 4: 0.0923329, 5: 0.32675546}\n",
      "389 {0: 0.13793209, 1: 0.13793176, 2: 0.13793212, 3: 0.13793209, 4: 0.13793206, 5: 0.31033984}\n",
      "390 {0: 0.26466095, 1: 0.11765591, 2: 0.11765983, 3: 0.117659636, 4: 0.117659576, 5: 0.26470408}\n",
      "391 {0: 0.121589035, 1: 0.061935827, 2: 0.25248298, 3: 0.3874247, 4: 0.121590726, 5: 0.05497672}\n",
      "392 {0: 0.11765371, 1: 0.117651686, 2: 0.11765378, 3: 0.2646779, 4: 0.26470897, 5: 0.11765396}\n",
      "393 {0: 0.20452654, 1: 0.11109462, 2: 0.18435676, 3: 0.31818858, 4: 0.09091644, 5: 0.09091704}\n",
      "394 {0: 0.17527747, 1: 0.067802936, 2: 0.067805864, 3: 0.06780572, 4: 0.43304756, 5: 0.18826042}\n",
      "395 {0: 0.052947145, 1: 0.04255808, 2: 0.09571269, 3: 0.5145363, 4: 0.14534092, 5: 0.14890489}\n",
      "396 {0: 0.23077513, 1: 0.10257101, 2: 0.102574244, 3: 0.10257398, 4: 0.10257384, 5: 0.35893178}\n",
      "397 {0: 0.038838837, 1: 0.046013538, 2: 0.038466755, 3: 0.3981907, 4: 0.42913282, 5: 0.049357314}\n",
      "398 {0: 0.13793807, 1: 0.16718622, 2: 0.13793823, 3: 0.1379382, 4: 0.28106076, 5: 0.13793848}\n",
      "399 {0: 0.0540682, 1: 0.2209371, 2: 0.1009004, 3: 0.37175384, 4: 0.18917905, 5: 0.06316145}\n",
      "400 {0: 0.1176499, 1: 0.11764905, 2: 0.4117512, 3: 0.1176499, 4: 0.11764982, 5: 0.117650084}\n",
      "401 {0: 0.074084826, 1: 0.082099244, 2: 0.25125125, 3: 0.25926, 4: 0.2592203, 5: 0.0740844}\n",
      "402 {0: 0.06797337, 1: 0.063479796, 2: 0.45310137, 3: 0.2904327, 4: 0.06250611, 5: 0.06250669}\n",
      "403 {0: 0.10256963, 1: 0.102567926, 2: 0.35672334, 3: 0.10481432, 4: 0.23075485, 5: 0.10256997}\n",
      "404 {0: 0.13793679, 1: 0.13793501, 2: 0.13793701, 3: 0.13793704, 4: 0.31031692, 5: 0.13793723}\n",
      "405 {0: 0.13793708, 1: 0.1379354, 2: 0.13793738, 3: 0.13793707, 4: 0.31031564, 5: 0.13793746}\n",
      "406 {0: 0.05063644, 1: 0.060276516, 2: 0.17101683, 3: 0.050636355, 4: 0.050636288, 5: 0.61679757}\n",
      "407 {0: 0.11765603, 1: 0.11765334, 2: 0.25412008, 3: 0.11765598, 4: 0.26465145, 5: 0.12826313}\n",
      "408 {0: 0.117651075, 1: 0.1176499, 2: 0.11765106, 3: 0.41174546, 4: 0.117650986, 5: 0.11765152}\n",
      "409 {0: 0.13165143, 1: 0.13116959, 2: 0.05898915, 3: 0.13893636, 4: 0.4038206, 5: 0.13543287}\n",
      "410 {0: 0.48405963, 1: 0.10392517, 2: 0.049675383, 3: 0.0785425, 4: 0.026155695, 5: 0.25764155}\n",
      "411 {0: 0.074082896, 1: 0.3518223, 2: 0.074082926, 3: 0.12783724, 4: 0.29809126, 5: 0.07408335}\n",
      "412 {0: 0.0842059, 1: 0.08254769, 2: 0.082542785, 3: 0.26606208, 4: 0.21801113, 5: 0.26663044}\n",
      "413 {0: 0.117816865, 1: 0.31234375, 2: 0.4345304, 3: 0.056497797, 4: 0.053647008, 5: 0.025164165}\n",
      "414 {0: 0.090923674, 1: 0.20453407, 2: 0.31819856, 3: 0.20449677, 4: 0.09092284, 5: 0.090924114}\n",
      "415 {0: 0.20445177, 1: 0.09091653, 2: 0.09091989, 3: 0.09091968, 4: 0.09091953, 5: 0.43187258}\n",
      "416 {0: 0.21870251, 1: 0.06545462, 2: 0.11140119, 3: 0.20769027, 4: 0.15168403, 5: 0.24506737}\n",
      "417 {0: 0.097343095, 1: 0.081640214, 2: 0.18365356, 3: 0.37205648, 4: 0.18366237, 5: 0.08164424}\n",
      "418 {0: 0.41175526, 1: 0.11764845, 2: 0.11764908, 3: 0.11764903, 4: 0.117649, 5: 0.117649175}\n",
      "419 {0: 0.1696849, 1: 0.17728175, 2: 0.116819054, 3: 0.13036536, 4: 0.34786323, 5: 0.057985686}\n",
      "420 {0: 0.18035714, 1: 0.18536018, 2: 0.04923181, 3: 0.13108388, 4: 0.4007763, 5: 0.05319076}\n",
      "421 {0: 0.24192993, 1: 0.1836801, 2: 0.18367626, 3: 0.12543923, 4: 0.08164089, 5: 0.18363361}\n",
      "422 {0: 0.06780448, 1: 0.0678021, 2: 0.14648502, 3: 0.32201383, 4: 0.32201838, 5: 0.073876224}\n",
      "423 {0: 0.35893428, 1: 0.10257167, 2: 0.2307692, 3: 0.10257491, 4: 0.1025746, 5: 0.10257535}\n",
      "424 {0: 0.41172987, 1: 0.11765211, 2: 0.11765466, 3: 0.11765444, 4: 0.11765408, 5: 0.117654875}\n",
      "425 {0: 0.10257485, 1: 0.3589116, 2: 0.10257496, 3: 0.102574624, 4: 0.13600062, 5: 0.19736338}\n",
      "426 {0: 0.27509058, 1: 0.067802295, 2: 0.0678049, 3: 0.1994492, 4: 0.18130232, 5: 0.20855074}\n",
      "427 {0: 0.097118184, 1: 0.3401088, 2: 0.0667916, 3: 0.19323376, 4: 0.22022669, 5: 0.08252095}\n",
      "428 {0: 0.09092018, 1: 0.0909168, 2: 0.20448993, 3: 0.20451999, 4: 0.3182322, 5: 0.09092094}\n",
      "429 {0: 0.26467767, 1: 0.11765453, 2: 0.11765807, 3: 0.26469377, 4: 0.117657624, 5: 0.11765831}\n",
      "430 {0: 0.06780812, 1: 0.06780464, 2: 0.23730865, 3: 0.1525303, 4: 0.18017691, 5: 0.2943714}\n",
      "431 {0: 0.3140021, 1: 0.35224253, 2: 0.03580974, 3: 0.069678135, 4: 0.031014523, 5: 0.19725293}\n",
      "432 {0: 0.13793176, 1: 0.13793154, 2: 0.13793178, 3: 0.13793178, 4: 0.3103414, 5: 0.13793181}\n",
      "433 {0: 0.13793485, 1: 0.13793367, 2: 0.31032714, 3: 0.1379347, 4: 0.13793465, 5: 0.13793498}\n",
      "434 {0: 0.08164366, 1: 0.08523172, 2: 0.18367209, 3: 0.28571504, 4: 0.18006182, 5: 0.18367568}\n",
      "435 {0: 0.14622658, 1: 0.14653116, 2: 0.27064842, 3: 0.1362434, 4: 0.17575182, 5: 0.12459862}\n",
      "436 {0: 0.060523894, 1: 0.13350855, 2: 0.05797989, 3: 0.057979755, 4: 0.5459887, 5: 0.14401917}\n",
      "437 {0: 0.14055783, 1: 0.06514846, 2: 0.14055608, 3: 0.21879597, 4: 0.16642146, 5: 0.2685202}\n",
      "438 {0: 0.09091876, 1: 0.090915844, 2: 0.2045216, 3: 0.2045161, 4: 0.09091853, 5: 0.31820923}\n",
      "439 {0: 0.1071335, 1: 0.121526584, 2: 0.16662037, 3: 0.047631383, 4: 0.22622523, 5: 0.33086297}\n",
      "440 {0: 0.043170646, 1: 0.3700614, 2: 0.061756916, 3: 0.04256015, 4: 0.1483339, 5: 0.33411697}\n",
      "441 {0: 0.08318642, 1: 0.08163719, 2: 0.2857201, 3: 0.08163914, 4: 0.22821227, 5: 0.23960492}\n",
      "442 {0: 0.2700313, 1: 0.050643172, 2: 0.11392374, 3: 0.2110229, 4: 0.24051253, 5: 0.11386634}\n",
      "443 {0: 0.12165542, 1: 0.18478194, 2: 0.18917371, 3: 0.18917838, 4: 0.24810025, 5: 0.067110285}\n",
      "444 {0: 0.30117366, 1: 0.34345028, 2: 0.04041024, 3: 0.13322796, 4: 0.14132738, 5: 0.040410478}\n",
      "445 {0: 0.084554784, 1: 0.08164111, 2: 0.18368709, 3: 0.2856919, 4: 0.27330992, 5: 0.09111521}\n",
      "446 {0: 0.18370847, 1: 0.28743747, 2: 0.27293497, 3: 0.08165151, 4: 0.08165081, 5: 0.09261674}\n",
      "447 {0: 0.090912715, 1: 0.09255447, 2: 0.09091278, 3: 0.45570526, 4: 0.16808355, 5: 0.10183121}\n",
      "448 {0: 0.102573596, 1: 0.3589459, 2: 0.10257372, 3: 0.23075953, 4: 0.10257321, 5: 0.10257405}\n",
      "449 {0: 0.117655784, 1: 0.11765319, 2: 0.117656186, 3: 0.26469573, 4: 0.2646827, 5: 0.11765643}\n",
      "450 {0: 0.09993793, 1: 0.09091249, 2: 0.14938901, 3: 0.090913944, 4: 0.09091385, 5: 0.47793272}\n",
      "451 {0: 0.08164589, 1: 0.08291178, 2: 0.38526154, 3: 0.08288773, 4: 0.2856463, 5: 0.08164671}\n",
      "452 {0: 0.06718012, 1: 0.06250766, 2: 0.0625112, 3: 0.29687873, 4: 0.37033227, 5: 0.14058998}\n",
      "453 {0: 0.2857341, 1: 0.28572857, 2: 0.08164629, 3: 0.081645995, 4: 0.18359818, 5: 0.08164692}\n",
      "454 {0: 0.117652364, 1: 0.117650725, 2: 0.11765249, 3: 0.41173938, 4: 0.11765233, 5: 0.117652714}\n",
      "455 {0: 0.029279938, 1: 0.39163435, 2: 0.18984455, 3: 0.28516182, 4: 0.0725582, 5: 0.031521127}\n",
      "456 {0: 0.080410436, 1: 0.057466615, 2: 0.4196797, 3: 0.2518481, 4: 0.05167642, 5: 0.1389187}\n",
      "457 {0: 0.061664045, 1: 0.3205812, 2: 0.16794054, 3: 0.17722954, 4: 0.16759427, 5: 0.10499044}\n",
      "458 {0: 0.15232877, 1: 0.05887266, 2: 0.2744404, 3: 0.39840537, 4: 0.05797615, 5: 0.057976637}\n",
      "459 {0: 0.11766045, 1: 0.11765627, 2: 0.11766051, 3: 0.2646734, 4: 0.11766026, 5: 0.2646891}\n",
      "460 {0: 0.31820843, 1: 0.20454548, 2: 0.090923905, 3: 0.09092358, 4: 0.20447399, 5: 0.09092459}\n",
      "461 {0: 0.11765344, 1: 0.11765152, 2: 0.117653556, 3: 0.26469058, 4: 0.26469702, 5: 0.11765387}\n",
      "462 {0: 0.044643734, 1: 0.022442536, 2: 0.31507576, 3: 0.29476565, 4: 0.27482885, 5: 0.04824344}\n",
      "463 {0: 0.06422459, 1: 0.14530073, 2: 0.06250889, 3: 0.21873836, 4: 0.44501615, 5: 0.06421125}\n",
      "464 {0: 0.14060156, 1: 0.06250766, 2: 0.14063068, 3: 0.062510744, 4: 0.14056094, 5: 0.45318848}\n",
      "465 {0: 0.08163597, 1: 0.081634946, 2: 0.081636034, 3: 0.081635945, 4: 0.38775736, 5: 0.2856997}\n",
      "466 {0: 0.13793993, 1: 0.31030023, 2: 0.13794024, 3: 0.13793962, 4: 0.13793957, 5: 0.13794036}\n",
      "467 {0: 0.0909286, 1: 0.20452935, 2: 0.090928406, 3: 0.2045453, 4: 0.20452861, 5: 0.20453967}\n",
      "468 {0: 0.28565216, 1: 0.10647806, 2: 0.081647314, 3: 0.18365164, 4: 0.09563668, 5: 0.24693415}\n",
      "469 {0: 0.08164194, 1: 0.28567833, 2: 0.08164227, 3: 0.08164206, 4: 0.38775277, 5: 0.08164261}\n",
      "470 {0: 0.062120687, 1: 0.059892874, 2: 0.34237552, 3: 0.24000175, 4: 0.07226064, 5: 0.22334856}\n",
      "471 {0: 0.10258003, 1: 0.102575235, 2: 0.102580324, 3: 0.23073797, 4: 0.23074494, 5: 0.2307815}\n",
      "472 {0: 0.08258015, 1: 0.2178491, 2: 0.12842365, 3: 0.22020912, 4: 0.3048951, 5: 0.046042845}\n",
      "473 {0: 0.09571935, 1: 0.09854866, 2: 0.253076, 3: 0.21601313, 4: 0.29315695, 5: 0.04348587}\n",
      "474 {0: 0.117648534, 1: 0.117648095, 2: 0.11764859, 3: 0.117648534, 4: 0.13522546, 5: 0.39418077}\n",
      "475 {0: 0.0384685, 1: 0.4230834, 2: 0.08308835, 3: 0.2788553, 4: 0.13457415, 5: 0.041930307}\n",
      "476 {0: 0.090931065, 1: 0.20447187, 2: 0.20458758, 3: 0.20453554, 4: 0.09093035, 5: 0.20454358}\n",
      "477 {0: 0.07169853, 1: 0.5966539, 2: 0.06606844, 3: 0.06250751, 4: 0.14056365, 5: 0.062508}\n",
      "478 {0: 0.09413203, 1: 0.084526174, 2: 0.3848536, 3: 0.08164004, 4: 0.27320787, 5: 0.08164031}\n",
      "479 {0: 0.13794027, 1: 0.13793752, 2: 0.13794023, 3: 0.31030113, 4: 0.13794012, 5: 0.13794075}\n",
      "480 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "481 {0: 0.54544204, 1: 0.09091096, 2: 0.09091172, 3: 0.09091172, 4: 0.09091164, 5: 0.090911835}\n",
      "482 {0: 0.13676795, 1: 0.24471395, 2: 0.102573305, 3: 0.21680629, 4: 0.19656482, 5: 0.10257367}\n",
      "483 {0: 0.07407738, 1: 0.074464746, 2: 0.07407748, 3: 0.3682422, 4: 0.33278015, 5: 0.07635805}\n",
      "484 {0: 0.13039544, 1: 0.20811544, 2: 0.20287561, 3: 0.26801994, 4: 0.06016908, 5: 0.1304245}\n",
      "485 {0: 0.116300106, 1: 0.10659134, 2: 0.10257582, 3: 0.3412406, 4: 0.23071541, 5: 0.1025767}\n",
      "486 {0: 0.1379327, 1: 0.13793218, 2: 0.13793275, 3: 0.3103369, 4: 0.13793269, 5: 0.13793279}\n",
      "487 {0: 0.18365113, 1: 0.4897971, 2: 0.08163794, 3: 0.08163783, 4: 0.08163774, 5: 0.08163824}\n",
      "488 {0: 0.26467395, 1: 0.11765423, 2: 0.117657654, 3: 0.26469904, 4: 0.11765701, 5: 0.11765809}\n",
      "489 {0: 0.13793682, 1: 0.13793507, 2: 0.1379366, 3: 0.13793653, 4: 0.2574065, 5: 0.19084844}\n",
      "490 {0: 0.117652655, 1: 0.14376941, 2: 0.23857613, 3: 0.26469654, 4: 0.117652334, 5: 0.117652915}\n",
      "491 {0: 0.117649555, 1: 0.41175216, 2: 0.11764959, 3: 0.117649496, 4: 0.11764945, 5: 0.1176497}\n",
      "492 {0: 0.26467326, 1: 0.11765358, 2: 0.26470378, 3: 0.1176563, 4: 0.117656216, 5: 0.11765685}\n",
      "493 {0: 0.15218478, 1: 0.14036383, 2: 0.21171154, 3: 0.28220007, 4: 0.14144912, 5: 0.072090685}\n",
      "494 {0: 0.09085807, 1: 0.6229705, 2: 0.1081795, 3: 0.09085076, 4: 0.04508708, 5: 0.042054098}\n",
      "495 {0: 0.14220187, 1: 0.06780133, 2: 0.078116074, 3: 0.06780301, 4: 0.46127385, 5: 0.18280384}\n",
      "496 {0: 0.08164533, 1: 0.43268707, 2: 0.1387321, 3: 0.08164527, 4: 0.08164509, 5: 0.18364519}\n",
      "497 {0: 0.08164627, 1: 0.18364058, 2: 0.1836531, 3: 0.38776633, 4: 0.0816465, 5: 0.081647195}\n",
      "498 {0: 0.13534889, 1: 0.11553514, 2: 0.1366752, 3: 0.08306442, 4: 0.45518693, 5: 0.074189454}\n",
      "499 {0: 0.05798356, 1: 0.20283504, 2: 0.08068987, 3: 0.42036197, 4: 0.18014541, 5: 0.05798416}\n",
      "500 {0: 0.11765989, 1: 0.24290097, 2: 0.13943762, 3: 0.11765961, 4: 0.26468128, 5: 0.117660664}\n",
      "501 {0: 0.16664763, 1: 0.07651929, 2: 0.07408451, 3: 0.078331836, 4: 0.41906658, 5: 0.1853502}\n",
      "502 {0: 0.1753529, 1: 0.032342494, 2: 0.032264583, 3: 0.20228969, 4: 0.27598655, 5: 0.2817638}\n",
      "503 {0: 0.10257516, 1: 0.2364259, 2: 0.102575175, 3: 0.12319309, 4: 0.16637787, 5: 0.2688528}\n",
      "504 {0: 0.06780651, 1: 0.56247836, 2: 0.06780679, 3: 0.15250205, 4: 0.08159919, 5: 0.06780716}\n",
      "505 {0: 0.13794166, 1: 0.1379383, 2: 0.3102947, 3: 0.13794152, 4: 0.13794148, 5: 0.13794233}\n",
      "506 {0: 0.060305394, 1: 0.31502363, 2: 0.192789, 3: 0.22413094, 4: 0.14362869, 5: 0.06412232}\n",
      "507 {0: 0.14061873, 1: 0.37500036, 2: 0.18058668, 3: 0.06250748, 4: 0.06250737, 5: 0.1787794}\n",
      "508 {0: 0.07408261, 1: 0.07408001, 2: 0.07408261, 3: 0.4375269, 4: 0.17357947, 5: 0.16664834}\n",
      "509 {0: 0.118708506, 1: 0.21157546, 2: 0.184369, 3: 0.31665242, 4: 0.07958411, 5: 0.08911045}\n",
      "510 {0: 0.2596306, 1: 0.20750877, 2: 0.07255818, 3: 0.31512353, 4: 0.1129155, 5: 0.03226344}\n",
      "511 {0: 0.074084274, 1: 0.4444183, 2: 0.074084476, 3: 0.25924397, 4: 0.07408402, 5: 0.07408491}\n",
      "512 {0: 0.41170853, 1: 0.117655195, 2: 0.11765908, 3: 0.117658965, 4: 0.11765838, 5: 0.117659874}\n",
      "513 {0: 0.1525362, 1: 0.13919236, 2: 0.23728926, 3: 0.08105178, 4: 0.06780927, 5: 0.3221211}\n",
      "514 {0: 0.13794377, 1: 0.31028003, 2: 0.13794442, 3: 0.13794374, 4: 0.13794337, 5: 0.1379446}\n",
      "515 {0: 0.28268653, 1: 0.032979038, 2: 0.15150815, 3: 0.032741446, 4: 0.07064482, 5: 0.42943996}\n",
      "516 {0: 0.117663346, 1: 0.11765846, 2: 0.11766381, 3: 0.11766374, 4: 0.26467228, 5: 0.26467836}\n",
      "517 {0: 0.137936, 1: 0.14918993, 2: 0.2990663, 3: 0.13793589, 4: 0.13793573, 5: 0.13793615}\n",
      "518 {0: 0.13793641, 1: 0.1379347, 2: 0.13793644, 3: 0.31031942, 4: 0.13793635, 5: 0.13793668}\n",
      "519 {0: 0.23071721, 1: 0.10257306, 2: 0.102577016, 3: 0.10257685, 4: 0.10257685, 5: 0.35897902}\n",
      "520 {0: 0.08590356, 1: 0.08163548, 2: 0.08163678, 3: 0.5875506, 4: 0.08163664, 5: 0.08163694}\n",
      "521 {0: 0.06780463, 1: 0.07135646, 2: 0.32204124, 3: 0.23727778, 4: 0.22915702, 5: 0.07236292}\n",
      "522 {0: 0.10256853, 1: 0.10256715, 2: 0.23075125, 3: 0.102568515, 4: 0.10256838, 5: 0.35897616}\n",
      "523 {0: 0.3589195, 1: 0.10257108, 2: 0.10257431, 3: 0.23078619, 4: 0.10257394, 5: 0.10257497}\n",
      "524 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.31029457}\n",
      "525 {0: 0.21112964, 1: 0.14548925, 2: 0.37777767, 3: 0.06251297, 4: 0.14057668, 5: 0.06251379}\n",
      "526 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "527 {0: 0.067808956, 1: 0.085917935, 2: 0.067809425, 3: 0.47342026, 4: 0.15249825, 5: 0.15254517}\n",
      "528 {0: 0.06250693, 1: 0.0663702, 2: 0.13419059, 3: 0.5020626, 4: 0.16728137, 5: 0.06758829}\n",
      "529 {0: 0.2473584, 1: 0.08828907, 2: 0.17700772, 3: 0.28568602, 4: 0.12001535, 5: 0.08164345}\n",
      "530 {0: 0.16658933, 1: 0.11538625, 2: 0.07409188, 3: 0.074091606, 4: 0.25923, 5: 0.31061098}\n",
      "531 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "532 {0: 0.1379362, 1: 0.310319, 2: 0.13793617, 3: 0.13793622, 4: 0.13793597, 5: 0.13793643}\n",
      "533 {0: 0.12457642, 1: 0.457551, 2: 0.059169643, 3: 0.065542236, 4: 0.16567689, 5: 0.12748384}\n",
      "534 {0: 0.13793984, 1: 0.13793716, 2: 0.13793999, 3: 0.3103028, 4: 0.1379398, 5: 0.13794044}\n",
      "535 {0: 0.35190696, 1: 0.13036874, 2: 0.12768367, 3: 0.13781413, 4: 0.19424298, 5: 0.05798349}\n",
      "536 {0: 0.2675452, 1: 0.2352833, 2: 0.23151189, 3: 0.032266367, 4: 0.11291762, 5: 0.12047558}\n",
      "537 {0: 0.07119007, 1: 0.07235326, 2: 0.31994784, 3: 0.16670844, 4: 0.2651446, 5: 0.104655854}\n",
      "538 {0: 0.13793229, 1: 0.31033856, 2: 0.1379323, 3: 0.13793227, 4: 0.13793224, 5: 0.13793236}\n",
      "539 {0: 0.20451638, 1: 0.09091789, 2: 0.09092205, 3: 0.2045227, 4: 0.31819847, 5: 0.09092249}\n",
      "540 {0: 0.2295488, 1: 0.09420255, 2: 0.09821272, 3: 0.39620084, 4: 0.09091718, 5: 0.09091798}\n",
      "541 {0: 0.13793257, 1: 0.1379321, 2: 0.1379326, 3: 0.1379326, 4: 0.31033742, 5: 0.13793267}\n",
      "542 {0: 0.20452227, 1: 0.11524807, 2: 0.2914912, 3: 0.20452152, 4: 0.09092323, 5: 0.0932937}\n",
      "543 {0: 0.104468964, 1: 0.03115505, 2: 0.029857302, 3: 0.16410655, 4: 0.41800076, 5: 0.2524114}\n",
      "544 {0: 0.13793367, 1: 0.1379329, 2: 0.31033248, 3: 0.13793363, 4: 0.13793352, 5: 0.13793378}\n",
      "545 {0: 0.022992844, 1: 0.36965925, 2: 0.32739386, 3: 0.22414668, 4: 0.029447451, 5: 0.026359899}\n",
      "546 {0: 0.13793425, 1: 0.13793321, 2: 0.1379342, 3: 0.31032994, 4: 0.13793404, 5: 0.13793437}\n",
      "547 {0: 0.11764927, 1: 0.117648594, 2: 0.11764934, 3: 0.11764931, 4: 0.117649235, 5: 0.41175422}\n",
      "548 {0: 0.16018565, 1: 0.11765483, 2: 0.117658675, 3: 0.22211644, 4: 0.11765799, 5: 0.2647264}\n",
      "549 {0: 0.13793229, 1: 0.31033856, 2: 0.1379323, 3: 0.13793227, 4: 0.13793224, 5: 0.13793236}\n",
      "550 {0: 0.09091855, 1: 0.09091558, 2: 0.11343734, 3: 0.2045338, 4: 0.4092756, 5: 0.09091914}\n",
      "551 {0: 0.17170551, 1: 0.1379423, 2: 0.27651265, 3: 0.13794634, 4: 0.13794585, 5: 0.13794732}\n",
      "552 {0: 0.14062166, 1: 0.062506884, 2: 0.21871042, 3: 0.0625099, 4: 0.1709956, 5: 0.3446555}\n",
      "553 {0: 0.030387811, 1: 0.20538826, 2: 0.09602426, 3: 0.43382868, 4: 0.13551836, 5: 0.09885259}\n",
      "554 {0: 0.14954336, 1: 0.034168553, 2: 0.032903604, 3: 0.23164363, 4: 0.24845144, 5: 0.30328944}\n",
      "555 {0: 0.10257105, 1: 0.10256907, 2: 0.102570824, 3: 0.10257083, 4: 0.48714688, 5: 0.102571376}\n",
      "556 {0: 0.1525277, 1: 0.17003538, 2: 0.0678028, 3: 0.14269745, 4: 0.07288858, 5: 0.39404812}\n",
      "557 {0: 0.08164651, 1: 0.08164214, 2: 0.18360938, 3: 0.28572446, 4: 0.28572997, 5: 0.08164749}\n",
      "558 {0: 0.10257939, 1: 0.35895306, 2: 0.1025797, 3: 0.23072888, 4: 0.10257891, 5: 0.1025801}\n",
      "559 {0: 0.11765961, 1: 0.117655694, 2: 0.24883313, 3: 0.2805319, 4: 0.11765934, 5: 0.117660314}\n",
      "560 {0: 0.11764927, 1: 0.11956312, 2: 0.11764932, 3: 0.14183956, 4: 0.19408037, 5: 0.30921835}\n",
      "561 {0: 0.116542034, 1: 0.0502839, 2: 0.101122186, 3: 0.5174391, 4: 0.11464051, 5: 0.09997226}\n",
      "562 {0: 0.23075975, 1: 0.10256853, 2: 0.35896027, 3: 0.102570325, 4: 0.10257024, 5: 0.1025709}\n",
      "563 {0: 0.13793549, 1: 0.13793422, 2: 0.13793576, 3: 0.31032327, 4: 0.13793547, 5: 0.13793582}\n",
      "564 {0: 0.12446829, 1: 0.11765278, 2: 0.12615943, 3: 0.11765529, 4: 0.25616992, 5: 0.2578943}\n",
      "565 {0: 0.13793933, 1: 0.13793658, 2: 0.13793926, 3: 0.13793905, 4: 0.31030616, 5: 0.13793957}\n",
      "566 {0: 0.44443434, 1: 0.036702752, 2: 0.08255651, 3: 0.17943421, 4: 0.2201665, 5: 0.036705628}\n",
      "567 {0: 0.11765436, 1: 0.11765216, 2: 0.11765462, 3: 0.41172954, 4: 0.11765437, 5: 0.11765493}\n",
      "568 {0: 0.07408089, 1: 0.078192614, 2: 0.15927276, 3: 0.35184035, 4: 0.25928307, 5: 0.07733032}\n",
      "569 {0: 0.28152353, 1: 0.08163787, 2: 0.08584214, 3: 0.28566554, 4: 0.18369028, 5: 0.081640586}\n",
      "570 {0: 0.050037287, 1: 0.045114752, 2: 0.4128743, 3: 0.2481293, 4: 0.14610572, 5: 0.0977386}\n",
      "571 {0: 0.08164249, 1: 0.081639364, 2: 0.08164279, 3: 0.48981306, 4: 0.18361916, 5: 0.08164313}\n",
      "572 {0: 0.11764903, 1: 0.11764844, 2: 0.11764911, 3: 0.117649056, 4: 0.41175517, 5: 0.117649175}\n",
      "573 {0: 0.04495477, 1: 0.05109735, 2: 0.20809099, 3: 0.28659895, 4: 0.2941923, 5: 0.11506562}\n",
      "574 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "575 {0: 0.120991305, 1: 0.20281574, 2: 0.058830503, 3: 0.08080919, 4: 0.46815413, 5: 0.06839915}\n",
      "576 {0: 0.09091837, 1: 0.09091564, 2: 0.090918854, 3: 0.20447057, 4: 0.43185762, 5: 0.09091898}\n",
      "577 {0: 0.26463014, 1: 0.117655985, 2: 0.117660135, 3: 0.26473296, 4: 0.11765958, 5: 0.11766121}\n",
      "578 {0: 0.081645615, 1: 0.081641726, 2: 0.08164594, 3: 0.38778442, 4: 0.25985944, 5: 0.10742283}\n",
      "579 {0: 0.10072437, 1: 0.49624905, 2: 0.13671751, 3: 0.040688537, 4: 0.0707013, 5: 0.1549192}\n",
      "580 {0: 0.12613751, 1: 0.40179825, 2: 0.11750227, 3: 0.040185984, 4: 0.27254516, 5: 0.041830815}\n",
      "581 {0: 0.06514598, 1: 0.06385789, 2: 0.2751455, 3: 0.06250692, 4: 0.37237677, 5: 0.16096692}\n",
      "582 {0: 0.067807786, 1: 0.40679827, 2: 0.067808, 3: 0.15248173, 4: 0.2372958, 5: 0.06780836}\n",
      "583 {0: 0.28508496, 1: 0.13793425, 2: 0.13793558, 3: 0.13793552, 4: 0.13793544, 5: 0.16317423}\n",
      "584 {0: 0.20450427, 1: 0.09091592, 2: 0.31817222, 3: 0.090918824, 4: 0.20456956, 5: 0.09091916}\n",
      "585 {0: 0.22085938, 1: 0.28023377, 2: 0.103095256, 3: 0.13415371, 4: 0.1977416, 5: 0.063916266}\n",
      "586 {0: 0.13793588, 1: 0.31032073, 2: 0.13793592, 3: 0.13793577, 4: 0.13793565, 5: 0.13793601}\n",
      "587 {0: 0.31813222, 1: 0.090917446, 2: 0.20453544, 3: 0.09092024, 4: 0.20457387, 5: 0.09092081}\n",
      "588 {0: 0.31823877, 1: 0.09091977, 2: 0.09092493, 3: 0.20450422, 4: 0.20448647, 5: 0.0909258}\n",
      "589 {0: 0.10173029, 1: 0.26382387, 2: 0.07205625, 3: 0.03246762, 4: 0.108357444, 5: 0.42156455}\n",
      "590 {0: 0.10257835, 1: 0.23069493, 2: 0.10257843, 3: 0.23077293, 4: 0.23079643, 5: 0.10257893}\n",
      "591 {0: 0.074082665, 1: 0.08185916, 2: 0.07408289, 3: 0.16662507, 4: 0.4444747, 5: 0.15887555}\n",
      "592 {0: 0.16595379, 1: 0.062072255, 2: 0.13722204, 3: 0.14955057, 4: 0.27175757, 5: 0.21344377}\n",
      "593 {0: 0.10178474, 1: 0.17547582, 2: 0.28321412, 3: 0.133573, 4: 0.27744174, 5: 0.0285106}\n",
      "594 {0: 0.09091498, 1: 0.09091316, 2: 0.0909151, 3: 0.09091497, 4: 0.4018825, 5: 0.23445924}\n",
      "595 {0: 0.10257653, 1: 0.10257275, 2: 0.20050159, 3: 0.10257648, 4: 0.2307334, 5: 0.2610393}\n",
      "596 {0: 0.10065958, 1: 0.5417806, 2: 0.038559966, 3: 0.14319311, 4: 0.11106255, 5: 0.06474415}\n",
      "597 {0: 0.2077166, 1: 0.0909178, 2: 0.09092108, 3: 0.204513, 4: 0.30064777, 5: 0.10528379}\n",
      "598 {0: 0.16663605, 1: 0.16656032, 2: 0.04763196, 3: 0.16669068, 4: 0.28581375, 5: 0.16666716}\n",
      "599 {0: 0.07561678, 1: 0.507536, 2: 0.08414341, 3: 0.080752, 4: 0.03585607, 5: 0.21609573}\n",
      "600 {0: 0.07218109, 1: 0.06250403, 2: 0.062505946, 3: 0.4454324, 4: 0.13865733, 5: 0.21871921}\n",
      "601 {0: 0.046368606, 1: 0.36475512, 2: 0.0206228, 3: 0.11352285, 4: 0.2815994, 5: 0.17313123}\n",
      "602 {0: 0.20367555, 1: 0.15245157, 2: 0.35575143, 3: 0.067812815, 4: 0.15249455, 5: 0.06781405}\n",
      "603 {0: 0.09092684, 1: 0.32784724, 2: 0.16672859, 3: 0.11903829, 4: 0.20453113, 5: 0.09092788}\n",
      "604 {0: 0.16667062, 1: 0.16654322, 2: 0.074088804, 3: 0.34917554, 4: 0.0768159, 5: 0.16670592}\n",
      "605 {0: 0.13793682, 1: 0.13793492, 2: 0.31031805, 3: 0.13793662, 4: 0.13793644, 5: 0.13793714}\n",
      "606 {0: 0.23735218, 1: 0.15249614, 2: 0.15253048, 3: 0.23731117, 4: 0.15249562, 5: 0.06781443}\n",
      "607 {0: 0.15684977, 1: 0.26466724, 2: 0.117657445, 3: 0.11765729, 4: 0.22551027, 5: 0.117657945}\n",
      "608 {0: 0.10258227, 1: 0.23077537, 2: 0.23074129, 3: 0.102582246, 4: 0.10258186, 5: 0.23073699}\n",
      "609 {0: 0.17030242, 1: 0.24449, 2: 0.30433527, 3: 0.08349263, 4: 0.121613055, 5: 0.07576664}\n",
      "610 {0: 0.18365581, 1: 0.38775495, 2: 0.081648715, 3: 0.081648536, 4: 0.08164812, 5: 0.18364388}\n",
      "611 {0: 0.13794176, 1: 0.13793848, 2: 0.13794194, 3: 0.13794175, 4: 0.1379415, 5: 0.31029454}\n",
      "612 {0: 0.048405107, 1: 0.050926283, 2: 0.15240918, 3: 0.3246765, 4: 0.3786304, 5: 0.04495255}\n",
      "613 {0: 0.117668055, 1: 0.18265165, 2: 0.11766836, 3: 0.19965029, 4: 0.26469204, 5: 0.117669605}\n",
      "614 {0: 0.16698046, 1: 0.10579362, 2: 0.27861637, 3: 0.14845388, 4: 0.1427881, 5: 0.15736756}\n",
      "615 {0: 0.10257642, 1: 0.10257261, 2: 0.23077124, 3: 0.23069954, 4: 0.2308029, 5: 0.102577284}\n",
      "616 {0: 0.31818298, 1: 0.090914935, 2: 0.09091761, 3: 0.09091729, 4: 0.20453872, 5: 0.2045285}\n",
      "617 {0: 0.15244211, 1: 0.06959249, 2: 0.20660514, 3: 0.067809865, 4: 0.067809574, 5: 0.43574077}\n",
      "618 {0: 0.081639096, 1: 0.0816371, 2: 0.18361694, 3: 0.08163924, 4: 0.081638925, 5: 0.48982874}\n",
      "619 {0: 0.11436985, 1: 0.042857908, 2: 0.04255932, 3: 0.4036214, 4: 0.354032, 5: 0.042559486}\n",
      "620 {0: 0.09091937, 1: 0.090916194, 2: 0.31819788, 3: 0.19525872, 4: 0.10019725, 5: 0.2045106}\n",
      "621 {0: 0.2291904, 1: 0.06118584, 2: 0.13850999, 3: 0.20286296, 4: 0.16854763, 5: 0.19970316}\n",
      "622 {0: 0.05750569, 1: 0.07022544, 2: 0.21600226, 3: 0.27719137, 4: 0.28039557, 5: 0.098679714}\n",
      "623 {0: 0.3811338, 1: 0.20194182, 2: 0.105072685, 3: 0.026850067, 4: 0.026849981, 5: 0.25815168}\n",
      "624 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "625 {0: 0.13076, 1: 0.31193087, 2: 0.036705, 3: 0.1742967, 4: 0.30607298, 5: 0.04023443}\n",
      "626 {0: 0.117661834, 1: 0.26463655, 2: 0.11766192, 3: 0.11766199, 4: 0.2647142, 5: 0.11766347}\n",
      "627 {0: 0.11631684, 1: 0.09091076, 2: 0.09091154, 3: 0.17913298, 4: 0.404217, 5: 0.11851084}\n",
      "628 {0: 0.13793297, 1: 0.14045425, 2: 0.137933, 3: 0.17130399, 4: 0.25763318, 5: 0.15474263}\n",
      "629 {0: 0.05406041, 1: 0.2567177, 2: 0.39190164, 3: 0.054060344, 4: 0.05406017, 5: 0.18919969}\n",
      "630 {0: 0.23146665, 1: 0.19981991, 2: 0.30668184, 3: 0.054339863, 4: 0.03753354, 5: 0.17015822}\n",
      "631 {0: 0.08163995, 1: 0.0816378, 2: 0.08164029, 3: 0.3877282, 4: 0.28571326, 5: 0.081640474}\n",
      "632 {0: 0.34222403, 1: 0.0803624, 2: 0.24049023, 3: 0.1724777, 4: 0.03509727, 5: 0.12934835}\n",
      "633 {0: 0.15464766, 1: 0.44540942, 2: 0.09574747, 3: 0.09571325, 4: 0.11275422, 5: 0.095728}\n",
      "634 {0: 0.05327184, 1: 0.044435684, 2: 0.37394956, 3: 0.2075663, 4: 0.21022397, 5: 0.11055265}\n",
      "635 {0: 0.06682907, 1: 0.039910156, 2: 0.20498174, 3: 0.2029134, 4: 0.13826145, 5: 0.34710416}\n",
      "636 {0: 0.11390285, 1: 0.30377233, 2: 0.17719401, 3: 0.05064222, 4: 0.29963902, 5: 0.054849554}\n",
      "637 {0: 0.0274156, 1: 0.023987977, 2: 0.4665616, 3: 0.12879041, 4: 0.101086035, 5: 0.25215837}\n",
      "638 {0: 0.16305687, 1: 0.07738131, 2: 0.23724215, 3: 0.07301656, 4: 0.29450515, 5: 0.15479793}\n",
      "639 {0: 0.09835371, 1: 0.37180346, 2: 0.04162351, 3: 0.025980366, 4: 0.28660744, 5: 0.17563155}\n",
      "640 {0: 0.17720753, 1: 0.11378574, 2: 0.113931336, 3: 0.17720942, 4: 0.3672174, 5: 0.05064858}\n",
      "641 {0: 0.24108201, 1: 0.58547807, 2: 0.020369463, 3: 0.035370097, 4: 0.01728341, 5: 0.10041692}\n",
      "642 {0: 0.11765477, 1: 0.117652394, 2: 0.11765487, 3: 0.41172838, 4: 0.11765452, 5: 0.1176551}\n",
      "643 {0: 0.117660195, 1: 0.13851887, 2: 0.26472116, 3: 0.1176601, 4: 0.24377875, 5: 0.11766092}\n",
      "644 {0: 0.23075746, 1: 0.102570295, 2: 0.10257331, 3: 0.10257309, 4: 0.35895222, 5: 0.10257362}\n",
      "645 {0: 0.13794298, 1: 0.13793936, 2: 0.1379428, 3: 0.1379428, 4: 0.17370151, 5: 0.27453056}\n",
      "646 {0: 0.1176572, 1: 0.1176541, 2: 0.11765759, 3: 0.26468083, 4: 0.2646924, 5: 0.11765794}\n",
      "647 {0: 0.08562066, 1: 0.1296869, 2: 0.2420132, 3: 0.0823895, 4: 0.36786965, 5: 0.09242012}\n",
      "648 {0: 0.04832506, 1: 0.04494814, 2: 0.04495014, 3: 0.10105843, 4: 0.5472768, 5: 0.21344145}\n",
      "649 {0: 0.23076367, 1: 0.7384179, 2: 0.012482492}\n",
      "650 {0: 0.054416843, 1: 0.070570774, 2: 0.17298926, 3: 0.20205095, 4: 0.37414023, 5: 0.12583195}\n",
      "651 {0: 0.086382374, 1: 0.18364489, 2: 0.18368301, 3: 0.08164124, 4: 0.28571644, 5: 0.17893209}\n",
      "652 {0: 0.16769227, 1: 0.020208795, 2: 0.13973244, 3: 0.39825985, 4: 0.2501877, 5: 0.023918927}\n",
      "653 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "654 {0: 0.09484089, 1: 0.08032003, 2: 0.074082546, 3: 0.14591959, 4: 0.33424667, 5: 0.27059025}\n",
      "655 {0: 0.09564907, 1: 0.15210524, 2: 0.14895271, 3: 0.45559198, 4: 0.09577075, 5: 0.051930312}\n",
      "656 {0: 0.13793531, 1: 0.31032366, 2: 0.13793531, 3: 0.13793518, 4: 0.13793512, 5: 0.13793546}\n",
      "657 {0: 0.11766005, 1: 0.26462787, 2: 0.11765962, 3: 0.11765946, 4: 0.156078, 5: 0.22631504}\n",
      "658 {0: 0.06251367, 1: 0.21862642, 2: 0.1321613, 3: 0.37508926, 4: 0.14065343, 5: 0.07095591}\n",
      "659 {0: 0.08164562, 1: 0.18363746, 2: 0.18368602, 3: 0.081645794, 4: 0.18366578, 5: 0.2857193}\n",
      "660 {0: 0.17996854, 1: 0.17201799, 2: 0.12109241, 3: 0.09042482, 4: 0.19386317, 5: 0.24263301}\n",
      "661 {0: 0.22240427, 1: 0.09091307, 2: 0.09091507, 3: 0.09091494, 4: 0.31816465, 5: 0.18668807}\n",
      "662 {0: 0.41173175, 1: 0.117651865, 2: 0.11765406, 3: 0.11765396, 4: 0.11765384, 5: 0.1176545}\n",
      "663 {0: 0.089893036, 1: 0.363424, 2: 0.15681258, 3: 0.038470466, 4: 0.08316037, 5: 0.26823956}\n",
      "664 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "665 {0: 0.11765177, 1: 0.11765048, 2: 0.11765162, 3: 0.11765153, 4: 0.41174284, 5: 0.11765181}\n",
      "666 {0: 0.117654495, 1: 0.14255007, 2: 0.11765467, 3: 0.2647164, 4: 0.23976943, 5: 0.11765492}\n",
      "667 {0: 0.38973802, 1: 0.06780185, 2: 0.15253001, 3: 0.08481932, 4: 0.06780383, 5: 0.23730701}\n",
      "668 {0: 0.4995695, 1: 0.06102768, 2: 0.123605706, 3: 0.08880638, 4: 0.055315774, 5: 0.17167492}\n",
      "669 {0: 0.33190948, 1: 0.09092053, 2: 0.20448036, 3: 0.09092544, 4: 0.19083762, 5: 0.090926506}\n",
      "670 {0: 0.16666387, 1: 0.07408338, 2: 0.16663478, 3: 0.35186797, 4: 0.166662, 5: 0.074087985}\n",
      "671 {0: 0.13793539, 1: 0.13793403, 2: 0.13793549, 3: 0.31032416, 4: 0.13793531, 5: 0.13793565}\n",
      "672 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "673 {0: 0.35895625, 1: 0.102570385, 2: 0.23075353, 3: 0.102573134, 4: 0.102573015, 5: 0.10257372}\n",
      "674 {0: 0.13793677, 1: 0.13793498, 2: 0.13793689, 3: 0.3103174, 4: 0.13793671, 5: 0.13793723}\n",
      "675 {0: 0.13793984, 1: 0.13793716, 2: 0.13793999, 3: 0.3103028, 4: 0.1379398, 5: 0.13794044}\n",
      "676 {0: 0.08164373, 1: 0.08163983, 2: 0.08164337, 3: 0.48982847, 4: 0.18360075, 5: 0.0816438}\n",
      "677 {0: 0.06488474, 1: 0.024697252, 2: 0.23656955, 3: 0.15176348, 4: 0.31125396, 5: 0.21083105}\n",
      "678 {0: 0.11765223, 1: 0.11765072, 2: 0.23001513, 3: 0.11765233, 4: 0.11765228, 5: 0.29937732}\n",
      "679 {0: 0.18362945, 1: 0.08163903, 2: 0.08164193, 3: 0.18368633, 4: 0.2857526, 5: 0.1836507}\n",
      "680 {0: 0.11682516, 1: 0.074889675, 2: 0.031015355, 3: 0.21647178, 4: 0.16732389, 5: 0.3934741}\n",
      "681 {0: 0.31427777, 1: 0.21270855, 2: 0.24915312, 3: 0.023396146, 4: 0.050989546, 5: 0.14947489}\n",
      "682 {0: 0.13794178, 1: 0.13793848, 2: 0.13794194, 3: 0.13794176, 4: 0.13794151, 5: 0.31029454}\n",
      "683 {0: 0.20456642, 1: 0.09092287, 2: 0.090929255, 3: 0.31817916, 4: 0.09092879, 5: 0.20447353}\n",
      "684 {0: 0.2307657, 1: 0.10257231, 2: 0.35893294, 3: 0.10257629, 4: 0.10257591, 5: 0.102576844}\n",
      "685 {0: 0.063220866, 1: 0.06284044, 2: 0.21870786, 3: 0.3269871, 4: 0.26376355, 5: 0.06448016}\n",
      "686 {0: 0.07408508, 1: 0.44444948, 2: 0.07408545, 3: 0.16664472, 4: 0.16664937, 5: 0.07408586}\n",
      "687 {0: 0.13793719, 1: 0.13793533, 2: 0.13793744, 3: 0.31031504, 4: 0.13793725, 5: 0.13793771}\n",
      "688 {0: 0.11766327, 1: 0.26467738, 2: 0.11766266, 3: 0.117662236, 4: 0.26467124, 5: 0.11766322}\n",
      "689 {0: 0.23076265, 1: 0.10257123, 2: 0.23076802, 3: 0.23074917, 4: 0.10257403, 5: 0.10257488}\n",
      "690 {0: 0.102569275, 1: 0.10332959, 2: 0.10256919, 3: 0.11064883, 4: 0.47374952, 5: 0.10713356}\n",
      "691 {0: 0.067807786, 1: 0.07834102, 2: 0.22670823, 3: 0.15252972, 4: 0.06780732, 5: 0.4068059}\n",
      "692 {0: 0.11764816, 1: 0.11764783, 2: 0.117648184, 3: 0.117648184, 4: 0.41175938, 5: 0.11764823}\n",
      "693 {0: 0.31031433, 1: 0.13793561, 2: 0.1379376, 3: 0.13793729, 4: 0.1379372, 5: 0.13793793}\n",
      "694 {0: 0.11766086, 1: 0.13117188, 2: 0.26466897, 3: 0.11766072, 4: 0.11766068, 5: 0.2511769}\n",
      "695 {0: 0.16666666, 1: 0.16666666, 2: 0.16666666, 3: 0.16666666, 4: 0.16666666, 5: 0.16666666}\n",
      "696 {0: 0.2306946, 1: 0.10257494, 2: 0.23077063, 3: 0.2307993, 4: 0.10257955, 5: 0.10258096}\n",
      "697 {0: 0.06781522, 1: 0.13302937, 2: 0.13910998, 3: 0.49172124, 4: 0.067815065, 5: 0.100509115}\n",
      "698 {0: 0.35895702, 1: 0.10256992, 2: 0.1025728, 3: 0.10257249, 4: 0.23075482, 5: 0.10257298}\n",
      "699 {0: 0.10256564, 1: 0.10256519, 2: 0.1025657, 3: 0.10256566, 4: 0.45598847, 5: 0.13374932}\n",
      "700 {0: 0.29210594, 1: 0.16501446, 2: 0.20762219, 3: 0.09014443, 4: 0.20916015, 5: 0.03595285}\n",
      "701 {0: 0.13793676, 1: 0.13793501, 2: 0.13793676, 3: 0.31031796, 4: 0.13793656, 5: 0.13793693}\n",
      "702 {0: 0.13793257, 1: 0.1379321, 2: 0.1379326, 3: 0.1379326, 4: 0.3103374, 5: 0.13793267}\n",
      "703 {0: 0.08163974, 1: 0.081637606, 2: 0.08163983, 3: 0.18358427, 4: 0.48985842, 5: 0.08164017}\n",
      "704 {0: 0.102578826, 1: 0.14847903, 2: 0.10257904, 3: 0.18484463, 4: 0.23074608, 5: 0.23077238}\n",
      "705 {0: 0.26471123, 1: 0.1176498, 2: 0.26468572, 3: 0.11765104, 4: 0.117650956, 5: 0.11765125}\n",
      "706 {0: 0.013232294, 1: 0.28159365, 2: 0.4084363, 3: 0.13605453, 4: 0.14710508, 5: 0.013578189}\n",
      "707 {0: 0.05833704, 1: 0.33924785, 2: 0.063821316, 3: 0.057978142, 4: 0.41997397, 5: 0.0606417}\n",
      "708 {0: 0.2307624, 1: 0.10256992, 2: 0.10257262, 3: 0.10257245, 4: 0.35894966, 5: 0.10257292}\n",
      "709 {0: 0.107148774, 1: 0.2019605, 2: 0.27560836, 3: 0.10709975, 4: 0.047629565, 5: 0.2605531}\n",
      "710 {0: 0.13793336, 1: 0.13793263, 2: 0.1379334, 3: 0.3103339, 4: 0.13793324, 5: 0.13793346}\n",
      "711 {0: 0.09091381, 1: 0.09596452, 2: 0.09091384, 3: 0.090913765, 4: 0.3181901, 5: 0.3131039}\n",
      "712 {0: 0.09091982, 1: 0.31815478, 2: 0.20455243, 3: 0.2045328, 4: 0.0909197, 5: 0.0909205}\n",
      "713 {0: 0.13009992, 1: 0.23818713, 2: 0.047022406, 3: 0.09571955, 4: 0.3887834, 5: 0.10018759}\n",
      "714 {0: 0.06250803, 1: 0.5312935, 2: 0.14057747, 3: 0.06250802, 4: 0.06250782, 5: 0.14060512}\n",
      "715 {0: 0.15767531, 1: 0.15226473, 2: 0.15619832, 3: 0.39554346, 4: 0.09575541, 5: 0.042562768}\n",
      "716 {0: 0.2045407, 1: 0.090917274, 2: 0.2045482, 3: 0.090920806, 4: 0.3181514, 5: 0.0909216}\n",
      "717 {0: 0.06703091, 1: 0.1303178, 2: 0.22735198, 3: 0.1997368, 4: 0.20292349, 5: 0.172639}\n",
      "718 {0: 0.14180358, 1: 0.19196196, 2: 0.38625017, 3: 0.118702926, 4: 0.08409579, 5: 0.07718554}\n",
      "719 {0: 0.35412174, 1: 0.5783696, 2: 0.037594352, 4: 0.010501583}\n",
      "720 {0: 0.05064135, 1: 0.113902114, 2: 0.050641418, 3: 0.24049924, 4: 0.30382317, 5: 0.24049267}\n",
      "721 {0: 0.11766239, 1: 0.264634, 2: 0.26471603, 3: 0.11766229, 4: 0.11766191, 5: 0.11766335}\n",
      "722 {0: 0.08164459, 1: 0.12452837, 2: 0.2812732, 3: 0.1836624, 4: 0.15943511, 5: 0.16945638}\n",
      "723 {0: 0.13793896, 1: 0.13793656, 2: 0.137939, 3: 0.13793899, 4: 0.13793907, 5: 0.3103074}\n",
      "724 {0: 0.10256953, 1: 0.10256786, 2: 0.1025696, 3: 0.48715374, 4: 0.10256943, 5: 0.10256984}\n",
      "725 {0: 0.090924956, 1: 0.090920135, 2: 0.0909254, 3: 0.31818515, 4: 0.20452042, 5: 0.20452395}\n",
      "726 {0: 0.11764821, 1: 0.117647864, 2: 0.39911184, 3: 0.11764821, 4: 0.117648184, 5: 0.13029568}\n",
      "727 {0: 0.05406031, 1: 0.055278484, 2: 0.32347056, 3: 0.44798502, 4: 0.062897645, 5: 0.05630799}\n",
      "728 {0: 0.06187024, 1: 0.21097007, 2: 0.31230024, 3: 0.10334584, 4: 0.24231738, 5: 0.06919618}\n",
      "729 {0: 0.26469713, 1: 0.13004787, 2: 0.11765674, 3: 0.11765672, 4: 0.117656365, 5: 0.25228518}\n",
      "730 {0: 0.024182893, 1: 0.023357365, 2: 0.24264248, 3: 0.49544734, 4: 0.05303909, 5: 0.1613308}\n",
      "731 {0: 0.076499574, 1: 0.060705878, 2: 0.123561166, 3: 0.3821345, 4: 0.2780381, 5: 0.07906076}\n",
      "732 {0: 0.03765731, 1: 0.39142567, 2: 0.023596182, 3: 0.045774136, 4: 0.140448, 5: 0.36109868}\n",
      "733 {0: 0.31034052, 1: 0.13793167, 2: 0.13793194, 3: 0.13793194, 4: 0.13793191, 5: 0.13793202}\n",
      "734 {0: 0.13793486, 1: 0.1379336, 2: 0.31032708, 3: 0.13793479, 4: 0.13793471, 5: 0.13793495}\n",
      "735 {0: 0.18363427, 1: 0.08164211, 2: 0.18368676, 3: 0.28572655, 4: 0.08164609, 5: 0.18366422}\n"
     ]
    }
   ],
   "source": [
    "#topic_proportions, doc_topics_list = test_eta('auto', dictionary, ntopics=6)\n",
    "for doc_topics in doc_topics_list:\n",
    "    print(doc_topics['document'], doc_topics['probabilities'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "fb84338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     document   topic_1   topic_2   topic_3   topic_4   topic_5   topic_6\n",
      "0           0  0.173174  0.444398  0.074084  0.074084  0.160175  0.074085\n",
      "1           1  0.051969  0.134467  0.265449  0.038850  0.041128  0.468137\n",
      "2           2  0.065103  0.168067  0.107118  0.180700  0.195750  0.283262\n",
      "3           3  0.137942  0.137938  0.137942  0.137942  0.137941  0.310295\n",
      "4           4  0.313884  0.110043  0.028797  0.204601  0.182684  0.159990\n",
      "..        ...       ...       ...       ...       ...       ...       ...\n",
      "731       731  0.076500  0.060706  0.123561  0.382134  0.278038  0.079061\n",
      "732       732  0.037657  0.391426  0.023596  0.045774  0.140448  0.361099\n",
      "733       733  0.310341  0.137932  0.137932  0.137932  0.137932  0.137932\n",
      "734       734  0.137935  0.137934  0.310327  0.137935  0.137935  0.137935\n",
      "735       735  0.183634  0.081642  0.183687  0.285727  0.081646  0.183664\n",
      "\n",
      "[736 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>736.000000</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>734.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>367.500000</td>\n",
       "      <td>0.147764</td>\n",
       "      <td>0.167976</td>\n",
       "      <td>0.158246</td>\n",
       "      <td>0.176647</td>\n",
       "      <td>0.184504</td>\n",
       "      <td>0.166227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>212.609188</td>\n",
       "      <td>0.091166</td>\n",
       "      <td>0.128093</td>\n",
       "      <td>0.094358</td>\n",
       "      <td>0.112132</td>\n",
       "      <td>0.112768</td>\n",
       "      <td>0.113853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.013439</td>\n",
       "      <td>0.010502</td>\n",
       "      <td>0.011021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>183.750000</td>\n",
       "      <td>0.087715</td>\n",
       "      <td>0.085742</td>\n",
       "      <td>0.090921</td>\n",
       "      <td>0.090924</td>\n",
       "      <td>0.102568</td>\n",
       "      <td>0.090920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>367.500000</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.121519</td>\n",
       "      <td>0.137932</td>\n",
       "      <td>0.137942</td>\n",
       "      <td>0.146621</td>\n",
       "      <td>0.130341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>551.250000</td>\n",
       "      <td>0.170928</td>\n",
       "      <td>0.204486</td>\n",
       "      <td>0.204553</td>\n",
       "      <td>0.230773</td>\n",
       "      <td>0.258418</td>\n",
       "      <td>0.210739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>735.000000</td>\n",
       "      <td>0.605779</td>\n",
       "      <td>0.807461</td>\n",
       "      <td>0.611520</td>\n",
       "      <td>0.652278</td>\n",
       "      <td>0.680302</td>\n",
       "      <td>0.718347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         document     topic_1     topic_2     topic_3     topic_4     topic_5  \\\n",
       "count  736.000000  736.000000  736.000000  736.000000  733.000000  735.000000   \n",
       "mean   367.500000    0.147764    0.167976    0.158246    0.176647    0.184504   \n",
       "std    212.609188    0.091166    0.128093    0.094358    0.112132    0.112768   \n",
       "min      0.000000    0.013232    0.012719    0.012482    0.013439    0.010502   \n",
       "25%    183.750000    0.087715    0.085742    0.090921    0.090924    0.102568   \n",
       "50%    367.500000    0.121600    0.121519    0.137932    0.137942    0.146621   \n",
       "75%    551.250000    0.170928    0.204486    0.204553    0.230773    0.258418   \n",
       "max    735.000000    0.605779    0.807461    0.611520    0.652278    0.680302   \n",
       "\n",
       "          topic_6  \n",
       "count  734.000000  \n",
       "mean     0.166227  \n",
       "std      0.113853  \n",
       "min      0.011021  \n",
       "25%      0.090920  \n",
       "50%      0.130341  \n",
       "75%      0.210739  \n",
       "max      0.718347  "
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for i, doc_topics in enumerate(doc_topics_list):\n",
    "    row = {'document': i}\n",
    "    for topic, prob in doc_topics['probabilities'].items():\n",
    "        row[f'topic_{topic+1}'] = prob\n",
    "    data.append(row)\n",
    "\n",
    "df_reg = pd.DataFrame(data)\n",
    "print(df_reg)\n",
    "df_reg.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "fde387f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: signing \"right-to-try\" legislation, allowing gravely ill patients access experimental drugs?\n",
      "Topic proportions: [0.17317405343055725, 0.44439786672592163, 0.07408427447080612, 0.07408405095338821, 0.16017508506774902, 0.07408468425273895]\n",
      "Document 1: posted - important accomplishment keeping foreign conflicts. [According article](https://www.theelders.org/news/only-us-president-who-didnt-wage-war), managed US foreign conflicts Jimmy Carter. Thus holds term, second manage that. talk idiot, dangerous, head, I'd submit keeping US people's wars easy do. deserves enormous amount respect pulled off.\n",
      "Topic proportions: [0.05196916311979294, 0.1344669610261917, 0.2654487192630768, 0.03885040059685707, 0.04112797603011131, 0.4681367576122284]\n",
      "Document 2: Doubling standard deduction taxes absolutely net positive country. Previously rarely 12k line unless used mortgage interest deduction, itemizing unfairly balanced towards home owners (of previously benefited). hurt less wealthy already behind weren’t earning home equity. Letting doubled standard deduction absolute step right direction tax code partially less regressive.\n",
      "Topic proportions: [0.06510327011346817, 0.16806703805923462, 0.10711836069822311, 0.18069981038570404, 0.19574980437755585, 0.2832617461681366]\n",
      "Document 3: [deleted]\n",
      "Topic proportions: [0.13794176280498505, 0.1379384845495224, 0.13794194161891937, 0.13794174790382385, 0.13794149458408356, 0.31029459834098816]\n",
      "Document 4: can't believe I'm this, argue favour things disagree sometimes..... said, easy. 1- He's donated entire presidential salary variety causes inauguration- VAs, education services plenty more. 2- convinced Mexican government modernise labour laws part trade treaty. Mexicans unionise properly! argued affect US, happier well-protected workforce trade partner country benefits. 3- started positive reforms prison system Step act. 4- killed (not personally) Abu Bakr al-Baghdadi. Honourable mention: SPACE FORCE. Worth name alone, gave laugh. course, none makes completely trashing (ahem) formerly positive international reputation US, go. **Edit:** added 'ahem'. **Second edit:** add five hundred comments regarding #1, know. do. Read first.\n",
      "Topic proportions: [0.31388410925865173, 0.11004332453012466, 0.0287972092628479, 0.20460082590579987, 0.18268412351608276, 0.15999041497707367]\n",
      "Document 5: lowered unemployment record lows 2019. high percentage American's better financially president, according official studies. factually job openings unemployed. wages gone up. African-American unemployment recently achieved lowest recorded. Hispanic-American unemployment lowest recorded. Asian-American unemployment recently achieved lowest recorded. Women’s unemployment recently reached lowest 65 years. Youth unemployment recently hit lowest nearly half century. Lowest unemployment recorded Americans without high school diploma. Administration, veterans’ unemployment recently reached lowest nearly 20 years. NATO allies cough money collective security. Allies increased defense spending $130 billion 2016. White House reports almost twice allies meeting commitment spend 2% gross domestic product defense today arrived. stood Hong Kong. warned China use violence suppress pro-democracy protests signed Hong Kong Human Rights Democracy Act. Hong Kong marched American flags sang national anthem gratitude. tariff threats forced Mexico crack illegal immigration. Mexico recent history enforcing immigration laws — sending thousands National Guard forces southern border stop caravans Central American migrants. Plus, Congress poised approve U.S.-Mexico-Canada free-trade agreement, possible without threat tariffs. Economic growth quarter hit 4.2 percent. Median household income hit highest level recorded. worked toward enforced FDA approve affordable generic drugs history. that, drug companies freezing reversing planned price increases. reformed Medicare program stop hospitals overcharging low-income seniors drugs—saving seniors hundreds millions dollars alone. signed ending gag orders Pharmacists prevented sharing money-saving information. Secured $6 billion funding fight opioid epidemic. reduced high-dose opioid prescriptions 16 percent office. signed bill allowing drug imports Canada prescription prices down. signed executive order forces healthcare providers disclose cost services Americans comparison shop less providers charge insurance companies. signing bill American blindsided bills medical services agreed advance. Hospitals required post standard charges services, include discounted price hospital willing accept Signed VA Choice VA Accountability Act, expanded VA telehealth services, walk-in-clinics, same-day urgent primary mental health care. recently signed 3 bills benefit Native people. gives compensation Spokane tribe loss lands mid-1900's, funds Native language programs, third gives federal recognition Little Shell Tribe Chippewa Indians Montana. signed cruelty animals federal felony animal abusers face tougher consequences. Violent crime fallen he’s office rising 2 years elected. signed bill CBD Hemp legal. Trump’s EPA gave $100 million fix water infrastructure problem Flint, Michigan. Trump’s leadership, 2018 U.S. surpassed Russia Saudi Arabia become world’s largest producer crude oil. signed “Allow States Victims Fight Online Sex Trafficking Act” (FOSTA), includes “Stop Enabling Sex Traffickers Act” (SESTA) enforcement victims tools fight sex trafficking. signed bill require airports provide spaces breastfeeding Moms. signed biggest wilderness protection & conservation bill decade designated 375,000 acres protected land. though everyone freaked dropped us programs, programs good, programs misused funding. go. better implementations. news tell that. signed Save Seas funds $10 million per clean tons plastic & garbage ocean. Step Act’s reforms addressed inequities sentencing laws disproportionately harmed Black Americans reformed mandatory minimums created unfair outcomes. Step expanded judicial discretion sentencing non-violent crimes. 90% benefiting retroactive sentencing reductions Step Black Americans. Step provides rehabilitative programs inmates, helping successfully rejoin society return crime. increased funding Historically Black Colleges Universities (HBCU's) 14%. signed legislation forgiving Hurricane Katrina debt threatened HBCU's. signed funding legislation September 2018 increased funding school choice $42 million. tax cuts signed promote school choice allowing families use 529 college savings plans elementary secondary education. Signed legislation improve National Suicide Hotline. Signed comprehensive childhood cancer legislation law, advance childhood cancer research improve treatments. Tax Cuts Jobs signed doubled maximum amount child tax credit available parents lifted income limits claim it. 2018, signed $2.4 billion funding increase Child Development Fund, providing total $8.1 billion States fund child low-income families. Child Dependent Tax Credit (CDCTC) signed provides tax credit equal 20-35% child expenses, $3,000 per child & $6,000 per family + Flexible Spending Accounts (FSA's) allow set aside $5,000 pre-tax $ use child care. 2019 signed Autism Collaboration, Accountability, Research, Education Support (CARES) allocates $1.8 billion funding next five years help autism spectrum disorder help families. 2019 signed two funding packages providing nearly $19 million funding Lupus specific research education programs, additional $41.7 billion funding National Institutes Health (NIH), Lupus funding EVER. (I appreciate opinions fact checking guys, it’s cool see.)\n",
      "Topic proportions: [0.25720852613449097, 0.668123722076416, 0.015318270772695541, 0.027475371956825256, 0.020852819085121155, 0.011021274141967297]\n",
      "Document 6: fully funded Land Water Conservation Fund perpetuity, funded nearly necessary backlog repair work national parks. Great American Outdoors Act. more, believe disproves claim. Edit: seem misunderstood CMV about. arguing Trump's environmental record good, simply pointing positive president.\n",
      "Topic proportions: [0.30857616662979126, 0.24363668262958527, 0.10232356190681458, 0.042564257979393005, 0.2510836124420166, 0.05181571841239929]\n",
      "Document 7: difference comes defence spending Europe, slowly climbing upwards 1991. Now, whether beneficial subjective, qualifies successfully achieving political goal. Regards\n",
      "Topic proportions: [0.15528441965579987, 0.13793383538722992, 0.13793513178825378, 0.13793499767780304, 0.29297637939453125, 0.13793519139289856]\n",
      "Document 8: [deleted]\n",
      "Topic proportions: [0.13794176280498505, 0.1379384845495224, 0.13794194161891937, 0.13794174790382385, 0.13794149458408356, 0.31029456853866577]\n",
      "Document 9: huge positive impact USA presidency given truth parents tell kids, namely want- United States. frankly usually joke, know, serious truth it. thoughts America. perspectives young involved. happen believe difference, certainly allows big difference. Now, Trump, around fit traditional political mold, (IMO least) qualified job, lowers bar. That's bad generally, maybe case makes kid \"hey, maybe chance, necessarily Harvard grad war hero tough president\", maybe kid turns fantastic president. Giving fight begins chance horrible thing. shows truly president, they'll willing start journey. And, ultimately fail, process anyway. lowering bar means I'm longer lying kids want, that's positive.\n",
      "Topic proportions: [0.02252289466559887, 0.030139081180095673, 0.13980484008789062, 0.13400651514530182, 0.5239043831825256, 0.14962230622768402]\n"
     ]
    }
   ],
   "source": [
    "# Visualize topic to see if assignation is consistent\n",
    "for i in range(10):\n",
    "    print(f\"Document {i}: {df.body[i]}\")\n",
    "    topic_props = df_reg.iloc[i, 1:].tolist()\n",
    "    print(f\"Topic proportions: {topic_props}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da3030e4",
   "metadata": {},
   "source": [
    "NGRAMES: tax_cut, positive_change, human_trafficking,court_system, middle_east"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7de36",
   "metadata": {},
   "source": [
    "##### Try LDA using priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "183f365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: -4.93\n",
      "Topic 0: ['signed', 'bill', 'order', 'trade', 'federal', 'reform', 'price', 'million']\n",
      "Topic 1: ['impact', 'country', 'bad', 'actually', 'shit', 'right', 'pretty', 'political']\n",
      "Topic 2: ['tax', 'american', 'obama', 'administration', 'job', 'state', 'policy', 'cut']\n",
      "Topic 3: ['war', 'china', 'peace', 'US', 'israel', 'korea', 'military', 'troop']\n",
      "Topic 4: ['positive', 'america', 'change', 'republican', 'presidency', 'government', 'politics', 'power']\n",
      "signing right try legislation allowing gravely ill patient access experimental drug ['(0, 54.5%)', '(1, 13.2%)', '(2, 9.1%)', '(3, 10.0%)', '(4, 13.2%)']\n",
      "posted important accomplishment keeping america new foreign conflict according article theelders org news didnt wage war managed US new foreign conflict jimmy carter thus hold term second manage talk idiot dangerous submit keeping US war easy deserves enormous amount respect pulled ['(0, 4.6%)', '(1, 7.1%)', '(2, 35.0%)', '(3, 45.0%)', '(4, 8.4%)']\n",
      "doubling standard deduction tax absolutely net positive country previously rarely 12k line unless used mortgage interest deduction itemizing unfairly balanced towards home owner previously benefited hurt wealthy already behind earning home equity letting doubled standard deduction absolute step right direction tax code partially regressive ['(0, 6.9%)', '(1, 9.2%)', '(2, 29.4%)', '(3, 27.4%)', '(4, 27.2%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "believe argue favour disagree sometimes easy donated entire presidential salary variety cause inauguration VAs education service plenty convinced mexican government modernise labour part trade treaty mexican unionise properly argued affect US happier protected workforce trade partner country benefit started positive reform prison system step killed personally abu bakr al baghdadi honourable mention SPACE FORCE worth name alone gave laugh course none completely trashing ahem formerly positive international reputation US edit added ahem second edit add five hundred comment regarding read ['(0, 21.6%)', '(1, 9.4%)', '(2, 2.8%)', '(3, 44.7%)', '(4, 21.5%)']\n",
      "lowered unemployment record low high percentage american better financially according official study factually job opening unemployed wage gone african american unemployment recently achieved lowest recorded hispanic american unemployment lowest recorded asian american unemployment recently achieved lowest recorded woman unemployment recently reached lowest youth unemployment recently hit lowest nearly half century lowest unemployment recorded american without high school diploma administration veteran unemployment recently reached lowest nearly NATO ally cough money collective security ally increased defense spending billion white house report almost twice ally meeting commitment spend gross domestic product defense today arrived stood hong kong warned china use violence suppress pro democracy protest signed hong kong human right democracy hong kong marched american flag sang national anthem gratitude tariff threat forced mexico crack illegal immigration mexico recent history enforcing immigration sending thousand national guard force southern border stop caravan central american migrant plus congress poised approve mexico canada free trade agreement possible without threat tariff economic growth quarter hit percent median household income hit highest level recorded worked toward enforced FDA approve affordable generic drug history drug company freezing reversing planned price increase reformed medicare program stop hospital overcharging low income senior drug saving senior hundred million dollar alone signed ending gag order pharmacist prevented sharing money saving information secured billion NEW funding fight opioid epidemic reduced high dose opioid prescription percent office signed bill allowing drug import canada prescription price signed executive order force healthcare provider disclose cost service american comparison shop provider charge insurance company signing bill american blindsided bill medical service never agreed advance hospital required post standard charge service include discounted price hospital willing accept signed VA choice VA accountability expanded VA telehealth service walk clinic urgent primary mental health recently signed bill benefit native compensation spokane tribe loss land mid fund native language program third federal recognition little shell tribe chippewa indian montana signed cruelty animal federal felony animal abuser face tougher consequence violent crime fallen office rising elected signed bill CBD hemp legal EPA gave million fix water infrastructure problem flint michigan leadership surpassed russia saudi arabia become largest producer crude signed allow state victim fight online sex trafficking FOSTA includes stop enabling sex trafficker SESTA enforcement victim new tool fight sex trafficking signed bill require airport provide space breastfeeding mom signed biggest wilderness protection conservation bill decade designated acre protected land though everyone freaked dropped program program program misused funding better implementation news tell signed save sea fund million per clean ton plastic garbage ocean step reform addressed inequity sentencing disproportionately harmed black american reformed mandatory minimum created unfair outcome step expanded judicial discretion sentencing non violent crime benefiting retroactive sentencing reduction step black american step provides rehabilitative program inmate helping successfully rejoin society return crime increased funding historically black college university HBCU signed legislation forgiving hurricane katrina debt threatened HBCU signed funding legislation september increased funding school choice million tax cut signed promote school choice allowing family use college saving plan elementary secondary education signed legislation improve national suicide hotline signed comprehensive childhood cancer legislation advance childhood cancer research improve treatment tax cut job signed doubled maximum amount child tax credit available parent lifted income limit claim signed billion funding increase child development fund providing total billion state fund child low income family child dependent tax credit CDCTC signed provides tax credit equal child expense per child per family flexible spending account FSA allow set aside pre tax use child signed autism collaboration accountability research education support CARES allocates billion funding next five help autism spectrum disorder help family signed two funding package providing nearly million new funding lupus specific research education program additional billion funding national institute health NIH lupus funding appreciate opinion fact checking guy cool ['(0, 76.5%)', '(1, 5.2%)', '(2, 17.2%)']\n",
      "fully funded land water conservation fund perpetuity funded nearly necessary backlog repair work national park great american outdoors believe disproves claim edit seem misunderstood CMV arguing environmental record simply pointing positive ['(0, 21.5%)', '(1, 7.9%)', '(2, 39.8%)', '(3, 12.7%)', '(4, 18.1%)']\n",
      "difference defence spending europe slowly climbing upwards whether beneficial subjective qualifies successfully achieving political goal regard ['(0, 17.5%)', '(1, 32.5%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "huge positive impact USA presidency given truth parent tell kid namely united state frankly usually joke serious truth new thought america new perspective young happen believe difference certainly allows big difference around fit traditional political mold IMO least qualified job lower bar bad generally maybe case kid hey maybe chance necessarily harvard grad war hero tough maybe kid turn fantastic giving fight begin chance horrible show truly willing start journey ultimately fail process anyway lowering bar longer lying kid positive ['(0, 3.1%)', '(1, 35.9%)', '(2, 15.4%)', '(3, 17.6%)', '(4, 28.1%)']\n",
      "thank trying start meaningful discussion canadian follows politics tried hard objective easy sometimes worship burn effigy worse ['(0, 9.5%)', '(1, 35.9%)', '(2, 9.1%)', '(3, 18.2%)', '(4, 27.3%)']\n",
      "sole positive turn blind eye china motivation center CCP tyrannical regime deprives basic liberty human right systematically destroying economy country dumping cost destroy local industry addicted artificially cheap new opium mention fentanyl export regime bit deadly hitler germany realization mindset chamberlain europe away peace prosperity v let hong kong freedom erode taiwan claim independence unrecognized away south china sea piss poor job alone approach critical start standing china pretty clear motif centered though idolizes putin russia subvert thuggish corrupt cleptocracy former leader refused stand CCP single change presidency likely positive forward ['(0, 6.0%)', '(1, 28.4%)', '(2, 13.8%)', '(3, 36.1%)', '(4, 15.7%)']\n",
      "legalized hemp brought focus southern border reducing human drug trafficking called epstein bill clinton campaign trail cool start new war conflict brought troop home actually given shit VA called military industrial complex multiple UAE peace closed travel china else taking corona seriously US never death prevented favorite pleasantly surprised presidency truth list accomplishment surprise almost major network believe foreign asset despite america number platform politician either terrible claim hitler bad hair formerly powerful angry finally seeing dirty politics real fight rather two party serve puppet master used openly talk corrupt politics outsider corrupt certain clue supposed inform certainly giving straight understand understand politics ['(0, 11.7%)', '(1, 14.3%)', '(2, 10.3%)', '(3, 32.7%)', '(4, 31.0%)']\n",
      "fan hate saying positive exposed sheer amount corruption federal government ['(0, 13.5%)', '(1, 14.3%)', '(2, 15.7%)', '(3, 21.4%)', '(4, 35.1%)']\n",
      "post evidence shown easily manipulated country believing purely purely side together excuse leader right excuse right hope realize bias exists mind competing viewpoint result presidency overwhelming society ['(0, 6.1%)', '(1, 63.5%)', '(2, 5.6%)', '(3, 12.2%)', '(4, 12.6%)']\n",
      "start saying fan easily hated mouth label point exact reason narrative confirmation bias use crack illegals obama absolute deporter chief axios immigration ice deportation obama a72a0a44 540d 46bc a671 cd65cf72f4b1 html fine issue racist deporting though build bullshit mainly bc worst US loved focused seem worse business owner hire work harder else work half speed felt able blame illegals coming least realizing racism critic poor american getting job black unemployment lowest decade maybe history fred stlouisfed org series LNS14000031 policy poor country workforce job poor usually start job near bottom illegals clear taking job thats exactly happened difference admins strategy harder stay welfare bc knew job opening seem cruel whatnot kick sometimes obama gutted restriction welfare allowing poor sit collect check unemployment showed across board trying stop reading news especially headline sturgis super spreader headline created narrative feel certain read realize total horseshit ['(0, 7.1%)', '(1, 21.1%)', '(2, 46.2%)', '(3, 14.0%)', '(4, 11.6%)']\n",
      "farm_sauce OP awarded delta post comment earned delta OP user listed r DeltaLog comment iq4iv8 deltas_awarded_in_cmv_donald_trump_has_not_made_a r DeltaLog please note change necessarily reversal conversation ended delta system explained r changemyview deltasystem deltaboards r changemyview deltaboards ['(0, 14.9%)', '(1, 16.5%)', '(2, 14.5%)', '(3, 27.3%)', '(4, 26.9%)']\n",
      "gotta mention top already mentioned statistic opened eye black grew poor believe prison system systematically ruined generation black family 90 pre covid administration best administration overall black community shockingly including obama lowest black incarceration past lowest black unemployment frame supporter highly BRC NYC father main charity provides low income home ownership opportunity black community stats always stick craziest push directly influence number ive bi product bunch shit side note SOO disappointed k harris VP announcement track record represents everything wrong justice system right thats main issue especially elizabeth warren k harris nomination ['(0, 5.3%)', '(1, 23.1%)', '(2, 46.6%)', '(3, 7.4%)', '(4, 17.7%)']\n",
      "started war alone warrant election american war hungry company biden hold starting war obama started several proxy war supplying rebel weapon cause libya turn wealthiest country africa war torn shithole actual slave market gave rebel syria enough weapon start civil war causing million refugee thousand death enough war bush started require another explanation war rebel supplied weapon hell actually helped korea south korea start talking pressure israel conflict fact never highlighted show bitching actually peace mind hundred thousand dying right skin colour completely fucked ['(0, 6.6%)', '(1, 26.7%)', '(2, 6.9%)', '(3, 57.5%)', '(4, 2.4%)']\n",
      "step justice reform money historically black university israel UAE agreement serbia kosovo agreement US energy independence started new war decade drawing troop iraq afghanistan opportunity zone brought 70b moved embassy jerusalem building border mexico trade replace NAFTA US mexico canada agreement starting china place exposed scum ['(0, 38.0%)', '(1, 5.4%)', '(2, 9.9%)', '(3, 39.7%)', '(4, 7.0%)']\n",
      "administration assisted normalizing relation UAE israel historical event celebrated nobel peace US history administration lowered cost prescription drug republican democrat pocket pharmaceutical company decade started fixing effect biden clinton crime bill destroyed black community regardless COVID vaccine arrives unprecedented step taken administration buy risk hundred million dos instrumental different entity stage trial right without federal government assistance nearly close turned tide manufacturing job pouring china recent ignored money large corporation ensuring offshore manufacturing job progress opioid crisis ignored federal level took office ['(0, 29.4%)', '(1, 6.8%)', '(2, 29.1%)', '(3, 24.5%)', '(4, 10.2%)']\n",
      "war lmao lowest unemployment black hispanic history small business owned black increased tax cut forgave debt HBCUs affected katrinahttps washingtonpost news grade point wp education department forgives million loan help historically black college recover hurricane program billion minoritiy retirement whitehouse gov briefing statement remark signing executive order establishing white house opportunity revitalizatiocompensation native american lost land thehill changing america respect diversity inclusion signed three bill affecting nativeset legislation fight sex trafficking appointed former victim black woman newest member advisory council human trafficking theepochtimes creates new position dedicated fighting human trafficking_3223105 htmllowering penalty none violent crime nytimes politics prison sentencing htmlbillions help urban development led ben carson politico state new york albany story administration imposes monitor nycha city pledge 22b 831349trump RESTORES funding HBCU historically black college university apnews c4834e48841d97c5a93312b1bf75302ahe award jesse jackson work black community ['(0, 57.4%)', '(1, 1.9%)', '(2, 26.2%)', '(3, 4.3%)', '(4, 10.2%)']\n",
      "new war armed conflict started conflict succeeded bringing peace korea east let honest worse least bill clinton ['(0, 11.0%)', '(1, 16.3%)', '(2, 5.3%)', '(3, 62.2%)', '(4, 5.3%)']\n",
      "biggest impact talk avoiding war iran US drone shot military planned bombing attack response personally stopped realized strike killed dozen iranian rhetoric hear career politician party pretty else office let military proceed strike ['(0, 7.1%)', '(1, 24.3%)', '(2, 10.8%)', '(3, 37.6%)', '(4, 20.2%)']\n",
      "disclosure idiot social policy generally stand deplorable ethical standard achievement worth noting helped broker fully normalized relation UAE israel big east BBC news canada big enough norwegian politician nominated nobel peace role normalized relation stated judged fact action behaves sometimes likely win love leftist explode handle righteous right gloating though reducing dependence china matching tarrifs chinese government increasingly expansionist flouting human right agree stupid shit calling xi xinping great leader maintained military pivot asia offering assurance allied asian nation action line verbal praise chinese leadership accomplishment bad depending political right instance religious freedom policy step backward US domestic social issue anti abortion religion US currently synonymous christian change helped domestic side international stage publicly called nigeria killing christian conference call nigeria criticized china persecution uighur muslim consistently strong backing religious freedom international front reuters article usa religion un un push religious freedom event slamming china uighur iduskbn1w82bj domestic social policy suck divisive biggest weakness knee jerk combative childish de escalate however foreign policy never mentioned US unless stupid bad ['(0, 3.7%)', '(1, 26.4%)', '(2, 16.2%)', '(3, 44.1%)', '(4, 9.6%)']\n",
      "plenty especially conservative e g court pick recent clinton earlier promise move US embassy jerusalem backed fearful palestinian backlash without blinking eye enough walked border korea fearless unprotected utter shock watched brief hope south korea unification across asia pro love fest america largely shielded USA MSN running nuclear war narrative quickly shut hell changed subject destroyed ISIS giving general mattis free hand remember bad ISIS threat prior gone ordered killing soleimani entire east better student iran started walking around ground painting american flag respect america changed overton window china standing theft american IP everyone else gutless icing cake list believed recent press release white house true sufficiently impressed page html2 f scribdassets 99k0aq4czk81zpd2 image 0343d5eb33 jpg page html2 f scribdassets 99k0aq4czk81zpd2 image d730990f61 jpg page html2 f scribdassets 99k0aq4czk81zpd2 image 54f6e8d291 jpg page html1 f scribdassets 99k0aq4czk81zpd2 image 05310c52ad jpg page html1 f scribdassets 99k0aq4czk81zpd2 image 5f048e4bd5 jpg page html1 f scribdassets 99k0aq4czk81zpd2 image dc5031e9db jpg nicely ordered list fan itemising amazing accomplishment frankreport hundred twenty five amazing accomplishment j find hundred list online comprehensive list overlap unique item use google find though search result battleground narrative wrestling balance choice pretty clear rational person vote opinion welcome ['(0, 7.5%)', '(1, 33.1%)', '(2, 19.4%)', '(3, 32.0%)', '(4, 8.1%)']\n",
      "single positive impact USA term signed order reuters article usa drugprices iduskcn24p2ja lower prescription drug price insulin nypost cut cost insulin medicare enrollee month month able stitch peace financialexpress defence century uae israel peace accord UAE israel bought gulf story US cut iraq troop pledge stop endles troop home iraq afghanistan newscaf official bringing troop home germany_7091101 html troop germany US unemployment whitehouse gov article unemployment fall low fall low ['(0, 20.2%)', '(1, 9.9%)', '(2, 26.2%)', '(3, 39.4%)', '(4, 4.3%)']\n",
      "mentioned pushing national security advisor foreign surveillance huge benefit US security understand attack TikTok realize TikTok foreign intelligence gather information US citizen case company administration pushing find former GOP regard attempting lower healthcare price hell extremely healthcare issue fact GOP member trying take step direction definitely worth mentioning nationalized healthcare already shit playing ball hong kong removing special status hong kong slighted china appreciate indirect support hong kong piss china necessarily great hong kong run believe played bargaining chip help strengthen democracy hong kong administration confirmation bias clouding reality unfortunate actually signed executive order pressuring police force US stop using excessive force yes EO bureaucratic hopefully effect hard tell anyway credit fight police reform right wing talk either narrative base federalregister gov document safe policing safe community federalregister gov document safe policing safe community mention obviously shrugged try thought EPA agency used political action front certain group power allowing rig certain energy price energy production conspiracy embedded function allowed tax flow action front essentially taxing energy company achieve impossibility dismantling EPA actually cutting revenue stream function front term protecting environment result pissed team place energy cheaper effect environment either stifled democrat power energy threw giant hoopla rid EPA GOP wanted stop DNC using regulatory ability EPA political globalist ideal funded black college university understand guy terrible personality country bad completely listening advisor respect smartest guy pretty dumb hire smartest yes conservative effectively running country office least lame duck bolstering shit US defense class conservative worse start attacking saying running country country turning shit turning shit regardless post stuff actually argument decision reply ['(0, 20.2%)', '(1, 29.5%)', '(2, 19.9%)', '(3, 16.3%)', '(4, 14.1%)']\n",
      "new war thats america ['(0, 14.6%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 35.4%)', '(4, 25.0%)']\n",
      "hasnt impact must watch CNN pity falling lie paper excellent best american history yeah easiest guy tough son bitch shit feeling list recently signed three bill benefit native compensation spokane tribe loss land mid 1900s fund native language program third federal recognition little shell tribe chippewa indian montana finalized creation space force 6th military branch signed cruelty animal federal felony animal abuser face tougher consequence violent crime fallen office rising two elected signed bill CBD hemp legal EPA gave million fix water infrastructure problem flint michigan leadership surpassed russia saudi arabia become largest producer crude signed ending gag order pharmacist prevented sharing money saving information signed allow state victim fight online sex trafficking FOSTA includes stop enabling sex trafficker SESTA enforcement victim new tool fight sex trafficking signed bill require airport provide space breastfeeding mom lowest paid american enjoyed income boost november outpaces gain earnings country highest paid worker low wage worker benefiting higher minimum wage corporation increasing entry level pay signed biggest wilderness protection conservation bill decade designated acre protected land signed save sea fund million per clean ton plastic garbage ocean signed bill allowing drug import canada prescription price signed executive order force healthcare provider disclose cost service american comparison shop provider charge insurance company signing bill american blindsided bill medical service never agreed advance hospital required post standard charge service include discounted price hospital willing accept eight prior inauguration prescription drug price increased average per drug price decline nine ten month drop recent month created white house VA hotline help veteran principally staffed veteran direct family member veteran VA employee held accountable poor performance VA employee removed demoted suspended issued executive order requiring secretary defense homeland security veteran affair submit joint plan provide veteran access access mental health treatment transition civilian bill signed championed federal employee pay increase average largest raise signed week paid parental leave million federal worker administration provide HIV prevention drug free uninsured patient per record sale holiday signed order allowing small business group together buying insurance better price ['(0, 88.8%)', '(1, 2.5%)', '(2, 6.5%)', '(4, 1.4%)']\n",
      "believe scroll hear black community step lowest unemployment american history reminded ordered invasion nation happened carter list accomplishment achieved hope offer different approach eliminate thread spoken state union speech press briefing RNC acceptance speech sadly due social alienation political division almost hate trusting governmental research advise e CDC FDA certainly white house press briefing simply dismiss lie part administration whole thread right side divide unwilling consider right lie deceit evil understandable mostly leaning mass constantly drone right supposedly proclaims evil racist bigoted sexist paint large number believe fascist important hear side envelope bubble ego liberal month election changed child sense right party type becoming comfortable gun enthusiast military veteran mechanic tradesman devoted christian general hard working union stiff used intimidate confuse upset wanted understand truly believed enough living support family able protect threat family community maintain safe community rule onerous regulation hurt fruit labor grand vision best everyone else learned resent minarchist libertarian else accountability best million others basically bureaucrat simply intelligent yes leader resent intellectual dangerous path lead letting small group ultimately bias blindspots dictate policy without regard others representative democracy important smaller district require focused set idea exist community let point continue ramble supported evil administration dimensional support base conservative talk op understand hold genuine belief around feel hold ideal firm talk help solidify ego attrition research trust mass readily reporting lean towards outrage buck empathize stop sympathizing confuse take hot minute clear mind bias truly consider agree conclusion thank platinum gold higher award expect ['(0, 7.9%)', '(1, 42.1%)', '(2, 31.5%)', '(3, 9.7%)', '(4, 8.7%)']\n",
      "dislike dislike jumping bandwagon hate let positive presidency USA china trade war devastating china impossible damaged chinese economy source saying crippled chinese regime desperate flip side US economy booming right covid hit economy strength strength p500 small local business pretty everyone america high killed public enemy number iranian economy fucked weak iran america amazing leverage east enough perhaps withdraw troop brings withdrawing troop syria iraq continuing obama era plan policing east saudi arabia isreal beinging american troop home continued downwards trend violent crime right BLM protest revealed extent failure MSM providing unbiased fair journalism accidently america best country live covid locking trying stop spread america managed escape worst economic issue covid lower death comparative european country enjoy luxury avoiding second spike second spate lockdown second spate layoff ['(0, 6.0%)', '(1, 22.2%)', '(2, 21.6%)', '(3, 31.9%)', '(4, 18.3%)']\n",
      "jimmy carter started new war foreign conflict step towards stopping CCP encroachment hong kong running actual concentration camp mention brokering historic peace isreal uae deptuizing state police washington order properly convict violent rioter without violating state right hopefully spell end mostly peaceful riot killed march effective take ['(0, 9.6%)', '(1, 6.4%)', '(2, 27.3%)', '(3, 44.3%)', '(4, 12.5%)']\n",
      "prevented TVA outsourcing employee direct violation stated reason existing enrich tennessee via employment TN resident helped save job currently staffed facing removal favor hiring outsourced role yeah broken clock right twice ['(0, 18.2%)', '(1, 12.1%)', '(2, 27.3%)', '(3, 30.4%)', '(4, 12.0%)']\n",
      "animal cruelty illegal federal level cnn politics animal cruelty signed trnd index html ['(0, 54.1%)', '(1, 7.1%)', '(2, 14.5%)', '(3, 7.1%)', '(4, 17.1%)']\n",
      "blow bad buries deed bad hard find article news bias ['(0, 9.4%)', '(1, 45.1%)', '(2, 22.6%)', '(3, 13.5%)', '(4, 9.3%)']\n",
      "name obama ['(0, 16.7%)', '(1, 16.7%)', '(2, 30.5%)', '(3, 19.5%)', '(4, 16.7%)']\n",
      "actually stood hong kong warned china resort violence ['(0, 15.2%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 27.6%)', '(4, 14.3%)']\n",
      "unfortunately change share frustration conversation friend frustrating knowing zero resource objective analysis presidency pretty solidly person naturally despise guy everything represents study politics sometimes nearly impossible find source talk activity positively hideous right wing website littered clickbait ad titled TRUTH feminism EXPOSED absolutely hint objectivity facially absurd claim actually BEST america especially black meanwhile source predominantly center apparatus histamine response mode flaring focused rejecting virus combine fact social pre decided narrative agree basic fact becomes nearly impossible synthesize truth whole frustrating fact ['(0, 3.9%)', '(1, 40.7%)', '(2, 8.6%)', '(3, 3.4%)', '(4, 43.4%)']\n",
      "whitehouse gov administration accomplishment list accomplishment administration september median household income hit highest level recorded atr org thanks median household income highest level amp almost million american lifted food stamp election low american EBT food stamp politifact factchecks jul correct food stamp low signed biggest package tax cut reform history tax cut billion poured quarter alone african american unemployment recently achieved lowest recorded cnn economy black unemployment index html hispanic american unemployment lowest recorded asian american unemployment recently achieved lowest recorded woman unemployment recently reached lowest youth unemployment recently hit lowest nearly half century lowest unemployment recorded american without high school diploma new unemployment claim recently hit low manufacturing job growing fastest THREE DECADES LIST GOES whitehouse gov administration accomplishment trying break deep state youtu 39m_npbbjd4 pedophile ring high number human trafficking arrest presidency ice gov news release ice hsi announces record high number criminal arrest fy19 higher obama instagram p CCrTgaPAm1n kicked epstein private club suspicious activity thehill homenews administration book claim barred epstein mar lago financier hit formed stable relationship korea youtube watch v j9opal4esog signed police reform politico news sign police reform executive order article help black community prosper delgazette opinion helping black community thrive list latino hispanic community whitehouse gov briefing statement j america policy uplifting empowering hispanic american ['(0, 28.2%)', '(1, 3.2%)', '(2, 60.7%)', '(3, 2.2%)', '(4, 5.8%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "wholeheartedly disagree quote jack nicholson batman whole town enema african american brought light great majority always known whole racism bedrock nation great white citizen brought delusion reality constant fight front group must pro active level government root kind evil vote election state local level second american rot system donkey kicked face bad politician job active participant getting real priveleged policy american effect become sloth oblivious ill society nc busy distracted brought focus right country accidentally become needed opinion opinion elected knowing corrupt system lame two party system spout rhetoric meaning control corporation poison regard except profit justice system habitually punishes poor whether black latino white health system suck religious fascism always around racist right right finally away coded rhetoric neo liberal republican light party serving corporation citizen never real problem surely everything front street side action take whole old system broken accidentally awoken action excuse rushed nature opinion ['(0, 3.6%)', '(1, 43.9%)', '(2, 14.8%)', '(3, 2.7%)', '(4, 35.0%)']\n",
      "signed biggest solar farm ['(0, 40.9%)', '(1, 14.3%)', '(2, 16.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "UAE israel peace administration heavily massive step forward huge accomplishment establishes normal relation two country including business relation tourism direct flight scientific cooperation eventually include full diplomatic tie ambassadorial level several positive especially relation china mentioned comment particular though massive win huge accomplishment ['(0, 4.4%)', '(1, 15.1%)', '(2, 25.4%)', '(3, 38.5%)', '(4, 16.6%)']\n",
      "better economy recent month v shaped recovery unemployment human trafficker caught due better border security donated salary actually lost million personal dollar pay PEACE ISRAEL AMD UAE holy shit besides iran almost country v country violence israel earned nomination nobel peace withdrawal intermediate range nuclear force INF treaty delivering china korea strategic setback tariff threat forced mexico crack illegal immigration ordered operation killed islamic state leader abu bakr al baghdadi african american unemployment achieved lowest diverse cabinet color lgb member working whitehouse ton prison reform bill ton HIV AIDS relief money bipartisan basis including criminal justice reform opioid sex trafficking legislation new right try giving dying american access experimental medication hope learns bad action policy statistical level top twitter big mouth logistical policy level amazing ['(0, 37.8%)', '(1, 16.0%)', '(2, 19.7%)', '(3, 20.3%)', '(4, 6.1%)']\n",
      "hey OP already listed positive shook expected win everyone thought hillary win kind becoming standardized clinton bush obama hillary kind became guy run new guy along wreck everything positive winning previous election bad undeniably stuff terrible public image choosing battle action pretty america however stuff divide comment torn apart decent actuality stuff colored presidency ['(0, 3.3%)', '(1, 29.1%)', '(2, 3.7%)', '(3, 35.8%)', '(4, 28.1%)']\n",
      "lowest black unemployment substantial margin tried decriminalize gay worldwide scope ['(0, 15.9%)', '(1, 12.5%)', '(2, 46.6%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "great american outdoors ['(0, 15.1%)', '(1, 14.9%)', '(2, 41.4%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "mostly apathetic populace pay attention politics realize crap system government devolved ['(0, 10.0%)', '(1, 9.1%)', '(2, 27.9%)', '(3, 18.2%)', '(4, 34.9%)']\n",
      "gave greatest political drama show ['(0, 30.5%)', '(1, 26.6%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "start war ['(0, 14.3%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 42.8%)', '(4, 14.3%)']\n",
      "remember republican celebs kissed ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "week ago started relation united arab emirate israel forty start war join international conflict ['(0, 15.4%)', '(1, 7.7%)', '(2, 15.4%)', '(3, 53.8%)', '(4, 7.7%)']\n",
      "recall banning HIKVISION camera system federal location policy garbage ['(0, 34.4%)', '(1, 11.1%)', '(2, 23.0%)', '(3, 11.1%)', '(4, 20.3%)']\n",
      "UAE israel peace treaty boarder construction replacement program two ['(0, 22.2%)', '(1, 14.2%)', '(2, 9.1%)', '(3, 45.4%)', '(4, 9.1%)']\n",
      "nominated three nobel peace recently week work israel uae peace agreement two different work stop korea actually meet leader set peace talk ['(0, 16.2%)', '(1, 21.8%)', '(2, 5.0%)', '(3, 52.4%)', '(4, 4.5%)']\n",
      "corporate news organization pissing came called fake nice bit ['(0, 12.0%)', '(1, 11.1%)', '(2, 25.4%)', '(3, 29.8%)', '(4, 21.7%)']\n",
      "proved democrat woman nypost wp content uploads site joe bide grand daughter ap jpg quality strip w ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "google prison reform actually help black unlike democrat policy ['(0, 22.6%)', '(1, 16.7%)', '(2, 34.2%)', '(3, 8.3%)', '(4, 18.2%)']\n",
      "change mind research saying bad expecting expect somebody disagree ['(0, 10.0%)', '(1, 40.0%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 30.0%)']\n",
      "careful changing mind acknowledge white supremacist ['(0, 15.2%)', '(1, 42.0%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "CMV totally brainwashed fake free represents rebrands main true source ['(0, 25.0%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 37.5%)']\n",
      "offense OP post happens due lie ommission ['(0, 15.9%)', '(1, 27.0%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "suggest looking FACTS ask user ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "accomplished hater fake news democrat destroyed decade arguing leftist hater fake news democrat four ['(0, 15.6%)', '(1, 10.0%)', '(2, 41.3%)', '(3, 18.2%)', '(4, 14.9%)']\n",
      "record number arrest human trafficking credit preventing child trafficked sex ['(0, 48.9%)', '(1, 8.3%)', '(2, 25.0%)', '(3, 9.4%)', '(4, 8.3%)']\n",
      "brave call wrong dude fucking blight saying general consensus place ask actual answer opposing opinion ['(0, 7.1%)', '(1, 42.9%)', '(2, 7.1%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "thread taught believe hate ['(0, 12.5%)', '(1, 25.0%)', '(2, 12.5%)', '(3, 25.0%)', '(4, 25.0%)']\n",
      "f yr bigoted democrat positive impact yr viewfinder blurred ['(0, 12.5%)', '(1, 25.0%)', '(2, 25.0%)', '(3, 12.5%)', '(4, 25.0%)']\n",
      "public aware fake news term didnt exist elected public aware china cheating economically public aware obama clinton angel ['(0, 6.1%)', '(1, 52.7%)', '(2, 9.3%)', '(3, 26.0%)', '(4, 5.9%)']\n",
      "haha neither obama positive childish ['(0, 14.3%)', '(1, 14.3%)', '(2, 26.1%)', '(3, 16.7%)', '(4, 28.6%)']\n",
      "compared liberal literally destroying country inside ['(0, 12.6%)', '(1, 35.2%)', '(2, 12.5%)', '(3, 21.1%)', '(4, 18.6%)']\n",
      "exposed flaw US version government check balance required ['(0, 11.3%)', '(1, 11.1%)', '(2, 29.7%)', '(3, 16.5%)', '(4, 31.4%)']\n",
      "technically brought current darkness ['(0, 18.0%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 32.0%)']\n",
      "blind pig find acorn freakishly stupid surprised accidentally stumble ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "helped bring peace israel UAE domestically helped economy arguably worse cutting deficit fueled fed inflation ['(0, 8.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 50.0%)', '(4, 8.3%)']\n",
      "shone light corrupt party McConnell graham cruz et al drained swamp thought ['(0, 11.1%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 55.5%)']\n",
      "healthy distrust pretty though ['(0, 14.3%)', '(1, 42.9%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "prison reform pretty big donated presidential paycheck helping veteran administration killed terrorist soleimani helped begin peace israel united arab emirate million job created right try legislation let sick feel option try experimental healthcare approach ['(0, 34.0%)', '(1, 17.6%)', '(2, 14.8%)', '(3, 20.9%)', '(4, 12.7%)']\n",
      "positive lay eye beholder recall seeing single trending popular post save sea apnews 2d5947a8bd924adc9f0ab077177fabdd amd heard great american outdoors federalnewsnetwork management great american outdoors lied tried calling release methane whatever wing blasted wanting trim forest prevent wildfire whitehouse gov presidential action eo promoting active management america forest rangeland federal land improve condition reduce wildfire risk conveniently forgot administration pushed huge wilderness protection bill newsweek wilderness protection bill sign environment largest death valley affordable clean energy bill flak restrictive obama new york conveniently forgot ran article supreme court blocked obama legislation place nytimes politics supreme court block obama epa coal emission regulation html heck google windmill hundred hit repeating article claiming hate windmill alive sued bird death argusleader story news wind energy project must nagivate rule protect bird nixed npr org section thetwo accidentally killing bird isnt crime administration cut bunch repopulated animal endangered list specie bee added fws gov midwest endangered insect rpbb FAQsFinalListing html kind groundwork series bee protection skip red tape force take bee specie area instead later TheHill impressed largest complaint NASA plan coming thehill opinion technology offer promise space force nasa second term talk court appointment maybe average working person money whitehouse gov briefing statement j delivered record breaking result american three office single impact elect socialist undone played ['(0, 30.1%)', '(1, 22.6%)', '(2, 28.5%)', '(3, 9.7%)', '(4, 9.1%)']\n",
      "pulled TPP madeus citizen subject IP created country without approval voter ['(0, 30.4%)', '(1, 27.9%)', '(2, 14.9%)', '(3, 16.8%)', '(4, 10.0%)']\n",
      "basically america war sharpen focus took office despite resistance chicken hawk party deep state killed two biggest terrorist start new war getting syria ended ISIS appointed effective surrogate menuchin negotiate successful coronavirus relief massive ventilator PPE production spurred presidential action massive undertaking distribute coronavirus vaccine soon effective produced offer effective federal assistance combat crime urban area chicago reduction violent crime assistance accepted lowest unemployment highest real wage growth lower income quintiles criminal justice reform greatly improved trade agreement canada mexico demanded ally contribute defense rather american taxpayer underwrite improved VA health system attempting prescription drug available US price country hospital price transparency appointed competent federal judge level politician lived word ['(0, 42.0%)', '(1, 4.5%)', '(2, 13.7%)', '(3, 16.1%)', '(4, 23.7%)']\n",
      "watch vernon jones RNC black democrat gone rogue used CEO ['(0, 12.5%)', '(1, 22.2%)', '(2, 31.9%)', '(3, 11.1%)', '(4, 22.2%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "nod tax bill positively effected income ['(0, 29.7%)', '(1, 12.5%)', '(2, 32.8%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "hate never support credit credit due improve diplomatic relation korea started prison reform overdue else forced republican party take hard political faction forever changed term simply took advantage base baiting DECADES add allowing stock buy airline industry getting bailout money exactly bailout given burned reserve cash greed ['(0, 25.5%)', '(1, 21.8%)', '(2, 3.2%)', '(3, 27.1%)', '(4, 22.4%)']\n",
      "honestly hard government vast body government function happened fair campaign promise kept specifically list sign resolution reverse obama executive order gun control signed presidential memorandum officially directing united state withdraw trans pacific partnership signature symbolic campaign promise white house promising administration enforce rid excessive legislation nominates neil gorsuch fill empty supreme court seat scalia pulling paris climate agreement create percent repatriation tax new repatriation tax percent close bill passed business holding asset overseas allowed repatriate asset percent percent liquid asset guantanamo bay detention center open suspend immigration terror prone place move embassy tel aviv jerusalem limit legal immigration create private white house veteran hotline happy holiday ask country protect pay joint defense reverse barack obama cuba policy ensure funding historic black college defund planned parenthood use steel infrastructure project lifetime ban white house official lobbying foreign government effect raise tariff imported increase veteran health save carrier plant indiana cut social security proposed cut congress bite end defense sequester take salary politifact truth meter promise list promise _group trumpometer ruling promise kept politifact truth meter promise list promise_group trumpometer ruling promise kept bad impossible perspective stance china idea dropped TPP leaving TPP great idea achievement subjective ['(0, 30.6%)', '(1, 8.5%)', '(2, 43.2%)', '(3, 8.3%)', '(4, 9.4%)']\n",
      "prior tax cut job united state highest corporate tax industrialized tax company largest expense despite fact tax generated came corporate tax US driving company seek tax shelter country offshore job US based business price competitive global scale change tax able pas allow american business compete better internationally minimal impact overall tax revenue fact increase business stay US generate tax revenue haul ['(0, 14.4%)', '(1, 13.6%)', '(2, 62.2%)', '(3, 3.9%)', '(4, 6.0%)']\n",
      "crimea annexed obama administration mostly reluctance obama specifically refused sell deadly weaponry ukrainian reluctant approve significant factor bringing stability region democrat administration wherewithal move embassy jerusalem appointing nikki haley call foreign policy loudmouth seems mostly decision ['(0, 4.8%)', '(1, 9.7%)', '(2, 61.0%)', '(3, 15.0%)', '(4, 9.5%)']\n",
      "blocked TPP hate fucker gotta credit due ['(0, 33.3%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 33.3%)', '(4, 11.1%)']\n",
      "brought awareness divided country influenced younger generation politics ['(0, 11.8%)', '(1, 32.1%)', '(2, 11.1%)', '(3, 12.2%)', '(4, 32.8%)']\n",
      "raising smoking age high schooler buy high schooler rise vapeing override ['(0, 14.3%)', '(1, 14.3%)', '(2, 42.8%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "changed international postal competitive order locally ordered AliExpress wondered shipping free china pay shipping country local shipping including expensive mile UPU net sender net recipient china took chunk ecommerce postal organization around net recipient started suffer alongside factor changed USA country suffering en wikipedia org universal _postal _union shifting _balances _and _the _united _states en wikipedia org universal_postal_union shifting_balances_and_the_united_states note fan stopped clock right twice ['(0, 11.9%)', '(1, 16.6%)', '(2, 29.3%)', '(3, 37.5%)', '(4, 4.7%)']\n",
      "presidency expose corruption racism including BLM mainstream socio economic disparity ['(0, 10.0%)', '(1, 20.0%)', '(2, 30.0%)', '(3, 10.0%)', '(4, 30.0%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "super emphasized explicitly reaching black american looking actively diversify republican party end particularly positive legacy side typical republican politician conservative generally uncomfortable appeal universalist touch race capitulate called racist likely buy common knowledge among political elite black destined vote bloc diversity republican party bring accountability party lessening extent charge racism used wedge issue funding restoration historically black college permanent particularly helpful feature help take issue board used wedge issue future decision based perceived patronage party wedge issue mouth service abortion republican clearly incentive never seeing solved let swallow shittiness let baby killer racist power ['(0, 13.8%)', '(1, 17.3%)', '(2, 7.7%)', '(3, 3.2%)', '(4, 58.0%)']\n",
      "dunno credit tension USA korea heard threatening use nuclear weapon tax cut nice affected money money super educated local government politics experience fully handled county decision regarding lockdown reason pandemic poorly handled choosing open close pandemic mention anti vaxxers anti masker completely disregarding safety measure unfair blame person bad stuff tension east referring upset maybe better insight idrk exactly experience political sub trying chill asking insight side feel looking hard stuff weird accusation mental gymnastics credit bad stuff instead looking stuff right front support biden hillary worse choice wish mild choice politics seem wildly shifted annoying treated point showed biased source felt CNN FOX unbiased trustworthy source feel news report ['(0, 16.2%)', '(1, 28.2%)', '(2, 7.3%)', '(3, 31.0%)', '(4, 17.4%)']\n",
      "positive take negative take depend side spectrum fall side positive negative step ring thinking loser managed unify folk support vote able organize side opponent side single handily impressive feat opinion turn vote getting taking action organizing speaking opponent else thank difference cast aside common enemy love em hate em vote next week voted alone amazing push trigger show hand undoes facade elected official longer hide behind scene filter expose priority wear shame matter reelected presence ushered deserved needed change politics never old fading newer era progressive capitalist leap fray igniting fire congress never face mirror change challenged deep seated corrupted politician proved untouchable miserable old miser behind younger innovative thinker relying news tell seeking truth everything hear relying doctored document article tell feel studying researching sorting fact fiction longer satisfied accepting told global community opinion call pot black mirror remember kettle america barely qualifies gen z next country russia china deep seated hatred disgust denial history american rallying pushing towards new forward single person known area history accomplished new blood popping never heard move difference thier level magnification whole watching watching closer turning blind eye love em hate em matter tonight name mentioned talking asking question thinking deeply matter fix wrong yes specifically impressive yes equal opposite vote talk discussion feel free hear doesnt wrong understanding compassion shared side battlefield end remember child ['(0, 6.0%)', '(1, 55.9%)', '(2, 10.2%)', '(3, 11.2%)', '(4, 16.7%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "insulin dropping price worst bad imo worse bad obama btw imo dont daminor bad ['(0, 16.7%)', '(1, 41.7%)', '(2, 15.2%)', '(3, 9.8%)', '(4, 16.7%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "pretty debate statement validity ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "number nearly started war soooo perhaps net positive dicey ['(0, 11.6%)', '(1, 9.1%)', '(2, 27.3%)', '(3, 27.3%)', '(4, 24.8%)']\n",
      "space force feel separation armed force help streamlines function ['(0, 49.6%)', '(1, 20.0%)', '(2, 10.4%)', '(3, 10.0%)', '(4, 10.0%)']\n",
      "neutral impact national metric system adoption please ['(0, 22.1%)', '(1, 25.0%)', '(2, 16.5%)', '(3, 12.5%)', '(4, 23.9%)']\n",
      "cause major reform system future positive impact pretty major ['(0, 16.1%)', '(1, 21.4%)', '(2, 7.1%)', '(3, 24.3%)', '(4, 31.0%)']\n",
      "youth politically fear anger ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "executive order combat human trafficking fan trying help combat HT big ['(0, 43.7%)', '(1, 15.4%)', '(2, 8.0%)', '(3, 17.6%)', '(4, 15.4%)']\n",
      "handwringing nobel peace nomination brokering normalization relation UAE israel significant achievement worthy nobel peace record whole certainly worthy finally clear personally responsible ['(0, 5.6%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 66.7%)', '(4, 5.6%)']\n",
      "supporter shorter anti animal cruelty ['(0, 39.1%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 16.5%)', '(4, 22.2%)']\n",
      "worth mentioning peace attempt east UAE country forgetting formally recognizing israel sovereign legal nation huge peace region incredible ['(0, 6.9%)', '(1, 8.0%)', '(2, 26.5%)', '(3, 52.0%)', '(4, 6.7%)']\n",
      "gotten american politics level dont happened ['(0, 11.4%)', '(1, 10.4%)', '(2, 28.9%)', '(3, 10.0%)', '(4, 39.2%)']\n",
      "signed measure congress gov bill 116th congress senate bill preserve native language article cbc ca news canada measure protect indigenous language ['(0, 45.6%)', '(1, 7.7%)', '(2, 19.0%)', '(3, 11.3%)', '(4, 16.4%)']\n",
      "step e prison reform en wikipedia org first_step_act ['(0, 28.1%)', '(1, 11.1%)', '(2, 22.2%)', '(3, 14.1%)', '(4, 24.4%)']\n",
      "supporter site luck getting real answer ['(0, 11.1%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 55.5%)']\n",
      "new regime change war past plus ['(0, 12.4%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 43.1%)', '(4, 22.2%)']\n",
      "starting war lifetime change yeah best ['(0, 12.5%)', '(1, 12.5%)', '(2, 25.0%)', '(3, 25.0%)', '(4, 25.0%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "ask question bidens government service ['(0, 26.0%)', '(1, 12.5%)', '(2, 13.5%)', '(3, 25.0%)', '(4, 23.0%)']\n",
      "gotta jump feel changed presidency opinion moral changed better worse changed better forget change soon leaf office finally apply enough american consider positive impact USA ['(0, 5.5%)', '(1, 34.3%)', '(2, 6.2%)', '(3, 22.7%)', '(4, 31.2%)']\n",
      "young politics change next ['(0, 13.2%)', '(1, 24.3%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 37.5%)']\n",
      "number bother actually tried killing abu bakr al baghdadi al baghdadi killed military personnel spite effort try stop please credit ['(0, 26.8%)', '(1, 15.4%)', '(2, 16.2%)', '(3, 33.9%)', '(4, 7.7%)']\n",
      "tell biden politician ask vote career politician ['(0, 9.1%)', '(1, 36.4%)', '(2, 9.1%)', '(3, 18.2%)', '(4, 27.3%)']\n",
      "inside US live greece affected US intervention east definitely peaceful US memory bush obama though brutal destroyed country started new war managed negotiate peace treaty israel UAE argue clearly economic benefit historic ['(0, 8.6%)', '(1, 9.4%)', '(2, 10.1%)', '(3, 67.8%)', '(4, 4.2%)']\n",
      "presidency pointed serious flaw political power structure US likely lesson coming election debug system follow protocol try best break motive ['(0, 15.0%)', '(1, 28.1%)', '(2, 17.8%)', '(3, 10.8%)', '(4, 28.2%)']\n",
      "several positive impact signed great american outdoors help fund maintain national park another pointless war withdrew troop iraq allowing effective airstrikes ISIS terrorist group command killed abu bakr al baghdadi leader ISIS helped negotiate historic peace israel UAE signed CARES largest stimulus bill signed US gave million american financial support supported small business signed USMCA replaced NAFTA roughly slightly better US mexico tough stance china beneficial entire raise awareness dictatorship chinese government running created space force moving certain air force capability new branch personnel autonomy room growth ['(0, 48.4%)', '(1, 4.8%)', '(2, 7.3%)', '(3, 34.5%)', '(4, 4.9%)']\n",
      "hate guy agreed withdrawing trans pacific partnership TTP youtu GWHDPuDpay8 TTP extended copyright coverage raised price luxury video game certain fan work cosplays doujinshis fan art fan fiction spin work subject copyright infringement criminal prosecution ['(0, 18.8%)', '(1, 11.0%)', '(2, 8.7%)', '(3, 46.9%)', '(4, 14.5%)']\n",
      "tuesday signed memorandum instructing interior secretary prohibit drilling water florida coast coast georgia south carolina period ['(0, 28.6%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "legalized hemp exhaustive list miss ['(0, 33.8%)', '(1, 14.3%)', '(2, 23.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "likely increased population vote ['(0, 23.4%)', '(1, 37.5%)', '(2, 14.1%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "controversial eye half country UK net positive cut tax introduced job la rona unprecedented deregulation reduced illegal immigration increased legal immigration great move US continued refuse enact insurrection deploy soldier state protest riot promoting state right federal government ['(0, 6.4%)', '(1, 13.4%)', '(2, 64.6%)', '(3, 4.7%)', '(4, 10.9%)']\n",
      "little late party chime helped broker UAE israel peace historic significant reason reason nominated nobel peace political step taken east ease tension recall bad situation past pretty impressive feat obligatory supporter disclaimer ignoring positive misguided ignoring negative ['(0, 4.5%)', '(1, 15.9%)', '(2, 4.0%)', '(3, 55.8%)', '(4, 19.8%)']\n",
      "check magapill dot nice list elect solely aggressive action towards ending human trafficking specifically child trafficking arresting pedophile exposing network ['(0, 35.1%)', '(1, 8.5%)', '(2, 26.2%)', '(3, 23.0%)', '(4, 7.1%)']\n",
      "although agree worst must contend refunding NASA creation space force powerful positive presidency ['(0, 27.3%)', '(1, 15.6%)', '(2, 9.1%)', '(3, 11.7%)', '(4, 36.4%)']\n",
      "great website listing magapill ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "significant peace agreement israel created peace east decade ['(0, 25.1%)', '(1, 8.3%)', '(2, 8.3%)', '(3, 48.3%)', '(4, 10.0%)']\n",
      "neighbor claim increased job job area industry increased paying job large company brought overseas job state ['(0, 10.2%)', '(1, 5.9%)', '(2, 67.2%)', '(3, 5.9%)', '(4, 10.8%)']\n",
      "mandatory penalty fee health insurance taken administration definitely needed shitty ['(0, 14.9%)', '(1, 22.2%)', '(2, 40.7%)', '(3, 11.1%)', '(4, 11.1%)']\n",
      "meh pet ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "brought light china quest america expense ['(0, 12.3%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 21.4%)', '(4, 44.0%)']\n",
      "signed clean ocean thats extremely positive ['(0, 37.5%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 25.0%)']\n",
      "thank posting whether liberal conservative willing LISTEN side political thread primarily liberal bashing conservative blanket statement forgotten courteous ['(0, 7.8%)', '(1, 46.0%)', '(2, 7.7%)', '(3, 7.7%)', '(4, 30.8%)']\n",
      "impact united state impact lost family member covid ['(0, 18.8%)', '(1, 33.3%)', '(2, 31.2%)', '(3, 8.3%)', '(4, 8.3%)']\n",
      "rich rich ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "american excuse ignorance dont started new war german take US military germany personally dislike US military jet nuke ramstein hard argue ['(0, 7.8%)', '(1, 18.6%)', '(2, 11.3%)', '(3, 54.9%)', '(4, 7.3%)']\n",
      "plan nominate anti war ambassador afghanistan motherjones politics pick afghanistan ambassador withdraw troop immediately ['(0, 8.8%)', '(1, 8.3%)', '(2, 8.3%)', '(3, 57.9%)', '(4, 16.7%)']\n",
      "jan leave positive impact leaf ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "small business owner signing tax cut job included QBI deduction allows small business owner layman term pay federal income tax gross earnings experience tax cut business help degree offset dramatically higher self employment tax pay w2 employee instead half pay business personal component tax towards social security medicare mention putting extra money away saving expending needed equipment business pay ton tax help small bit capped high earning business take advantage break ['(0, 21.9%)', '(1, 9.0%)', '(2, 63.4%)', '(3, 3.3%)', '(4, 2.4%)']\n",
      "music modernization stop music IP stolen used without proper payment artist en wikipedia org music_modernization_act ['(0, 13.0%)', '(1, 11.1%)', '(2, 34.5%)', '(3, 19.1%)', '(4, 22.2%)']\n",
      "lament raise legal smoking age ['(0, 17.8%)', '(1, 16.7%)', '(2, 32.2%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "recently played significant role brokering increased economic diplomatic relation kosovo serbia google amp thehill opinion international webb serbia kosovo move forward help united state 3famp ['(0, 23.3%)', '(1, 15.0%)', '(2, 40.2%)', '(3, 14.3%)', '(4, 7.1%)']\n",
      "took BLM global NFL apologize kaepernick NASCAR ban confederate flag mississippi take racist flag confederate flag banned US military rename base named confederate general killed big coal USA paris accord agreement actual progress climate change gotten woman color elected ['(0, 5.9%)', '(1, 25.2%)', '(2, 5.5%)', '(3, 36.8%)', '(4, 26.6%)']\n",
      "decade road government oppressive regularly committed war crime representative protect serve citizen destroyed government destroy build government shit ['(0, 20.9%)', '(1, 16.7%)', '(2, 9.1%)', '(3, 16.6%)', '(4, 36.8%)']\n",
      "positive saving market crashing covid crisis real big ['(0, 18.2%)', '(1, 27.3%)', '(2, 18.2%)', '(3, 9.1%)', '(4, 27.3%)']\n",
      "whining voted ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "literally nominated nobel peace ['(0, 11.1%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 53.8%)', '(4, 12.9%)']\n",
      "clarified court proceeding outlining exactly allowed turn executive order affect person based religion established case cited future establishment try similar ['(0, 29.1%)', '(1, 21.4%)', '(2, 17.8%)', '(3, 7.1%)', '(4, 24.6%)']\n",
      "depends happens election following month definetly actively hopefully immense failure lead necessary change prevent abuse power diplomatic failure straight illegality committed future run end best happens america easily worst ['(0, 12.5%)', '(1, 17.1%)', '(2, 14.1%)', '(3, 6.3%)', '(4, 50.0%)']\n",
      "american cashed stimulus check socialist ['(0, 15.1%)', '(1, 14.9%)', '(2, 41.4%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "approved largest solar farm positive impact googled administration approves largest solar farm US expected power home administration approved proposal monday construct operate largest solar power project history issuing final permit massive facility la vega guy either better without positive bit fetched ['(0, 17.5%)', '(1, 8.3%)', '(2, 25.4%)', '(3, 16.2%)', '(4, 32.5%)']\n",
      "ugh thread talking stuff positive accomplishment guy tasked laying minefield around cambodia ended feeling positive accomplishment thinking proud randomly maim ruin next century lay minefield future politician start backing advising small government tea partyists fundamental christian state run psuedo theocracy federal government positive historical reaction catastrophic presidency single caught attention better WWII led cold war led space race created generation nerd led computer revolution allowed map genome cure disease enough timeline hitler monstrosity becomes crucial saving million perhaps dying gasp shitty status quo room new maybe shift culture away limitless capitalization industrialization fix planet maybe cultural revolution proletariat overthrow ruling class fix wealth disparity maybe realize twitter social communication McDonalds health early literally easier point hitler historically right hitler evil competent evil incompetent therefore manipulated enabled GOP hard point accomplishment seems personally generated executive order undoing obama personal admission entire cabinet chosen desire collapse government hell FEC oversee election appointed enough member quorum figurehead lightning rod distraction overall agent chaos raising china issue american public deserved central government worse intolerable pretty everything else personally entire terrible flawed tainted bad reason right refusing acknowledge interpersonal familial love feel tainted discolored fundamental MO mortage term health country trade short term profitability ruling class thread giving credit signing bill didnt create endorse understand read bill point work n korea visiting kim jong un benefit kim jong un feather cap towards peace realize recognized leader legitimacy job security third dictator exist china support ransom nuclear attack food produce canada removing environmental regulation designed prevent drowning waste product signed save sea exxon cause trillion dollar spill due lax regulation underfunded agency clean dawn soap bottle floating next dead pelican yay ['(0, 23.6%)', '(1, 29.4%)', '(2, 10.6%)', '(3, 20.8%)', '(4, 15.6%)']\n",
      "stopped TPP continued hollowing american manufacturing job ['(0, 23.9%)', '(1, 11.6%)', '(2, 31.2%)', '(3, 22.2%)', '(4, 11.1%)']\n",
      "wrong tiger king never financially recover wealth gathered top rear accelerated unprecedented speed valuable infrastructure dissapeared deficit grew hard soft power dwindled take pre level guy power dynamic shifted favour totalitairian regime ally alienated pact broken female leader verbally abused basically insulting whole country ['(0, 6.0%)', '(1, 41.5%)', '(2, 5.6%)', '(3, 6.0%)', '(4, 40.9%)']\n",
      "banned TikTok started prison reform supporter argumentative ['(0, 17.3%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 22.2%)', '(4, 38.3%)']\n",
      "agree press given challenge beginning presidency big atrocious personality combined lack compassion destroyed foundation country night revelation regarding lying covid potential danger nation proverbial straw broke camel ['(0, 8.4%)', '(1, 49.0%)', '(2, 16.7%)', '(3, 9.3%)', '(4, 16.7%)']\n",
      "single positive impact period inherited real estate safety net failed almost business venture apprentice pretend businessman right ['(0, 7.9%)', '(1, 31.8%)', '(2, 26.1%)', '(3, 7.9%)', '(4, 26.4%)']\n",
      "believe changed american foreign policy better win finally disengaging china better including obama domestic issue disaster wish mouth shut internal issue ['(0, 6.2%)', '(1, 6.2%)', '(2, 29.9%)', '(3, 26.7%)', '(4, 31.0%)']\n",
      "best shot peace united entire ['(0, 11.1%)', '(1, 11.1%)', '(2, 33.3%)', '(3, 33.3%)', '(4, 11.1%)']\n",
      "half trillion debt ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "tuesday actually expanded renewed ban drilling FL include atlantic side SC ['(0, 14.3%)', '(1, 42.9%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "taught american happens blame voter apathy vote voter november around asking vote lesser two evil everyone pretty answer question ['(0, 7.3%)', '(1, 64.0%)', '(2, 8.7%)', '(3, 6.7%)', '(4, 13.3%)']\n",
      "donated VA campaign early presidency wanted reform VA taken better hasnt disrespecting word ['(0, 42.9%)', '(1, 10.0%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 27.1%)']\n",
      "bombarded reply thank keeping open opinion hard nowadays step high horse comfort reasonable right leaning moderate ['(0, 12.5%)', '(1, 32.7%)', '(2, 18.2%)', '(3, 26.1%)', '(4, 10.5%)']\n",
      "topic considering date sept 11th victim compensation fund permanent fund due expire victim file claim compensated ['(0, 33.3%)', '(1, 11.1%)', '(2, 22.2%)', '(3, 22.2%)', '(4, 11.1%)']\n",
      "successfully flushed white supremacist hiding open ['(0, 15.8%)', '(1, 27.0%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "running tab confirmed positive actually presidency ['(0, 12.5%)', '(1, 25.0%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 37.5%)']\n",
      "thought positive basically impossible US positive impact guy suck negative positive ['(0, 7.7%)', '(1, 23.1%)', '(2, 9.5%)', '(3, 13.6%)', '(4, 46.1%)']\n",
      "positive shown bad america another post somewhere today oompa loompa doom problem worse woken glaring issue facing daily basis change change painfull change needed usually lead change westernised country genuinelly hope november ball rolling actually america great ['(0, 4.1%)', '(1, 47.3%)', '(2, 8.0%)', '(3, 4.6%)', '(4, 36.0%)']\n",
      "ISIS essentially disappeared administration major positive ['(0, 13.1%)', '(1, 11.1%)', '(2, 22.2%)', '(3, 31.4%)', '(4, 22.2%)']\n",
      "small banned bump stock modification weapon appreciate ['(0, 42.2%)', '(1, 14.9%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "border security valued major party USA review behavior obama administration confirm ready instrumental bringing real change border security ['(0, 7.5%)', '(1, 11.7%)', '(2, 26.8%)', '(3, 30.5%)', '(4, 23.5%)']\n",
      "delta thread given freely stuff offered either bogus hold minimum scrutiny ['(0, 11.1%)', '(1, 33.3%)', '(2, 11.1%)', '(3, 33.3%)', '(4, 11.1%)']\n",
      "mishandling pandemic exposed american flawed healthcare system ['(0, 23.4%)', '(1, 10.7%)', '(2, 16.7%)', '(3, 20.0%)', '(4, 29.2%)']\n",
      "worst leader failure representing country democracy everything blatant lie lying taking highest turnover office staff failing unite troubling hey stock market conservative comment seem signed office suddenly large amount ups dude seems fond putin dictator russia routinely opposition killer ['(0, 19.8%)', '(1, 27.6%)', '(2, 20.8%)', '(3, 12.6%)', '(4, 19.2%)']\n",
      "brokering largest peace history entire whitehouse gov briefing statement j secured historic israel united arab emirate advance peace prosperity region google amp nytimes politics israel united arab emirate uae amp html able successfully broker peace israel UAE never happened ['(0, 8.7%)', '(1, 4.4%)', '(2, 26.1%)', '(3, 44.7%)', '(4, 16.2%)']\n",
      "permanently funded black university signed right try criminal justice reform black jail list worth ['(0, 53.5%)', '(1, 9.1%)', '(2, 12.5%)', '(3, 14.8%)', '(4, 10.1%)']\n",
      "boat parade combined ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "veiled propaganda thread always groomed fucked daughter epstein ['(0, 14.3%)', '(1, 42.8%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "historic eastern peace treaty uae israel normalized relation lead nation creating stronger anti iran coalition region historic tax cut regulation slashing led precovid economic growth new foreign war modern edit renegotiated great trade korea redid NAFTA trade war china damaged economy reneged iran nuclear curtailed regime ability build nuclear weapon rebuilt american military position strength addendum comment foreign war utilized restraint insuring unlike obama red line crossed syrian missile strike killing iranian revolutionary guard general projected strength without needlessly endangering american ['(0, 10.5%)', '(1, 2.4%)', '(2, 36.0%)', '(3, 48.7%)', '(4, 2.4%)']\n",
      "hospital list price shop child live saving procedure ['(0, 56.8%)', '(1, 10.0%)', '(2, 13.2%)', '(3, 10.0%)', '(4, 10.0%)']\n",
      "change change bashing ['(0, 14.3%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 42.9%)']\n",
      "starting ZERO war military intervention change mind told jimmy carter thought bombastic rhetoric send war everyone caused violence carter bad ['(0, 7.8%)', '(1, 30.8%)', '(2, 7.7%)', '(3, 30.7%)', '(4, 23.1%)']\n",
      "strongly believe learn failure mistake positive impact call insignificant learn stop idiotic couch potato vote ['(0, 10.6%)', '(1, 27.3%)', '(2, 10.0%)', '(3, 24.8%)', '(4, 27.3%)']\n",
      "EPA despite loosening regulation polluter revived superfund clean level decade official deleted seven site superfund list highest single total politico news magazine superfund activist minden wv ['(0, 40.4%)', '(1, 12.3%)', '(2, 29.0%)', '(3, 8.6%)', '(4, 9.7%)']\n",
      "least war death carter new war ['(0, 10.9%)', '(1, 20.0%)', '(2, 10.0%)', '(3, 49.1%)', '(4, 10.0%)']\n",
      "aware politically engaging right american vote whether agianst half US population voted voting ['(0, 8.7%)', '(1, 42.1%)', '(2, 27.6%)', '(3, 12.3%)', '(4, 9.3%)']\n",
      "fun trying explain republican r conservative ['(0, 12.5%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 50.0%)']\n",
      "sign federal animal cruelty bill animal cruelty felony similar ['(0, 66.6%)', '(1, 8.3%)', '(2, 8.4%)', '(3, 8.3%)', '(4, 8.3%)']\n",
      "amazes quickly forget remember ISIS problem obama heard lately ['(0, 10.3%)', '(1, 39.7%)', '(2, 16.1%)', '(3, 23.9%)', '(4, 10.0%)']\n",
      "banned critical race theory best protect 2a ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "serbia kosovo peace israel united arab emirate ['(0, 12.5%)', '(1, 12.5%)', '(2, 25.0%)', '(3, 37.5%)', '(4, 12.5%)']\n",
      "list accomplishment twitter robbystarbuck status ['(0, 17.5%)', '(1, 14.3%)', '(2, 39.6%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "nominated nobel peace work bring peace east ['(0, 9.1%)', '(1, 11.5%)', '(2, 10.0%)', '(3, 60.3%)', '(4, 9.1%)']\n",
      "opened eye incredible amount racism country ['(0, 10.1%)', '(1, 49.4%)', '(2, 20.0%)', '(3, 10.5%)', '(4, 10.0%)']\n",
      "killed TPP week office promised strongly supported obama neoliberal bizarre watching vehemently suddenly killed TPP pull trade china moron trusted vote ['(0, 42.6%)', '(1, 13.3%)', '(2, 9.5%)', '(3, 25.2%)', '(4, 9.3%)']\n",
      "accidental win instance forced NA trade agreement modernize outdated intention working class increase money rich bigger increase ['(0, 42.4%)', '(1, 18.9%)', '(2, 7.7%)', '(3, 23.3%)', '(4, 7.7%)']\n",
      "personally easier veteran use GI bill benefit without limit benefit claimed sit without using nice struggled school right away due child family illness worth complete degredation reputation US ['(0, 37.3%)', '(1, 6.0%)', '(2, 6.9%)', '(3, 44.3%)', '(4, 5.5%)']\n",
      "massive failure extreme racism beneficial america bringing belligerently limelight insulting institution demographic US outside managed expose white nationalism major threat rather ignored fringe group thought handful idiot real harm beneficial brought crap surface real ['(0, 6.3%)', '(1, 26.0%)', '(2, 5.4%)', '(3, 22.4%)', '(4, 39.9%)']\n",
      "shattered notion electability border security actually important tried canada america ['(0, 24.8%)', '(1, 20.0%)', '(2, 16.0%)', '(3, 19.1%)', '(4, 20.0%)']\n",
      "stopped tpp thats free taint corruption ['(0, 25.0%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 25.0%)', '(4, 25.0%)']\n",
      "maybe orange bad ['(0, 14.3%)', '(1, 42.9%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "divisive language biased opinion politics divisive nature always course anybody answer performance full biased opinion literally asking asking opinion expect answer non biased ['(0, 7.2%)', '(1, 35.7%)', '(2, 7.1%)', '(3, 7.8%)', '(4, 42.1%)']\n",
      "heard stated podcast today actually least warmongering modern history ['(0, 10.0%)', '(1, 50.0%)', '(2, 20.0%)', '(3, 10.0%)', '(4, 10.0%)']\n",
      "small summarisation edit reply others quick TLDR based mind changed ['(0, 20.1%)', '(1, 24.4%)', '(2, 11.7%)', '(3, 32.7%)', '(4, 11.1%)']\n",
      "hello praise timidly help entire seemed actually anti war described meeting expressed wanted end significantly cut fighting syria ISIS lost territory entire room exploded outrage general advisor war war war war war x200b ab lutely believe person inside told kind stuff hawkish government military industrial complex x200b ultimately walked commitment real shame disliked hand wheel hoping right turn chance told truth war ultimately x200b suck talking obligated hate love without exception ['(0, 4.8%)', '(1, 15.2%)', '(2, 7.1%)', '(3, 55.0%)', '(4, 17.9%)']\n",
      "surrendering taliban US alread spent nearly 3t yes trillion war afghanistan cost incurred veteran benefit term likely additional 3t getting operation handing power taliban killing US warfighters untenably unpopular democrat republican variety reason nobody surrender taliban chance money pit taking opportunity ['(0, 26.7%)', '(1, 16.1%)', '(2, 11.0%)', '(3, 27.9%)', '(4, 18.3%)']\n",
      "exposed racist bigot misogynist bringing support limelight ['(0, 16.1%)', '(1, 17.2%)', '(2, 11.1%)', '(3, 22.2%)', '(4, 33.3%)']\n",
      "given kudos stopping illegal war actually order health plan deconstructed order economy create job military commander chief order afghanistan iraq libya syria actually order excuse general let disingenuous eager convertible ride dallas either ['(0, 22.7%)', '(1, 16.6%)', '(2, 17.8%)', '(3, 38.9%)', '(4, 4.0%)']\n",
      "semi positive impact utter idiocy position smidgen smarter god forbid smart accomplished putin beyond fucked stupidity saved intellectual foe potential actually america unlivable ['(0, 11.6%)', '(1, 30.0%)', '(2, 10.0%)', '(3, 18.3%)', '(4, 30.0%)']\n",
      "postponed student loan payment till january prolonged grateful nonetheless ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "pretty easy tell swamp ['(0, 14.3%)', '(1, 42.9%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "share contribution find support truly loss fit description seems smothered vitriol diversion divisiveness dishonesty lifelong independent voted party start impatient hoped positive achieved feeling cheated afraid democracy given bloodshed hatred mistreatment child name calling death mayhem hard whether found true ['(0, 13.4%)', '(1, 39.5%)', '(2, 5.9%)', '(3, 17.6%)', '(4, 23.5%)']\n",
      "best reason reason started new war beat ['(0, 9.7%)', '(1, 9.1%)', '(2, 18.2%)', '(3, 53.9%)', '(4, 9.1%)']\n",
      "nominated principled supreme court judge thought nominated conservative suddenly break principle start siding 3rd country fact nominated qualified principled decide huge case next stand decade possibly hundred ['(0, 5.5%)', '(1, 21.9%)', '(2, 10.9%)', '(3, 30.3%)', '(4, 31.3%)']\n",
      "positive dragged new war unlike recent predecessor ['(0, 14.0%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 41.5%)', '(4, 22.2%)']\n",
      "federal judge appointed serve changed ['(0, 24.4%)', '(1, 12.5%)', '(2, 13.1%)', '(3, 25.0%)', '(4, 25.0%)']\n",
      "positive started friendly negotiation korea lower drug price however compare disaster presidency ['(0, 23.1%)', '(1, 7.7%)', '(2, 15.4%)', '(3, 30.8%)', '(4, 23.1%)']\n",
      "AFIK gone war send troop overseas warzones ['(0, 12.5%)', '(1, 25.0%)', '(2, 12.5%)', '(3, 37.5%)', '(4, 12.5%)']\n",
      "worry child policy matter speech TV affect next generation answer absolutely trace origin opinion behavior sometimes surprising basing pop culture tv conduct unfortunately affect child looking today ['(0, 19.1%)', '(1, 43.4%)', '(2, 12.5%)', '(3, 6.3%)', '(4, 18.7%)']\n",
      "another case TDS orange bad upvotes right ['(0, 11.3%)', '(1, 34.1%)', '(2, 11.1%)', '(3, 17.1%)', '(4, 26.3%)']\n",
      "trashed reputation US opened eye truly corrupt system power helped radicalize ruling class US simply obviously mask bad saying quiet part loud politician shit obama created ICE kid cage finally paying attention comic book villain instead guy speech ['(0, 7.9%)', '(1, 24.1%)', '(2, 6.3%)', '(3, 38.8%)', '(4, 22.9%)']\n",
      "decent decision idea though NATO country paying fair share corruption positive impact show country power abuse show changing government ['(0, 6.4%)', '(1, 36.4%)', '(2, 6.8%)', '(3, 6.8%)', '(4, 43.6%)']\n",
      "awful absolutely right impose tariff chine sanction tech company gut especially big american company benefiting illegal unethical state ['(0, 14.8%)', '(1, 16.4%)', '(2, 38.2%)', '(3, 9.2%)', '(4, 21.5%)']\n",
      "started war ['(0, 14.3%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 42.8%)', '(4, 14.3%)']\n",
      "believe along line stopping huawei developing 5g info structure brazil ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "family member great economy virus came messed everything ['(0, 22.6%)', '(1, 20.0%)', '(2, 37.4%)', '(3, 10.0%)', '(4, 10.0%)']\n",
      "incorrect paved everyman become become JK rowling start new war polite politician around shown digital otherwise farce funny ['(0, 9.6%)', '(1, 37.6%)', '(2, 7.7%)', '(3, 29.7%)', '(4, 15.4%)']\n",
      "underrated part tax cut passed overall bad bill limiting salt deduction state local tax deduction previously total amount paid state local income tax deductible federal income tax tax cut job changed state local tax deducted effect raise tax wealthy earner high tax state tax code progressive mitch McConnell progressive hero housing price rich area fallen allowing move area great detail bad bill ['(0, 15.0%)', '(1, 7.8%)', '(2, 69.4%)', '(3, 5.2%)', '(4, 2.6%)']\n",
      "hey half ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "extended foster age limit 21yo implemented change US foster system including strengthening child welfare program story saw virtually nowhere link partial story abcnews health wirestory sign order strengthen child welfare system ['(0, 44.3%)', '(1, 6.3%)', '(2, 17.6%)', '(3, 9.1%)', '(4, 22.7%)']\n",
      "shown real snake brainwashed turn opened eye bad country HOPEFULLY spark change turn positivity ya ['(0, 7.2%)', '(1, 56.9%)', '(2, 7.1%)', '(3, 7.4%)', '(4, 21.4%)']\n",
      "tax bracket lower swore tax wrong ['(0, 11.1%)', '(1, 22.3%)', '(2, 44.4%)', '(3, 11.1%)', '(4, 11.1%)']\n",
      "wish side seems divided admit big cause fix unless understand side ['(0, 8.6%)', '(1, 57.2%)', '(2, 8.3%)', '(3, 17.4%)', '(4, 8.3%)']\n",
      "operation warp speed ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "catch disagree level semantics propaganda powerful tool average person ['(0, 16.8%)', '(1, 22.2%)', '(2, 18.3%)', '(3, 11.1%)', '(4, 31.6%)']\n",
      "nah right ['(0, 16.7%)', '(1, 24.2%)', '(2, 16.7%)', '(3, 18.3%)', '(4, 24.1%)']\n",
      "discharged student loan due disability taxed income huge disability ['(0, 14.7%)', '(1, 12.5%)', '(2, 35.3%)', '(3, 25.0%)', '(4, 12.5%)']\n",
      "damage america international reputation disrupt ability project imperial antiwar positive end destroying republican party ['(0, 10.0%)', '(1, 10.0%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 60.0%)']\n",
      "amen ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "currently reading niece book waste gotten insight guy asking old cousin ['(0, 14.5%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 42.7%)']\n",
      "maybe biased putting increasingly tough sanction taxing incoming china aswell voicing stance china china basically nazi germany disguise putting ethnic religious group camp retaking land poking india taiwan amd feel shown voice sanction executive order china terrible ['(0, 27.5%)', '(1, 31.7%)', '(2, 5.6%)', '(3, 24.2%)', '(4, 11.1%)']\n",
      "highlighted weakness society existed focus metro focus police brutality racism sexism hillary election almost attention hope office problem addressed ['(0, 11.0%)', '(1, 56.0%)', '(2, 9.1%)', '(3, 8.3%)', '(4, 15.6%)']\n",
      "israel EAU thanked bringing peace two state literally bringing peace east adding war getting war slowly obama noble peace elected bombed droned countless away civilian hostile without prejudice office bush went iraq afghanistan ending nearly two decade sending troop without real goal plan end troop coming home moved active war field end WWII ['(0, 4.5%)', '(1, 9.6%)', '(2, 6.0%)', '(3, 59.7%)', '(4, 20.3%)']\n",
      "opened due discussion personally climate mistrust worse degree worthless showcased instant smarter tackle two move cause distraction agree position necessarily least talked ['(0, 7.3%)', '(1, 42.4%)', '(2, 8.5%)', '(3, 35.2%)', '(4, 6.7%)']\n",
      "company enjoys rubbing relevant ['(0, 18.3%)', '(1, 16.7%)', '(2, 31.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "already covered commend open minded wish follow neither right driven right past irrational unmitigated hatred cost approach politics open mind ['(0, 15.4%)', '(1, 21.4%)', '(2, 7.7%)', '(3, 34.1%)', '(4, 21.4%)']\n",
      "US send troop new conflict followed draw plan ['(0, 11.0%)', '(1, 10.0%)', '(2, 10.5%)', '(3, 58.4%)', '(4, 10.0%)']\n",
      "find original article saw blog follow fortunately plenty source nytimes politics animal cruelty bill html nytimes politics animal cruelty bill html blog follow usually heavily critical particular issue collectivity applauded reader ['(0, 41.2%)', '(1, 11.8%)', '(2, 11.7%)', '(3, 5.9%)', '(4, 29.4%)']\n",
      "populist generally medical expensive capped whatever refuse clean air clean water administration increased allowable amount toxin water selling untouched alaskan wilderness gas criminal justice reform actually improve decreased federal protection financial advisor lie client money overall conman business designed agreeable ultimately take advantage trust ['(0, 52.4%)', '(1, 14.8%)', '(2, 20.9%)', '(3, 5.3%)', '(4, 6.7%)']\n",
      "bullshit country reagan biden especially obama ['(0, 11.2%)', '(1, 30.3%)', '(2, 17.8%)', '(3, 27.1%)', '(4, 13.6%)']\n",
      "ISIS gone ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "plan voting personally glad went harder china beyond speech censorship CCP literally genociding uigur million blatant displacement removal entire culture trade government though matter ask nazi existed today answer trade fully aware tariff trade human right right personally wish harder china ['(0, 23.4%)', '(1, 24.2%)', '(2, 3.6%)', '(3, 36.5%)', '(4, 12.3%)']\n",
      "executive order hire believe intern based skill degree necessarily college reaching order show shift valuing degree american society work force ['(0, 51.3%)', '(1, 12.9%)', '(2, 13.7%)', '(3, 7.8%)', '(4, 14.3%)']\n",
      "smooth relation korea stopped threatening bomb neighbour ['(0, 12.5%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 50.0%)', '(4, 12.5%)']\n",
      "killing ISIS leader removing obamacare individual mandate penalty signing hong kong human right democracy cracking illegal immigration certainly call supporter saying rather questionable ['(0, 13.2%)', '(1, 21.0%)', '(2, 14.5%)', '(3, 33.7%)', '(4, 17.6%)']\n",
      "animal abuse federal crime strange took happen ['(0, 39.8%)', '(1, 10.0%)', '(2, 10.2%)', '(3, 11.0%)', '(4, 28.9%)']\n",
      "completely opposed absolutely point agree x200b stopped republican gutting senate ethic committee move republican tried inauguration try destroy ethic committee surprise surprise right kinda stopped called pakistan pretending ally aid money indian love use detente talking pakistan airspace access afghanistan prison reform bill democrat approached prison reform labeled weak crime criminal lover fine ['(0, 28.6%)', '(1, 10.0%)', '(2, 9.3%)', '(3, 19.6%)', '(4, 32.4%)']\n",
      "disclaimer personally love playing devil advocate favour watch blow gasket list help poorer black community delgazette opinion helping black community thrive ofc covid shitstorm caused economy worth read different perspective ['(0, 8.4%)', '(1, 22.2%)', '(2, 41.6%)', '(3, 22.2%)', '(4, 5.6%)']\n",
      "wanna try asking another site ['(0, 28.6%)', '(1, 17.4%)', '(2, 14.3%)', '(3, 25.4%)', '(4, 14.3%)']\n",
      "reagan start another war achieved best economy history covid hit achieved lowest unemployment american history defeated isi ease ['(0, 6.8%)', '(1, 14.0%)', '(2, 49.2%)', '(3, 23.7%)', '(4, 6.3%)']\n",
      "supreme court pick particularly gorsuch impeccable expanded protection covering LGBT community effect ['(0, 22.2%)', '(1, 11.1%)', '(2, 43.1%)', '(3, 11.1%)', '(4, 12.5%)']\n",
      "list executive order signed signed hear half ['(0, 45.6%)', '(1, 16.6%)', '(2, 21.1%)', '(3, 8.3%)', '(4, 8.3%)']\n",
      "positively increased negativity towards US ['(0, 20.1%)', '(1, 12.5%)', '(2, 36.9%)', '(3, 18.0%)', '(4, 12.5%)']\n",
      "paid gas yesterday BOOM ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "ludicrously terrible amount republican wake corrupt party ['(0, 10.0%)', '(1, 10.0%)', '(2, 20.0%)', '(3, 10.0%)', '(4, 50.0%)']\n",
      "thanks OP posing question valid response though essentially none named hear yelling red hat defend bring trade whatever told tout actual accomplishment ['(0, 28.8%)', '(1, 30.0%)', '(2, 15.3%)', '(3, 10.0%)', '(4, 15.9%)']\n",
      "peace east considering fighting war past ['(0, 11.1%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 55.5%)', '(4, 11.1%)']\n",
      "called military industrial complex multiple high ranking official within military perpetual war spill american blood sole purpose profit source youtu x0ie3a_0muc youtu vc4vywjfjne ['(0, 9.5%)', '(1, 8.7%)', '(2, 24.1%)', '(3, 33.2%)', '(4, 24.5%)']\n",
      "hope mostly surround believe orange bad ['(0, 11.1%)', '(1, 33.3%)', '(2, 22.2%)', '(3, 11.1%)', '(4, 22.2%)']\n",
      "showed bottom barrel scrape always sink lower actually positive rise number simply vote staggering everybody registered vote went voted republican win democrat outnumber republican registration margin wider consider poll personal belief extend likely vote neo con extreme right wing anywhere near washington let alone white house positive ifs idea ['(0, 3.9%)', '(1, 49.7%)', '(2, 18.2%)', '(3, 9.4%)', '(4, 18.8%)']\n",
      "form USA heard started war fact check though ['(0, 8.4%)', '(1, 41.7%)', '(2, 16.7%)', '(3, 25.0%)', '(4, 8.3%)']\n",
      "clearly plenty positive effect top comment point latest UAE huge news week announcing pulling troop iraq failed mention ['(0, 11.7%)', '(1, 5.9%)', '(2, 19.4%)', '(3, 39.2%)', '(4, 23.7%)']\n",
      "taken ultra conservative racist movement brought forefront lie worried terrible undoing hope ['(0, 10.3%)', '(1, 20.0%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 49.8%)']\n",
      "easier identify asshole racist ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "ton interested concerned politics vote better best ['(0, 22.6%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 10.0%)', '(4, 27.4%)']\n",
      "family tax went significantly ended critical race theory ['(0, 14.3%)', '(1, 11.1%)', '(2, 41.2%)', '(3, 22.2%)', '(4, 11.1%)']\n",
      "certainly fan ignorant similarly supporter wrongdoing administration change GI bill education benefit veteran expiration date expiration date small change old policy sense ['(0, 35.2%)', '(1, 6.0%)', '(2, 17.7%)', '(3, 17.6%)', '(4, 23.5%)']\n",
      "argue legalize hemp stole native land log iirc CBD business exploded family video cuyahoga fall sell ['(0, 40.2%)', '(1, 11.2%)', '(2, 26.3%)', '(3, 11.1%)', '(4, 11.1%)']\n",
      "OP recommend researching seems mildly progressive beneficial passed presidency outside deregulation bill passed stuck congress republican blocking passing reply top comment ['(0, 17.4%)', '(1, 16.6%)', '(2, 8.3%)', '(3, 16.7%)', '(4, 41.0%)']\n",
      "increase tax trade country china preventing company leaving US ['(0, 28.6%)', '(1, 12.3%)', '(2, 26.2%)', '(3, 24.6%)', '(4, 8.3%)']\n",
      "rule accomplishment club talk accomplishment online ['(0, 13.8%)', '(1, 32.3%)', '(2, 30.7%)', '(3, 12.1%)', '(4, 11.1%)']\n",
      "definitely point peace UAE israel positive step severely ratcheting tension east country already looking thinking joining peace east hand least step thats definitely concrete point ['(0, 6.0%)', '(1, 12.1%)', '(2, 5.3%)', '(3, 55.5%)', '(4, 21.1%)']\n",
      "term isi completely destroyed massive terrorist organization went global threat ur dirty little cave protect massive bomb overnight isi created obama power vacuum destroyed hate democrat leader obama clinton negotiated tried barter actually sell firearm instead killing x200b went planned attack country course zero planned attack carried hate whatever islamic terrorism thoroughly WHOOPED ['(0, 7.9%)', '(1, 18.6%)', '(2, 10.4%)', '(3, 45.0%)', '(4, 18.1%)']\n",
      "trash prof ignorance high ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "supporter inspired traditional non voting group vote depend actively intended though least hope ['(0, 8.3%)', '(1, 53.5%)', '(2, 7.7%)', '(3, 7.7%)', '(4, 22.8%)']\n",
      "recently brokered huge historic peace agreement east remember stop pharmaceutical company abusing price significantly lower price prescription medicine ['(0, 33.8%)', '(1, 11.1%)', '(2, 21.5%)', '(3, 28.0%)', '(4, 5.6%)']\n",
      "fan glad agreed declassify CIA kennedy file ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "achieved single positive actually incredible inherit billion real term manage single achievement hard imagine incompetent ['(0, 15.0%)', '(1, 41.9%)', '(2, 7.3%)', '(3, 14.3%)', '(4, 21.4%)']\n",
      "true positive never vote republicants ['(0, 11.1%)', '(1, 22.2%)', '(2, 11.1%)', '(3, 11.3%)', '(4, 44.2%)']\n",
      "positive corona positive lifetime effect ['(0, 12.5%)', '(1, 12.5%)', '(2, 25.0%)', '(3, 12.5%)', '(4, 37.5%)']\n",
      "actually pas requiring welfare pas drug test regular basis order welfare somewhat help take welfare abuser hate guy least ['(0, 31.2%)', '(1, 28.7%)', '(2, 8.1%)', '(3, 15.4%)', '(4, 16.6%)']\n",
      "remotely fan always upvote attempt hear separate viewpoint involve trashing side ['(0, 11.1%)', '(1, 44.4%)', '(2, 11.1%)', '(3, 22.2%)', '(4, 11.1%)']\n",
      "disagree american shined light shit show american political system knowing damage person using position hopefully inspired next generation vote loud fan tampering hopefully next generation coherent steadily progressive democrat voted power ['(0, 5.7%)', '(1, 44.3%)', '(2, 14.3%)', '(3, 13.1%)', '(4, 22.6%)']\n",
      "farm bill legalized hemp federal level ending war agaisnt hemp acutal progress towards ending war drug ['(0, 48.4%)', '(1, 7.1%)', '(2, 14.5%)', '(3, 21.1%)', '(4, 8.8%)']\n",
      "work pedophile child porn ['(0, 28.6%)', '(1, 24.2%)', '(2, 16.9%)', '(3, 16.0%)', '(4, 14.3%)']\n",
      "timeless rock bottom bad prevents ilk elected sort positive right protects US future ['(0, 9.5%)', '(1, 31.1%)', '(2, 11.1%)', '(3, 16.8%)', '(4, 31.5%)']\n",
      "wellnhe gay trans right window ['(0, 16.7%)', '(1, 24.2%)', '(2, 16.7%)', '(3, 18.3%)', '(4, 24.1%)']\n",
      "sorry impossible change based fact opinion ['(0, 12.5%)', '(1, 37.5%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 25.0%)']\n",
      "yeah accomplishment directly overseen stuff work completed ['(0, 14.2%)', '(1, 17.8%)', '(2, 27.5%)', '(3, 28.0%)', '(4, 12.5%)']\n",
      "add UAE israel peace accord ['(0, 12.5%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 54.1%)', '(4, 11.1%)']\n",
      "wealthy benefiting tax policy argue broke dirt ended sending check IRS new tax save damn dime realize ask government take tax paycheck order owe tax forget getting tax return end spectrum ['(0, 16.5%)', '(1, 5.5%)', '(2, 41.4%)', '(3, 16.4%)', '(4, 20.3%)']\n",
      "wanted post rule guideline presidential power grey area clearly defined wallowing smell racist sexist bullshit always getting exposed light feel empowered exposed huge number defend racist sexist bullshit wont able pull remark gone x200b great service biggest hat possible leading follower light ['(0, 9.4%)', '(1, 22.7%)', '(2, 25.5%)', '(3, 3.8%)', '(4, 38.5%)']\n",
      "rolled water united state enacted obama single river stream culvert ditch federal control massive overreach federal authority created duplicate regulation state regs fine rolled obama horrible interpretation title XI rule apply sexual assault campus obama required college create kangaroo court steamrolled innocent men effectively presumed guilty study obama relied change never meant author study took extraordinary step public announcement obama misinterpreting result study ['(0, 16.4%)', '(1, 17.7%)', '(2, 42.5%)', '(3, 5.2%)', '(4, 18.3%)']\n",
      "positive buffoon reinforce meaning behind quote purpose serve warning others ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "hate guy space force stolen star trek logo qualify administration accomplished biggest economic crisis decade ['(0, 35.5%)', '(1, 7.7%)', '(2, 25.2%)', '(3, 15.4%)', '(4, 16.3%)']\n",
      "saw signed animal abuse federal crime maybe felony universal compared bad imagining swear saw somewhere ['(0, 41.5%)', '(1, 25.0%)', '(2, 8.5%)', '(3, 8.3%)', '(4, 16.7%)']\n",
      "success positive subjective part gas industry exec street appreciate regulation guy ['(0, 11.3%)', '(1, 11.1%)', '(2, 32.4%)', '(3, 12.0%)', '(4, 33.2%)']\n",
      "least presidency reminded importance limitation presidential government power okay obama hot seat sudden realised hand hand ['(0, 7.8%)', '(1, 15.4%)', '(2, 11.7%)', '(3, 27.1%)', '(4, 38.1%)']\n",
      "start war join war withdrawing troop overseas ['(0, 11.1%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 55.5%)', '(4, 11.1%)']\n",
      "biggest IMO presidency gotten young pay attention politics importance everyday ['(0, 17.1%)', '(1, 10.0%)', '(2, 22.9%)', '(3, 10.0%)', '(4, 40.0%)']\n",
      "cant speak USA european favour stopped TTIP CETA negotiation ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "tax cut helped job high earner high tax state didnt benefit unemployment GDP respectively took office unemployment GDP pandemic ISIS decimated troop coming home john bolton james mattis spoke war responds terrorism force saw iran known country messed brokered historic peace israel UAE forcing country help bill UN NATO signed bill veteran ability seek private medical cost VA claim processing efficient minority unemployment record low pandemic thanks part opportunity zone brought billion poor community winning trade war china war cared fight replaced NAFTA better trade worked fight discrimination persecution LGBT across elected supporting gay marriage signed executive order lower prescription drug price forcing hospital disclose pricing effort bring healthcare cost increase transparency ['(0, 43.4%)', '(1, 1.9%)', '(2, 28.1%)', '(3, 24.4%)', '(4, 2.2%)']\n",
      "war afghanistan present iraq war war west pakistan present part war terror present operation ocean shield operation observant compass american led intervention iraq present operation inherent resolve present yemeni civil war present american intervention libya present war started republican democrat humanitarian nightmare combine led death ten million innocent military clusterfucks hurt america fault started another war perhaps impeached needle death inside US obama bush face gallows million killed outside america ['(0, 11.7%)', '(1, 4.0%)', '(2, 12.3%)', '(3, 60.5%)', '(4, 11.4%)']\n",
      "hows 401k value today v obama bitch ['(0, 14.3%)', '(1, 28.6%)', '(2, 26.1%)', '(3, 16.7%)', '(4, 14.3%)']\n",
      "gonna provide rather explain feel believe united state become polarized taken extreme subject depending source either find saying terrible infallible incredibly hard find unbiased claim true accomplishment compound issue lazy research source likely biased opinion take fact ['(0, 4.1%)', '(1, 39.3%)', '(2, 18.3%)', '(3, 7.4%)', '(4, 31.0%)']\n",
      "helped end korean war facilitated peace talk israel UAE decade drag armed conflict despite fact democrat attempting impeach moment took hand bible support gay marriage entering office obama support gay marriage midway election campaign laughing nominated nobel peace obama peace obama old joke obama george bush stupid dishonest justification basically george bush grasping straw case outright lying twitter echo chamber bad echoed amplified remembered better everyone devolving tribalists taking attitude must bad reading sound unironically voting non career politician become gigantic positive matter side ['(0, 2.8%)', '(1, 31.0%)', '(2, 9.6%)', '(3, 36.7%)', '(4, 19.9%)']\n",
      "great american outdoors ['(0, 15.1%)', '(1, 14.9%)', '(2, 41.4%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "recent nobel peace nomination addition israel UAE nomination letter nobel committee cited mr key role facilitating contact conflicting party kashmir border dispute india pakistan conflict south korea ['(0, 6.5%)', '(1, 6.3%)', '(2, 6.3%)', '(3, 68.5%)', '(4, 12.5%)']\n",
      "wealthy part oligarchy positive impact powerless racist poor person desperately feel powerful loving light country fire troll liberal ['(0, 6.9%)', '(1, 44.0%)', '(2, 14.6%)', '(3, 7.8%)', '(4, 26.7%)']\n",
      "key word positive impact ton negative impact country never currupt deeper downward spiral market crash ['(0, 16.8%)', '(1, 32.6%)', '(2, 16.7%)', '(3, 9.2%)', '(4, 24.7%)']\n",
      "great outdoors np gov subject legal great american outdoors htm ['(0, 11.7%)', '(1, 11.4%)', '(2, 54.7%)', '(3, 11.1%)', '(4, 11.1%)']\n",
      "clearly divide stand managed expose kind disgusting hat bumber sticker identify po tell idiot wear mask wrong public ['(0, 10.0%)', '(1, 44.4%)', '(2, 10.0%)', '(3, 25.6%)', '(4, 10.0%)']\n",
      "christmas eve federal hisay dope ['(0, 32.5%)', '(1, 16.7%)', '(2, 17.5%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "federally legal hemp system obviously passed congress administration allowed ['(0, 19.5%)', '(1, 8.3%)', '(2, 32.7%)', '(3, 16.6%)', '(4, 22.9%)']\n",
      "challenge renewed veteran choice slight modification name change original version signed obama military daily news sign billion bill replace va choice program html specific quite short list course took credit original idea mention effectively renewal extension original e lied origin managed tarnish bad bad remaining pretty messed realize pretty hard malicious ['(0, 38.3%)', '(1, 23.6%)', '(2, 6.8%)', '(3, 22.8%)', '(4, 8.5%)']\n",
      "true helped lower american population ['(0, 11.8%)', '(1, 11.6%)', '(2, 32.2%)', '(3, 22.2%)', '(4, 22.2%)']\n",
      "animal abuse felony ['(0, 28.6%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "zero input anyrhing positive possibly brought positive impact brain power toddler ['(0, 10.3%)', '(1, 20.0%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 49.7%)']\n",
      "change objectively correct ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "problem negative impact outweigh positive large large margin ['(0, 10.4%)', '(1, 29.6%)', '(2, 30.0%)', '(3, 10.0%)', '(4, 20.0%)']\n",
      "korea problem completely table ['(0, 13.3%)', '(1, 24.2%)', '(2, 12.5%)', '(3, 37.5%)', '(4, 12.5%)']\n",
      "obama ISIS rampant constantly news korea conflict kim jong un talking possible war III threat news cycle barely talked pressing issue currently ['(0, 7.2%)', '(1, 14.3%)', '(2, 9.8%)', '(3, 54.3%)', '(4, 14.5%)']\n",
      "american korea pretty big fucking regardless hate policy huge ['(0, 8.0%)', '(1, 32.1%)', '(2, 29.2%)', '(3, 23.1%)', '(4, 7.7%)']\n",
      "term positive effect american economy regard standing country ripping US stealing intellectual property US obvious happening short term seem painful term actually unpalatable succession previous leader talk allowed perpetrator persist gradually worsen behavior ['(0, 5.1%)', '(1, 36.8%)', '(2, 39.6%)', '(3, 8.5%)', '(4, 10.0%)']\n",
      "decade send additional troop battle fact decreased overseas troop troop home ['(0, 14.4%)', '(1, 18.2%)', '(2, 9.1%)', '(3, 45.5%)', '(4, 12.9%)']\n",
      "clear govt dependent tradition politician rather enforceable ['(0, 14.3%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 42.8%)']\n",
      "recent peace israel UAE monumental ['(0, 11.9%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 54.7%)', '(4, 11.1%)']\n",
      "entire fucking economy covid suck anyway ['(0, 11.1%)', '(1, 33.3%)', '(2, 22.2%)', '(3, 22.2%)', '(4, 11.1%)']\n",
      "success country whole virus instilled fear country bogged political non sense independent acknowledge either side success side noticeable amount recently never believe ['(0, 12.4%)', '(1, 39.7%)', '(2, 11.8%)', '(3, 13.3%)', '(4, 22.8%)']\n",
      "bit early judge impact surprise record voter turn november despite pandemic obviously point source happened exactly point early tell impact direction ['(0, 5.0%)', '(1, 30.0%)', '(2, 25.0%)', '(3, 15.0%)', '(4, 25.0%)']\n",
      "absolutely loathe spirit post read earlier week found interesting politico news magazine superfund activist minden wv titled incredibly green EPA remediate superfund site administration bit mixed bag white neighborhood disproportionately prioritized completely ignored orphan site cleanup toxic waste dump undoubtedly clinton program EPA ruthless refusing settle penalty responsible party administration spectacular taxpayer bailing criminal corporation government agency either pay liquidated grew within five mile three noxious site zero sympathy heinous criminal whether chemical company navy site responsible thousand slow painful poisoning death corporate serial killer thanking profusely throwing everyone fucking gulag belong instead fining worthless paper complete cleanup CEOs general clean waste bare hand handmaid tale credit great american outdoors legislation nature grand accomplishment veto bill overwhelming support credit promotion peace iran policy fucking trainwreck dangerous brinksmanship luck iranian government wisdom prevented escalating WW3 ['(0, 28.2%)', '(1, 12.8%)', '(2, 25.2%)', '(3, 23.8%)', '(4, 10.0%)']\n",
      "destroyed ISIS acknowledge response chinese threat global existential threat previous combined fan kind joke american politician anyway nonetheless ['(0, 9.3%)', '(1, 28.1%)', '(2, 12.2%)', '(3, 28.1%)', '(4, 22.4%)']\n",
      "farm bill legalized hemp lawyered ['(0, 42.8%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "passed bill animal cruelty felony end list ['(0, 46.1%)', '(1, 10.0%)', '(2, 13.9%)', '(3, 10.0%)', '(4, 20.0%)']\n",
      "pick worry korea nukeing ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "although certainly attempt great american educated supposed legally able greater understanding position within administration filled security clearance granted fire hell without emolument ['(0, 8.9%)', '(1, 7.8%)', '(2, 51.0%)', '(3, 24.5%)', '(4, 7.7%)']\n",
      "expanded range feel qualified smart otherwise dissuaded presidency hey directly pointed quick past war war non intervention hallmark nice carry next administration ['(0, 7.6%)', '(1, 21.2%)', '(2, 14.3%)', '(3, 35.7%)', '(4, 21.2%)']\n",
      "pull couple thousand troop syria debatable whether ultimately best situation dunno ['(0, 12.5%)', '(1, 12.5%)', '(2, 25.0%)', '(3, 37.5%)', '(4, 12.5%)']\n",
      "presidency volatile public politics net positive obviously downside vigilante misinformation ['(0, 9.1%)', '(1, 18.2%)', '(2, 18.2%)', '(3, 18.2%)', '(4, 36.4%)']\n",
      "historic israel UAE treaty negotiated benefit US unemployment pretty low removed critical race theory taught government caused major divisiveness including segregation college dorm certain event however continuing taught college pulling troop afghanistan bringing home family add plenty dinner eat ['(0, 11.3%)', '(1, 7.4%)', '(2, 27.4%)', '(3, 48.9%)', '(4, 5.0%)']\n",
      "opposed harvard affirmative action case SFFA blatant bigotry asian american mind boggling reason actively support despite wokeness ['(0, 10.9%)', '(1, 29.8%)', '(2, 22.8%)', '(3, 20.1%)', '(4, 16.4%)']\n",
      "conservation import medication country started new war actively trying bring troop home ['(0, 8.9%)', '(1, 10.3%)', '(2, 8.3%)', '(3, 55.8%)', '(4, 16.7%)']\n",
      "personally best thus american aware voting ['(0, 10.5%)', '(1, 31.7%)', '(2, 27.7%)', '(3, 20.0%)', '(4, 10.0%)']\n",
      "signing bill transparency healthcare healthcare entity must itemize charge bill accurate picture stupid healthcare bill address systemic issue cost right try legislation terminal patient fuckin send try wacky experimental treatment lastly animal abuse legislation added penalty better enforced animal abuse top ['(0, 62.2%)', '(1, 4.4%)', '(2, 4.0%)', '(3, 4.1%)', '(4, 25.3%)']\n",
      "shown everyone flaw within political system urgent fix actually competent take full advantage ['(0, 9.1%)', '(1, 56.6%)', '(2, 8.3%)', '(3, 8.3%)', '(4, 17.6%)']\n",
      "ate citing mostly happened lucky didnt stop ['(0, 14.9%)', '(1, 12.5%)', '(2, 43.7%)', '(3, 16.4%)', '(4, 12.5%)']\n",
      "furthered peace relation korea killed abu ackbar lifted homelessness best certainly useless ['(0, 9.3%)', '(1, 9.1%)', '(2, 18.2%)', '(3, 54.3%)', '(4, 9.1%)']\n",
      "top administration played huge part forcing hospital insurance company disclose pricing certain common procedure front consumer insurancejournal news national htm ['(0, 16.3%)', '(1, 6.7%)', '(2, 54.6%)', '(3, 8.9%)', '(4, 13.5%)']\n",
      "country divided everything person find right another find equally bad worse heart republican talk obama vacation democratic killed bush hate side acknowledge single ounce fixing NADTA funding HBCUs perpetuity funded beyond maybe write letter congressman holding china accountable big step american class went china consider presidential personally country matter perspective ['(0, 6.7%)', '(1, 46.0%)', '(2, 3.9%)', '(3, 34.5%)', '(4, 8.9%)']\n",
      "guy person whole obvious watching side news funded national park given money repair donated dime pay different charity education fund moved embassy jerusalem deduction average american tax froze student loan interest recently UAE israel sign peace treaty country area follow suite UAE son played big hand personally prison reform attempted police reform gave mattis needed defeat isi rid soleimani easily anti war generation top loud mouth personally damage reputation wide country taking advantage kindness presence anyways bad biden harris better choice horribly hypocritical ['(0, 26.1%)', '(1, 25.7%)', '(2, 14.6%)', '(3, 24.5%)', '(4, 9.1%)']\n",
      "become politically aware engaged ['(0, 15.5%)', '(1, 41.7%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "nomination several federal judge literal interpretation constitution though conservative opinion protect fundamental freedom right established constitution check work federalist society ['(0, 16.1%)', '(1, 36.1%)', '(2, 16.1%)', '(3, 7.6%)', '(4, 24.1%)']\n",
      "bet balance family ['(0, 21.9%)', '(1, 16.7%)', '(2, 28.1%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "huge order amount money towards helping end child sex trafficking ['(0, 42.9%)', '(1, 7.1%)', '(2, 28.6%)', '(3, 7.1%)', '(4, 14.3%)']\n",
      "managed isolate US major ally edit didnt positive bit ['(0, 10.0%)', '(1, 9.6%)', '(2, 20.7%)', '(3, 41.5%)', '(4, 18.2%)']\n",
      "aussie start new hot war internal positive ['(0, 12.4%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 43.1%)', '(4, 22.2%)']\n",
      "knew worse expected quite literally worst person role tearing country apart constitution truth decency devil atheist ['(0, 9.2%)', '(1, 35.5%)', '(2, 9.1%)', '(3, 11.5%)', '(4, 34.8%)']\n",
      "blatantly corrupt winning presidency despite popular choice identified urgent reform government top bottom definitely positive ['(0, 19.8%)', '(1, 7.7%)', '(2, 15.8%)', '(3, 7.7%)', '(4, 49.1%)']\n",
      "broke clock right ['(0, 16.7%)', '(1, 24.3%)', '(2, 16.7%)', '(3, 18.3%)', '(4, 24.1%)']\n",
      "hate trending ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "dominionists penny pompeo happy move jerusalem embassy big jesus freak trying game theory end big list ['(0, 8.1%)', '(1, 24.6%)', '(2, 36.6%)', '(3, 7.7%)', '(4, 23.1%)']\n",
      "israel UAE sign peace bad ['(0, 20.0%)', '(1, 20.0%)', '(2, 10.0%)', '(3, 40.0%)', '(4, 10.0%)']\n",
      "step renegotiated trade mexico canada NAFTA didnt sign TPP scaling overseas troop presence NATO member spend defense hospital price transparency removed individual mandate animal cruelty federal offense CBD hemp legalization allowing small business buy insurance group better pricing right try increase energy export EU VA reform edit UAE israel promiseskept achievement overview justice ['(0, 70.1%)', '(1, 3.6%)', '(2, 4.1%)', '(3, 18.6%)', '(4, 3.6%)']\n",
      "ended tax health insurance ['(0, 16.0%)', '(1, 11.1%)', '(2, 50.7%)', '(3, 11.1%)', '(4, 11.1%)']\n",
      "okay hard mode appended altruistic reason sentence ['(0, 16.0%)', '(1, 26.8%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "tariff great raw steel production US however stressful agriculture ['(0, 22.2%)', '(1, 11.1%)', '(2, 25.4%)', '(3, 30.1%)', '(4, 11.1%)']\n",
      "removed semblance credible deniability GOP authoritarian racist party coward sycophant criminal end defeated roundly held accountable ['(0, 14.5%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 52.2%)']\n",
      "absolute positive shining glaring spotlight hypocrisy right wing christian evangelicals right ['(0, 12.5%)', '(1, 18.8%)', '(2, 12.5%)', '(3, 13.8%)', '(4, 42.4%)']\n",
      "donated entire presidential salary variety cause inauguration VAs education service plenty obama convinced threatened forced bullied mexican government drastically tighten security southern border caused major decrease illegal immigration peace israel UAE everyone moving embassy jerusalem gonna light islamic radical fire yeah obama managed turn libya modern open air slave market eh changed rule engagement guy effectively fight ISIS result ISIS crushed matter month obama rule engagement getting guy killed preserve civilian exposed corruption highest level NSA FBI politician spying rival hillary spying never exposed save forgo future election opponent campaign staff email phone call text win exposed extreme bias soooo spewing crap russia collusion turned ZERO EVIDENCE COLLUSION never happened least started clinton bush obama YEARS china stealing intellectual property job finally call ['(0, 10.6%)', '(1, 13.8%)', '(2, 15.9%)', '(3, 36.0%)', '(4, 23.7%)']\n",
      "war ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "dat stock market doe ['(0, 28.6%)', '(1, 14.3%)', '(2, 28.6%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "actually unintentionally opened dialogue racism equality take NFL player field brought attention cause better worse led NBA player recently taking stance playoff without antagonizing movement strong ['(0, 15.1%)', '(1, 42.5%)', '(2, 8.1%)', '(3, 16.9%)', '(4, 17.4%)']\n",
      "tell bad information information ['(0, 14.3%)', '(1, 42.9%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "try change state fact ['(0, 22.2%)', '(1, 22.2%)', '(2, 22.2%)', '(3, 11.1%)', '(4, 22.2%)']\n",
      "flaw american political system desperately fixing glaringly obvious hope around another four place solidify ['(0, 9.5%)', '(1, 52.2%)', '(2, 11.9%)', '(3, 10.1%)', '(4, 16.3%)']\n",
      "started decoupling china america needed fucking concentration camp shit whoever next biden carry thrust political limelight democrat republican tough china serious level impact everything else crap ['(0, 5.6%)', '(1, 47.5%)', '(2, 9.5%)', '(3, 18.7%)', '(4, 18.7%)']\n",
      "focus bringing child pedo ring outpaced past grouping consecutive ['(0, 25.0%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 37.5%)', '(4, 12.5%)']\n",
      "clearly unequivocally shown corruption flaw country government country use presidency change necessary avoid election another leader ilk work towards eliminating rampant corruption within government positive ['(0, 9.9%)', '(1, 35.4%)', '(2, 10.4%)', '(3, 6.8%)', '(4, 37.6%)']\n",
      "support heap bullshit ['(0, 24.2%)', '(1, 25.8%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "fact choice better worse decision USA proven delusional without decision biased fact little common sense ['(0, 15.2%)', '(1, 33.3%)', '(2, 10.3%)', '(3, 9.6%)', '(4, 31.5%)']\n",
      "foreign policy overwhelming success metric ['(0, 14.3%)', '(1, 14.3%)', '(2, 42.9%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "joe biden single change united state case pretty jojo2020 ['(0, 8.5%)', '(1, 33.3%)', '(2, 25.0%)', '(3, 8.3%)', '(4, 24.9%)']\n",
      "managed cool korea v west feud simply matching kim jong un crazy told china despite despite everything overall fighting powerful evil government ['(0, 8.1%)', '(1, 18.4%)', '(2, 25.5%)', '(3, 35.3%)', '(4, 12.8%)']\n",
      "disagreed korea talk happening fallen apart pretty ['(0, 12.5%)', '(1, 34.7%)', '(2, 12.5%)', '(3, 27.8%)', '(4, 12.5%)']\n",
      "mind raising smoking age ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "file large manila envelope titled shit ['(0, 14.3%)', '(1, 28.6%)', '(2, 28.6%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "troop withdrawal east historic israel UAE peace new war past job united state minority ['(0, 6.1%)', '(1, 5.9%)', '(2, 23.5%)', '(3, 58.6%)', '(4, 5.9%)']\n",
      "yes given meme obama ['(0, 14.3%)', '(1, 28.6%)', '(2, 26.1%)', '(3, 16.7%)', '(4, 14.3%)']\n",
      "personally politics ['(0, 14.3%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 28.6%)']\n",
      "objectively decision interest ended postal treaty disadvantaged USPS relative country backed war thought outweighed objectively bad reason honest right accidental ['(0, 9.5%)', '(1, 21.1%)', '(2, 12.0%)', '(3, 32.9%)', '(4, 24.5%)']\n",
      "hospital must disclose price starting progress toward border protection deportation limit population control climate otherwise killing political correctness withdrew troop east proposed peace plan brokered peace treaty israel palestine negotiated new trade agreement mexico canada china killed NAFTA replaced USMCA donates salary work free economy booming lowest unemployment highest stock market exposed corruption stopped human trafficking US energy independence jailed human trafficers ['(0, 38.0%)', '(1, 3.6%)', '(2, 11.3%)', '(3, 39.9%)', '(4, 7.3%)']\n",
      "hate guy delight pay exorbitant monthly student loan bill month april believe extended december ['(0, 31.7%)', '(1, 9.1%)', '(2, 14.4%)', '(3, 18.2%)', '(4, 26.6%)']\n",
      "let forget love new immigrant canada spent two stepping away career move NYC order start new adventure halted visa work studying ultimately affected negatively situation positive agree single positive impact date international perspective staying NYC watching news eye opening badly governed pray NYC rise stronger place love ['(0, 14.9%)', '(1, 46.0%)', '(2, 5.1%)', '(3, 21.9%)', '(4, 12.1%)']\n",
      "beg listen carefully remember share bill moyers white house press secretary johnson administration historian political commentator discus mike lofgren congressional staff member capitol hill accountant regarding inner working finance power wealthiest powerful nation earth discussion forth public broadcasting service relevant hiding plain sight american deep state pb org video moyers company deep state hiding plain sight pb org video moyers company deep state hiding plain sight rather changing video broaden showcase america truly ran powerful vested interest served yield whichever party occupies executive branch four television noam chomsky asked thought american foreign policy ['(0, 17.7%)', '(1, 17.6%)', '(2, 43.5%)', '(3, 3.0%)', '(4, 18.2%)']\n",
      "help mediate armistice south korea else ['(0, 20.7%)', '(1, 22.2%)', '(2, 12.7%)', '(3, 33.3%)', '(4, 11.1%)']\n",
      "historic UAE peace treaty doesnt count ['(0, 11.1%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 55.5%)', '(4, 11.1%)']\n",
      "weigh pet project israel embassy move total destruction barack obama devisiveness hate engenders difficult value cost benefit scenario presidency ['(0, 23.1%)', '(1, 8.2%)', '(2, 28.3%)', '(3, 25.0%)', '(4, 15.4%)']\n",
      "personally radical party level headed point fact biased side ridiculous ['(0, 9.7%)', '(1, 27.3%)', '(2, 9.1%)', '(3, 18.2%)', '(4, 35.7%)']\n",
      "great american outdoors ['(0, 15.1%)', '(1, 14.9%)', '(2, 41.4%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "aware nazi woken white moderate type mlk disparaged enough million maybe hundred million globally admittedly least split keeping myopic technically benefit ['(0, 29.5%)', '(1, 49.1%)', '(2, 7.1%)', '(3, 7.1%)', '(4, 7.1%)']\n",
      "hate admit threw wrench american political cycle paying attention otherwise remained undisturbed voter turnout projected biggest election million new unreliable voter planning voting face enemy american facing right class struggle ['(0, 20.7%)', '(1, 44.0%)', '(2, 10.3%)', '(3, 19.5%)', '(4, 5.6%)']\n",
      "dumbest shit imaginable diplomatoc progress korea corporate tax break leading booming economy tough china fucking break ['(0, 9.4%)', '(1, 27.3%)', '(2, 27.2%)', '(3, 26.9%)', '(4, 9.1%)']\n",
      "suck biden suck suck least obama feel big ball doesnt realize using em wrong ['(0, 8.3%)', '(1, 50.0%)', '(2, 13.4%)', '(3, 19.9%)', '(4, 8.3%)']\n",
      "unbelievable arguably best withdrawing TPP mentioned ['(0, 25.0%)', '(1, 25.0%)', '(2, 25.0%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "waiting actually claim spoiler alert proof claim ['(0, 12.5%)', '(1, 25.0%)', '(2, 37.5%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "sound whole parliament leadership worked id assume worked member write bill form voted representative otherwise single handedly US dictatorship ['(0, 30.4%)', '(1, 29.6%)', '(2, 12.3%)', '(3, 17.7%)', '(4, 10.0%)']\n",
      "agree tariff china term impact benefit US outside hell ['(0, 26.2%)', '(1, 30.2%)', '(2, 9.8%)', '(3, 25.5%)', '(4, 8.3%)']\n",
      "depends individual politics judge positive negative please rape presidency gotten VA reform take better veteran idk behind bad though brought ton evangelicals causing half state old girl raped weird uncle incest child ameirca approach cult follows bunch potato ['(0, 27.5%)', '(1, 15.1%)', '(2, 13.6%)', '(3, 4.5%)', '(4, 39.2%)']\n",
      "leftist wanted win hillary positive impact spotlighting progressive alternative centrist status quo unfortunately DNC rigged primary bernie twice progressive momentum shot liberal elite ['(0, 11.1%)', '(1, 42.6%)', '(2, 11.1%)', '(3, 12.9%)', '(4, 22.2%)']\n",
      "love post op admits stupidity ['(0, 15.2%)', '(1, 42.0%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "used rule military temporarily place away assigned base enough compensated reduced changed ['(0, 8.4%)', '(1, 37.9%)', '(2, 8.3%)', '(3, 28.7%)', '(4, 16.7%)']\n",
      "massive federal deregulation transparency hospital price competition generic drug allowing canada anti war peace worldwide tax cut job huge removal obamacare mandate withdrawal paris accord complete revamping NAFTA USMCA list stand edit website outline promiseskept recent justice reform ['(0, 43.5%)', '(1, 3.9%)', '(2, 22.4%)', '(3, 22.4%)', '(4, 7.8%)']\n",
      "pardon snowden positive ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "best jewish ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "opinion ok pandemic fell apart started overtly racist corruption aired several credible close ['(0, 10.0%)', '(1, 20.0%)', '(2, 10.0%)', '(3, 30.0%)', '(4, 30.0%)']\n",
      "PRC learned official position communist government mao zedong bad always liked using describe leader almost always complex legacy decision huge implication inverse bad napoleon bonaparte course abe lincoln ghenghis khan figure ago asked legacy obviously result credit mass murderer g khan religious tolerance award founding space force ['(0, 22.9%)', '(1, 38.2%)', '(2, 11.6%)', '(3, 13.5%)', '(4, 13.8%)']\n",
      "revealed idiocy electoral college shown system check balance work proven idea electing businessman office horrible idea lesson positive choose learn ['(0, 8.9%)', '(1, 27.9%)', '(2, 27.8%)', '(3, 7.4%)', '(4, 28.0%)']\n",
      "change effect entertainment industry recent decade uncomfortable marriage politician shone light relationship IMO positive largely thanks normal away healthy skepticism previously lost ['(0, 10.5%)', '(1, 9.7%)', '(2, 15.4%)', '(3, 19.6%)', '(4, 44.9%)']\n",
      "OP fan east particularly israel game iran ['(0, 11.1%)', '(1, 11.1%)', '(2, 22.2%)', '(3, 44.4%)', '(4, 11.1%)']\n",
      "believe presidency field working hire america instead bringing cheap labor india friend experience finally found paying job due high demand skill low payed labor went home ['(0, 5.6%)', '(1, 11.1%)', '(2, 22.6%)', '(3, 38.5%)', '(4, 22.2%)']\n",
      "rescinded dear colleague letter gave accuser legal right kangaroo court obama ruling UAE irasel pretty historic carter enter new conflict tax cut opportunity zone poor minority area ['(0, 13.0%)', '(1, 13.1%)', '(2, 41.1%)', '(3, 26.6%)', '(4, 6.2%)']\n",
      "korea right away east anymore military idustrial complex boogie ['(0, 10.0%)', '(1, 14.5%)', '(2, 10.0%)', '(3, 53.1%)', '(4, 12.3%)']\n",
      "kinda humbling america call USA america nobody mexico canada american let alone hemisphere gone terrible maybe needed humbling contrition ['(0, 18.6%)', '(1, 38.6%)', '(2, 7.2%)', '(3, 13.4%)', '(4, 22.2%)']\n",
      "argue job deescalating tension korea mostly generally speaking hard militarily bad move everything situation worse atleast average american ['(0, 7.7%)', '(1, 35.9%)', '(2, 36.4%)', '(3, 13.3%)', '(4, 6.7%)']\n",
      "push china great change including run becoming independent china help american run excuse tax cut thr majority american tax cut family appreciated ['(0, 7.1%)', '(1, 6.6%)', '(2, 62.0%)', '(3, 14.4%)', '(4, 10.0%)']\n",
      "opened conversation diplomacy DPRK korea meet korean leader dick count regardless popular opinion big douche ['(0, 10.1%)', '(1, 48.5%)', '(2, 10.0%)', '(3, 21.3%)', '(4, 10.0%)']\n",
      "ITT excellent basic black white non nuanced explanation thorough critical analysis immediately rejected never felt quote deeply reading thread little information dangerous ['(0, 14.2%)', '(1, 26.3%)', '(2, 15.3%)', '(3, 9.3%)', '(4, 34.9%)']\n",
      "genuinely dont insane cant find country though dislike possible actual country willful ignorance ['(0, 11.2%)', '(1, 54.1%)', '(2, 11.1%)', '(3, 12.4%)', '(4, 11.1%)']\n",
      "invest business set income person ['(0, 15.1%)', '(1, 25.2%)', '(2, 34.7%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "holy shit changed mind wow ['(0, 12.5%)', '(1, 37.5%)', '(2, 12.5%)', '(3, 25.0%)', '(4, 12.5%)']\n",
      "sending troop sea killed obama bush ['(0, 11.4%)', '(1, 11.1%)', '(2, 15.1%)', '(3, 51.2%)', '(4, 11.1%)']\n",
      "problem argument giving actually talk explain seem rather situation advised ['(0, 9.3%)', '(1, 34.7%)', '(2, 18.2%)', '(3, 19.6%)', '(4, 18.2%)']\n",
      "read twitter shown basically constitution run honor system worry smarter politician next teeth rule ['(0, 8.0%)', '(1, 45.7%)', '(2, 8.0%)', '(3, 15.4%)', '(4, 22.9%)']\n",
      "federal employee paid leave giving federal employee mother father week paid leave birth child adoption ['(0, 49.7%)', '(1, 10.0%)', '(2, 10.3%)', '(3, 20.0%)', '(4, 10.0%)']\n",
      "emboldens BLM movement violent protest cause vote pure genius ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "socialist plan voting joe biden likely vote socialist party candidate however government employee HR positive federal employee finally gave maternal paternal leave obama gave biggest annual pay raise career signed executive order calling federal hiring reform actually agree badly needed hate government ['(0, 35.7%)', '(1, 24.8%)', '(2, 6.5%)', '(3, 17.8%)', '(4, 15.1%)']\n",
      "literally nominated nobel peace brokering east sence carter literally enough term korea stepped korea without guard sitting united state ended nafta beneficial united state joe biden claim always nafta though supported baned critical race theory government organization end racism low expectation claiming white construct poc expected held standard white argue divisiveness activated pushing ether vote generally take part government ['(0, 3.1%)', '(1, 30.2%)', '(2, 29.0%)', '(3, 25.8%)', '(4, 11.9%)']\n",
      "policy change consider EO kidney disease whitehouse gov presidential action executive order advancing american kidney health vox raved vox future perfect triump kidney disease transplant EO highlighting save thousand largest government action kidney decade vox followed additional coverage vox future perfect kidney transplant requirement rule white house seem pretty real x200b thinking broadly health seems fairly thought approach hhs gov site default file reforming america healthcare system choice competition pdf helping ['(0, 31.0%)', '(1, 20.0%)', '(2, 14.2%)', '(3, 3.8%)', '(4, 31.0%)']\n",
      "personally china korea rival china emerging dominance fighting rocket problem honest feel great knowing democrat republican cult ['(0, 7.8%)', '(1, 21.1%)', '(2, 21.4%)', '(3, 35.4%)', '(4, 14.3%)']\n",
      "energized entire generation politically ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 28.6%)', '(4, 14.3%)']\n",
      "paid parental leave giving federal employee mother father week paid leave birth child adoption ['(0, 44.2%)', '(1, 11.1%)', '(2, 11.3%)', '(3, 22.2%)', '(4, 11.1%)']\n",
      "pretty hot though ['(0, 14.3%)', '(1, 42.9%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "generally feel person loathe guy stand hate love approach forced dispassionately campaign bit hated conservative find obama hated liberal find although fair arrogance combative nature difficult task obama official memory US politics conservative happy appointing gorsuch kavanaugh iran obama allowed enrichment uranium used nuclear weapon glad withdrew nuclear iran actually allowed kind crazy withdrawal least positive impact suspect replace sometime near future controversial pretty politician agreed earlier border security closed border essential national security economic stability glad least started building process immigrant honestly immigrant understand though ['(0, 2.6%)', '(1, 31.4%)', '(2, 29.2%)', '(3, 16.4%)', '(4, 20.4%)']\n",
      "reason listed single impact hmmm political family lawyer career politician hopefully outsider run office career politician useless ['(0, 10.1%)', '(1, 34.6%)', '(2, 12.9%)', '(3, 14.3%)', '(4, 28.1%)']\n",
      "reduction bomb east excluding afghanistan nice along anti interventionist reducing troop bringing plenty home calling military racket ran pentagon ['(0, 7.9%)', '(1, 7.7%)', '(2, 7.7%)', '(3, 69.0%)', '(4, 7.7%)']\n",
      "drawback troop east pretty positive impact ['(0, 10.0%)', '(1, 30.0%)', '(2, 10.0%)', '(3, 30.0%)', '(4, 20.0%)']\n",
      "baiting fudds high blood pressure medication handle additional strain ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "supporter recall looked deep pas tougher penalty animal abuse wildly character move grateful ['(0, 22.2%)', '(1, 12.9%)', '(2, 20.4%)', '(3, 11.1%)', '(4, 33.3%)']\n",
      "move US embassy jerusalem permanent job voted 90 ball ['(0, 10.0%)', '(1, 10.4%)', '(2, 57.3%)', '(3, 12.3%)', '(4, 10.0%)']\n",
      "maybe space force definitely idea kicking around ['(0, 30.0%)', '(1, 38.9%)', '(2, 11.1%)', '(3, 10.0%)', '(4, 10.0%)']\n",
      "list stopped escalation military conflict country showed tremendous restraint iran attacked military base injured troop ['(0, 7.9%)', '(1, 17.4%)', '(2, 20.8%)', '(3, 46.8%)', '(4, 7.1%)']\n",
      "realize start voting ['(0, 12.5%)', '(1, 25.0%)', '(2, 12.5%)', '(3, 37.5%)', '(4, 12.5%)']\n",
      "rid healthy lunch initiative kid absolutely take fruit vegetable lunch exception idea behind bad created WASTE school trade type program kid take food eat leave kid wanted work donate local farmer throwing away hundred pound uneaten food gone waste reduced almost half used fill garbage bag positive ['(0, 22.7%)', '(1, 40.9%)', '(2, 10.9%)', '(3, 5.0%)', '(4, 20.5%)']\n",
      "wrong positive finally realize enough finally enough try corruption country rug delivered red white blue platter signed name acknowledging corruption actively working wise yeah piece shit ['(0, 15.5%)', '(1, 38.7%)', '(2, 5.0%)', '(3, 20.8%)', '(4, 20.0%)']\n",
      "successful keeping US endless war thank ['(0, 14.3%)', '(1, 14.3%)', '(2, 16.1%)', '(3, 41.0%)', '(4, 14.3%)']\n",
      "stopped pay tax insurance liked love universal healthcare truly obama change access preexisting condition otherwise big win insurance profit taking insurance pay tax nice ['(0, 12.0%)', '(1, 21.9%)', '(2, 39.7%)', '(3, 16.8%)', '(4, 9.5%)']\n",
      "investing newest generation nuclear power instead subsidizing coal natural gas environmental protection important imo ['(0, 22.2%)', '(1, 22.2%)', '(2, 11.8%)', '(3, 21.6%)', '(4, 22.2%)']\n",
      "tax reform slashed tax class lowered corporate tax help employment number ['(0, 18.5%)', '(1, 7.7%)', '(2, 50.0%)', '(3, 15.4%)', '(4, 8.4%)']\n",
      "best imo point ridiculous system become flaw abuseable power ['(0, 11.7%)', '(1, 18.5%)', '(2, 20.0%)', '(3, 10.0%)', '(4, 39.8%)']\n",
      "beef pound today ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "america grate ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "human trafficking arrest child trafficking arrest promised bigly ['(0, 53.8%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 12.9%)', '(4, 11.1%)']\n",
      "exposed flaw system government revealed among family friend actually complete piece shit ['(0, 12.3%)', '(1, 27.3%)', '(2, 16.0%)', '(3, 9.1%)', '(4, 35.3%)']\n",
      "love hate young never interested politics positive impact country ['(0, 8.4%)', '(1, 31.8%)', '(2, 8.3%)', '(3, 18.6%)', '(4, 32.8%)']\n",
      "week parental leave new parent working federal government previously mother went unpaid leave used sick leave PS hate though help baby girl expecting november ['(0, 30.0%)', '(1, 20.0%)', '(2, 7.5%)', '(3, 23.6%)', '(4, 18.9%)']\n",
      "stir shit undo whole industrial outsourcing china sabotage global neoliberal gimmick beyond class asshat ['(0, 10.4%)', '(1, 33.1%)', '(2, 10.0%)', '(3, 36.4%)', '(4, 10.0%)']\n",
      "change ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "signed forever GI bill meaning veteran GI bill benefit longer expire ['(0, 60.0%)', '(1, 10.0%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 10.0%)']\n",
      "method fact checking confirming claim pro con ['(0, 14.3%)', '(1, 28.6%)', '(2, 28.6%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "indirectly work culture dramatically shift remote potential ['(0, 16.7%)', '(1, 28.2%)', '(2, 19.8%)', '(3, 18.7%)', '(4, 16.7%)']\n",
      "entertaining never cared watching press conference reading twitter watching state union address fun honestly politics ['(0, 12.5%)', '(1, 12.5%)', '(2, 25.0%)', '(3, 12.9%)', '(4, 37.1%)']\n",
      "payroll tax cut foot faster ['(0, 14.3%)', '(1, 14.4%)', '(2, 42.8%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "best post period lock ['(0, 15.9%)', '(1, 27.0%)', '(2, 28.6%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "000th line opinionated liberal absolutely despises everything associated considered positive outcome produced conclusion feel properly exposed china true adversary initiated strong response threat believe tariff strategy effective opening salvo issue likely increase national importance coming decade ['(0, 22.0%)', '(1, 27.3%)', '(2, 5.0%)', '(3, 7.3%)', '(4, 38.5%)']\n",
      "heard opportunity zone en wikipedia org opportunity_zone wprov sfla1 initiative passed part tax designates particular geographical area mostly urban area economically stagnant served business allowed defer portion tax directly tied profit income generated serving zone developing kind pissed garbage partisan job never reporting particular incentive edit hyperlink formatting ['(0, 10.7%)', '(1, 9.5%)', '(2, 64.3%)', '(3, 6.2%)', '(4, 9.2%)']\n",
      "chew argued meaningful US nixon achieved accomplishment positive impact two despicable trying everyone ['(0, 10.3%)', '(1, 32.6%)', '(2, 19.3%)', '(3, 12.8%)', '(4, 25.0%)']\n",
      "late game DJT minority college part national budget instead waiting fed money ['(0, 30.8%)', '(1, 10.0%)', '(2, 29.3%)', '(3, 19.8%)', '(4, 10.0%)']\n",
      "public future potentially grit engenders creation pearl aside quaking western reckon implication learned behavior animal moral philosophy biology converge conclusion intolerable traditionalist unknow die win attrition sometimes mature ['(0, 20.0%)', '(1, 38.4%)', '(2, 10.0%)', '(3, 11.6%)', '(4, 20.0%)']\n",
      "fan credit due IMO due narcissistic reason another predominately muslim country recognize israel recently serbia recognize country kosovo realize serbian leader always read signing big achievement considering genocide occurred ago small positive impression multiply reason enough bad reason biggest order immigration xenophobia propaganda loving russia NK MBS turkey tyrant loving removal US troop discussion europe asia stabbing kurdish leaving without support syria vocally condemning prejudice action hate mismanaging current pandemic never admitting fault edit larger list add comment likely right ['(0, 19.3%)', '(1, 18.8%)', '(2, 3.7%)', '(3, 52.9%)', '(4, 5.4%)']\n",
      "rebuttal donated salary donates salary avoid legal repercussion taking money taxpayer take salary financials open taxpayer review citizen standing sue tracking action declared intention run single citizen personally profit decision ['(0, 14.5%)', '(1, 35.0%)', '(2, 13.1%)', '(3, 22.7%)', '(4, 14.7%)']\n",
      "kinda terrible greatly national park ['(0, 23.6%)', '(1, 14.3%)', '(2, 19.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "hope source included trajectory otherwise seem flattering statistic direction country headed took office ['(0, 9.6%)', '(1, 26.2%)', '(2, 18.2%)', '(3, 10.9%)', '(4, 35.2%)']\n",
      "personally source judge smaller court system fair trial deceit evil court system heard great case judge judicial court hear main stream newspaper american avid supporter super stuff believe country easy opinionated biased reaction calling god fault believe person kinda wack ['(0, 4.2%)', '(1, 20.0%)', '(2, 14.3%)', '(3, 12.8%)', '(4, 48.7%)']\n",
      "eastern peace important calmed tension actually gave jersualem recognition country ['(0, 22.5%)', '(1, 30.5%)', '(2, 11.1%)', '(3, 24.8%)', '(4, 11.1%)']\n",
      "briefly speaking vocational training program america high school ton DeVos harm role hopefully future funding support allocated program ['(0, 45.2%)', '(1, 8.6%)', '(2, 15.4%)', '(3, 7.7%)', '(4, 23.1%)']\n",
      "spelling favour favor labour labor obviously british odd ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "mentioned actually quite bit space sector NASA commercial partner space force granted mike penny figure hear multiple space directive better allocation fund yearly budget appointing best administrator jim bridenstine decisive figure paying attention artemis program hoping country towards apollo mission 60 70 digress big fan policy rhetoric massive improvement obama era undeniable win god help continues major positive impact future space exploration unseen wonder quality ['(0, 32.8%)', '(1, 24.6%)', '(2, 19.4%)', '(3, 8.8%)', '(4, 14.4%)']\n",
      "tax cut helped enormously healthcare removal tax penalty great relief obama never helped directly definitely directly hurt ['(0, 14.3%)', '(1, 7.2%)', '(2, 41.6%)', '(3, 24.2%)', '(4, 12.8%)']\n",
      "subjective hate guy personally supreme court pick perspective though disagree ['(0, 9.2%)', '(1, 18.2%)', '(2, 11.5%)', '(3, 27.3%)', '(4, 33.9%)']\n",
      "politics general politician garbage exist money flow money flow involve corporation black matter matter tell whatever hear elected money flow pocket friend pocket regard used coach youth football always believed learn coach sometimes lesson little humorous actually press pause bother yes OP bother read bullshit thought name ok suppose classroom memorize name major historical significance history pandemic MLK killed rodney king trial unremarkable ['(0, 23.2%)', '(1, 30.6%)', '(2, 8.2%)', '(3, 18.3%)', '(4, 19.8%)']\n",
      "china trade conversation politicized real issue dealt apple store selling fake apple product across china apple recourse chinese government unwilling enforce patent related crime american company blatant wrong fixed open trade china tax reform positive impact economy individual sort eye beholder though ['(0, 22.3%)', '(1, 19.7%)', '(2, 21.8%)', '(3, 17.1%)', '(4, 19.0%)']\n",
      "animal cruelty federal crime else though ['(0, 45.3%)', '(1, 27.3%)', '(2, 9.2%)', '(3, 9.1%)', '(4, 9.1%)']\n",
      "gonna moving embassy jerusalem ['(0, 14.3%)', '(1, 14.3%)', '(2, 42.8%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "brokered israel UAE normalizing relation saudi arabia let israeli origin plane use airspace modern history lead war ['(0, 16.7%)', '(1, 8.7%)', '(2, 16.7%)', '(3, 49.6%)', '(4, 8.3%)']\n",
      "legalized hemp k ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "recently helped negotiate diplomatic agreement UAE israel fully normalize relation country includes agreement prime minister netanyahu suspended plan annex multiple part west bank great step forward call peace east obviously agreement peace east step right direction ['(0, 9.2%)', '(1, 4.6%)', '(2, 8.5%)', '(3, 73.6%)', '(4, 4.2%)']\n",
      "shown potential presidential candidate ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "brought seagull sweep hairstyle fashion ['(0, 18.0%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 32.0%)']\n",
      "identifying corruption front stage ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "stock check market trend ['(0, 25.0%)', '(1, 12.5%)', '(2, 37.5%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "tell none especially tell joe biden tough china ['(0, 10.4%)', '(1, 40.0%)', '(2, 10.0%)', '(3, 27.7%)', '(4, 11.9%)']\n",
      "impact determined office undone bunch policy prior next undoes policy change thread pointless ['(0, 9.0%)', '(1, 33.1%)', '(2, 25.0%)', '(3, 8.3%)', '(4, 24.5%)']\n",
      "real peace east ['(0, 12.5%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 37.5%)', '(4, 25.0%)']\n",
      "supposed change factual statement post scam upvotes ['(0, 13.9%)', '(1, 23.6%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 37.5%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "able admit animal abuse felony obviously administration treatment human specifically south border ['(0, 17.7%)', '(1, 7.7%)', '(2, 23.1%)', '(3, 36.2%)', '(4, 15.4%)']\n",
      "harris becomes fuckydoo ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "biden kamala term held significantly longer kamala jail weed possession use basically slave labour forest fire biden word remember oohhh anyway gotta take nap word mine ['(0, 16.6%)', '(1, 57.6%)', '(2, 8.5%)', '(3, 8.3%)', '(4, 8.9%)']\n",
      "true showed america joke word country absolutely completely change without warning positive ['(0, 7.2%)', '(1, 19.0%)', '(2, 9.0%)', '(3, 21.9%)', '(4, 42.9%)']\n",
      "brought dumb american side exposed partially hidden underbelly inherently flawed system nazi v communist neither side eye eye based upon adaptive web browsing longer opposing google search based upon cooky ['(0, 8.8%)', '(1, 41.9%)', '(2, 11.3%)', '(3, 7.7%)', '(4, 30.3%)']\n",
      "giving prop job presidential stuff impressed actually required position praise performing task job requires expected ['(0, 8.9%)', '(1, 16.7%)', '(2, 25.0%)', '(3, 32.8%)', '(4, 16.7%)']\n",
      "raising tobacco nicotine age ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "pen holder stick pen stupid money ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "gave meaningful tax break allowed retirement start pulling investment stock market spend money money circulation stronger economy gave meaningful tax break dependent limited tax write offs high valued home able renegotiate NAFTA preemptively placed large order COVID vaccine important vaccine producer produce limited number vaccine period placing enormous order allowed company gear equipment vaccine become approved churn large production run short period large amount money US government forth towards COVID vaccine US poised successful vaccine available imposed tarriffs foreign successfully negotiated china trade ongoing phase signed incentivized company produce US ['(0, 31.7%)', '(1, 2.8%)', '(2, 52.6%)', '(3, 10.3%)', '(4, 2.6%)']\n",
      "definitely voting reading ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "administration blame credit whatever happens right maybe vein great american outdoors greatest piece conservation legislation passed generation nobody talk ['(0, 22.5%)', '(1, 35.5%)', '(2, 26.2%)', '(3, 7.8%)', '(4, 8.0%)']\n",
      "digging unemployment record low presidency ncsl org research labor employment national employment monthly update aspx p continuously grown signal market performing macrotrends net sp historical annual return deported obama administration cato org blog deportation historical perspective GDP continuously grown presidency whereas obama remained stagnant period regressed bit statista statistic annual gdp growth united state edit added source ['(0, 4.2%)', '(1, 4.0%)', '(2, 71.1%)', '(3, 4.7%)', '(4, 16.0%)']\n",
      "end bad either umbrella administration worse rhetoric toxic base face america hardly tolerate brought positive change US never kid person double edged sword except side butter knife kitchen knife end lightsaber ['(0, 5.4%)', '(1, 29.7%)', '(2, 11.4%)', '(3, 13.7%)', '(4, 39.8%)']\n",
      "paid grand tax suck curved vein ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "hope post comprehensive summary comprehensive summary bad honestly cause dislike betsy devois appointment ['(0, 11.6%)', '(1, 44.0%)', '(2, 11.1%)', '(3, 22.2%)', '(4, 11.1%)']\n",
      "publish story biden china anti russia ['(0, 12.7%)', '(1, 22.2%)', '(2, 11.1%)', '(3, 42.8%)', '(4, 11.1%)']\n",
      "EARN NEGATIVE impact ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "thank post seriously wanted ask without starting fight thank ['(0, 18.6%)', '(1, 20.1%)', '(2, 14.4%)', '(3, 30.0%)', '(4, 16.8%)']\n",
      "believe DJT entirely evil motif tad askew never understand imagine went vietnam POW grew realize everything upbringing father fred pure trash sense least somewhat capable empathetic instead sociopathic different today believe applied adolf hitler father halfway decent human raised nurture instead nature adolf grown different sigmund freud greater importance father figure child woe share derived negligence abuse others enough enough stop preaching hate stop trying sow division none exist capable feeling bleeding dying death discriminate message never abuse worse wrath karma endure ['(0, 8.2%)', '(1, 26.3%)', '(2, 3.7%)', '(3, 35.1%)', '(4, 26.6%)']\n",
      "eh korea ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "CPA dealing corporate tax tax cut job passed biggest piece tax legislation changed landscape international taxation brought major change certain deduction tax accountant quite valuable however effort driven mostly congressional republican rather tax passed without office stand republican certainly disagree tax policy certainly take job security ['(0, 7.2%)', '(1, 3.1%)', '(2, 43.1%)', '(3, 21.4%)', '(4, 25.1%)']\n",
      "apathetic politics ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "new war started compared ['(0, 14.0%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 48.5%)', '(4, 12.5%)']\n",
      "new uae israel alone insane event ['(0, 16.4%)', '(1, 23.5%)', '(2, 12.5%)', '(3, 35.1%)', '(4, 12.5%)']\n",
      "donated salary proved seeing tax return ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "action gotten vote election lose ['(0, 11.1%)', '(1, 42.2%)', '(2, 11.1%)', '(3, 13.4%)', '(4, 22.2%)']\n",
      "subreddit called r changemyview r myview ['(0, 18.0%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 31.9%)']\n",
      "deserve peace work korea general east definitely flaw great stride peace around ['(0, 7.7%)', '(1, 18.7%)', '(2, 16.6%)', '(3, 49.3%)', '(4, 7.7%)']\n",
      "politics science objective truth right wrong opinion fix climate drive electric car cost gasoline job money money buy cheaper dirty stuff return cause CO2 emission kept gasoline car replaced electric organically organically price brainer buy believe therefore enforcing electrification essence republican let market fix problem issue solution become valuable company provide filthy rich free country opinion free government dictation course US perfect closest republican leadership intervention better intervention ['(0, 24.9%)', '(1, 25.1%)', '(2, 11.5%)', '(3, 12.7%)', '(4, 25.8%)']\n",
      "believe fact america great twisted exploited presidency possible past relied tradition fundamental understanding cannot despicable human leader honestly believe next various maker student history work fix exploit close gap exposed result america better country decent diplomatic tradition took granted tradition however result understand ramification perhaps enforceable rule place prevent happening ['(0, 4.2%)', '(1, 39.2%)', '(2, 10.6%)', '(3, 15.6%)', '(4, 30.3%)']\n",
      "dunno least hundred pretty solid kinda odd shittiest shitty accident ['(0, 12.5%)', '(1, 50.0%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "started war economy france weird french government order LVMH stop investment US beginning ['(0, 19.1%)', '(1, 8.3%)', '(2, 21.8%)', '(3, 36.8%)', '(4, 14.0%)']\n",
      "hooo wheeee read comment looked proof found light bad outweighs wish kinder person ['(0, 10.0%)', '(1, 30.0%)', '(2, 10.0%)', '(3, 30.0%)', '(4, 20.0%)']\n",
      "remember month gas price dropped thanks ['(0, 37.5%)', '(1, 25.0%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "damn subreddit talk discus hear eachother ['(0, 14.3%)', '(1, 41.5%)', '(2, 14.3%)', '(3, 15.6%)', '(4, 14.3%)']\n",
      "starting war invading new country ['(0, 14.4%)', '(1, 18.1%)', '(2, 12.5%)', '(3, 42.5%)', '(4, 12.5%)']\n",
      "fact arguing china china policy mind blowing american worry country future luck america wrong move china onwards cost global dominance ['(0, 12.4%)', '(1, 30.5%)', '(2, 17.0%)', '(3, 24.3%)', '(4, 15.8%)']\n",
      "iran nuclear ticking bomb pun intended economy best track c19 became energy independent ['(0, 12.5%)', '(1, 12.5%)', '(2, 50.0%)', '(3, 12.5%)', '(4, 12.5%)']\n",
      "neither changed ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "news bash thought neutral anymore ['(0, 14.3%)', '(1, 14.3%)', '(2, 17.5%)', '(3, 24.4%)', '(4, 29.5%)']\n",
      "CHILDREN pushing election JOE BYE ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "scrolled read commenting mentioned ripped TPP everyone seems forgotten vote dont earned respect everyone short memory TPP awful agreement screwed american WHOLE GODDAMN INTERNET trying push TPP reason never cared barak throw trash thus keeping internet relatively free argued installing ajit pai position power countered internet asked trashing TPP ruined afterwards remove ['(0, 32.1%)', '(1, 27.4%)', '(2, 5.3%)', '(3, 18.3%)', '(4, 16.9%)']\n",
      "feel taking crazy pill ['(0, 14.3%)', '(1, 42.8%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "fact find plausible without researching single positive impact tell feeding ['(0, 8.4%)', '(1, 50.0%)', '(2, 12.9%)', '(3, 12.1%)', '(4, 16.7%)']\n",
      "feel question flawed absolutely none positive listed administration credit god ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 10.0%)', '(4, 30.0%)']\n",
      "hard line stance china right obama proposed policy liberal accepted necessary contain authoritarian government likely committing genocide biden recognizes policy likely similar wsj article whats bidens china policy ['(0, 6.0%)', '(1, 35.4%)', '(2, 33.4%)', '(3, 16.7%)', '(4, 8.5%)']\n",
      "love person willing accept perspective matter comment section showed piece faith humanity chaotic ruined 21st century thank wonderful living ['(0, 10.0%)', '(1, 50.0%)', '(2, 10.0%)', '(3, 20.0%)', '(4, 10.0%)']\n",
      "depends COVID pretty positive ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "gotten potentially dangerous radical group country identify brought mockery ridicule bullying public mind problematic behavior avoid read content aware clickbait disconnect title content fact delegated governor acted various shown update structure government actually work instead incumbent crony ['(0, 5.7%)', '(1, 51.3%)', '(2, 5.8%)', '(3, 16.6%)', '(4, 20.6%)']\n",
      "fail learn succeed learn fail particular anymore ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "hate step right direction abolishing puppy mill gotten thought supposed sign animal abuse point ['(0, 25.9%)', '(1, 7.9%)', '(2, 7.1%)', '(3, 17.6%)', '(4, 41.5%)']\n",
      "maybe positive impact remember ['(0, 11.1%)', '(1, 44.4%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 22.2%)']\n",
      "change straight factual statement ['(0, 14.3%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 42.8%)']\n",
      "giving away 200k breaking emulments clause joke answer ask change actually stick parlor trick ['(0, 9.1%)', '(1, 21.3%)', '(2, 9.1%)', '(3, 33.2%)', '(4, 27.3%)']\n",
      "best admin IMO creation qualified opportunity zone zone established department treasury IRS tax plan tax cut job opportunity zone census area historically struggled lower economic indicator essentially federal government giving investor business tax incentive establish new business zone great approach stir growth area struggle economically experience real estate development growth follows growth continue policy moving forward effect clear another ['(0, 6.3%)', '(1, 3.7%)', '(2, 65.9%)', '(3, 16.2%)', '(4, 8.0%)']\n",
      "repealed infamous dear colleague letter pretty worst mistake obama presidency department education sent letter suggesting college become arbiter sexual misconduct conduct hearing using preponderance standard lowest standard evidence accused student entitled due process hearing charge evidence counselor available suggestion administration strongly implied cut federal funding school course college university across country complied ['(0, 26.0%)', '(1, 16.2%)', '(2, 32.6%)', '(3, 10.9%)', '(4, 14.3%)']\n",
      "clarify obama political impact USA attempt objective without bringing side right obama focused current era ['(0, 7.2%)', '(1, 41.1%)', '(2, 20.5%)', '(3, 23.3%)', '(4, 7.8%)']\n",
      "signed music modernization leading establishment licensing organization administering blanket mechanical publishing license set organization responsible ensuring copyright owner paid song streamed service spotify apple music help streaming service avoid infringement lawsuit due lack ownership data MMA allows artist paid pre release seems pretty received music industry ['(0, 41.3%)', '(1, 25.0%)', '(2, 8.7%)', '(3, 16.7%)', '(4, 8.3%)']\n",
      "step ['(0, 25.6%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 24.4%)', '(4, 16.7%)']\n",
      "lmao OP saying consider positive almost response ['(0, 12.0%)', '(1, 30.5%)', '(2, 14.0%)', '(3, 11.1%)', '(4, 32.5%)']\n",
      "conservative talk prison reform bill speaking point RNC spark note helped change prison system pardon handful non violent drug possession crime little early thought heard somewhere kim kardashian source ['(0, 21.7%)', '(1, 12.6%)', '(2, 4.5%)', '(3, 10.1%)', '(4, 51.0%)']\n",
      "help ASAP rocky freed ['(0, 31.0%)', '(1, 16.7%)', '(2, 19.0%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "already mentioned bump stock ban major positive gun control ['(0, 29.0%)', '(1, 22.2%)', '(2, 11.1%)', '(3, 15.4%)', '(4, 22.2%)']\n",
      "majority answer seem benefit majority american ['(0, 23.9%)', '(1, 11.6%)', '(2, 31.2%)', '(3, 11.1%)', '(4, 22.2%)']\n",
      "preface statement saying supporter special interest excelled least picked slack behind past two administration ignorance underestimation respectively VA massive stride fall short mark course correction start militarytimes news pentagon congress va program percent funding boost fiscal budget plan stripe news veteran budget plan call another increase va spending granted publication shut asked impact potentially four ['(0, 25.9%)', '(1, 17.8%)', '(2, 8.1%)', '(3, 30.4%)', '(4, 17.7%)']\n",
      "monkey throw shit air occasionally land bad person deed ['(0, 22.2%)', '(1, 44.5%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 11.1%)']\n",
      "impact swath stupid given enough traction preach stupid shit donny enabled viewed dumb viewed patriotic impact voice selfish dumb voice silenced silenced decade ago dumb revolution festering cause donny ['(0, 13.1%)', '(1, 50.0%)', '(2, 8.3%)', '(3, 16.7%)', '(4, 11.9%)']\n",
      "positive gave TPP fucking bullet australian term trade pact basically let US arse whenever feel totally australia interest given term board political class populated almost completely utterly craven fuckwits former real estate agent edit unlikely start war russia pretty big plus physical spiritual taste cock holster edit along lady tit plus though YMMV ['(0, 13.7%)', '(1, 40.8%)', '(2, 3.9%)', '(3, 31.6%)', '(4, 10.0%)']\n",
      "somewhat cynical take managed help society clearly transparently shit work nation climate economy tax institutional systemic racism KKK nazi wannabe living amongst uneducated basic science critical thinking structural issue safeguard political appointee william barr idea allowed problem country address taking problem exacerbating shown bad sorely attention yeah whole covid add list sense showing take public health threat seriously address ['(0, 8.1%)', '(1, 58.2%)', '(2, 22.8%)', '(3, 4.5%)', '(4, 6.4%)']\n",
      "fucking broke work civil name positive impact america ['(0, 10.0%)', '(1, 38.8%)', '(2, 10.7%)', '(3, 10.5%)', '(4, 30.0%)']\n",
      "retracted terrible dear colleague letter obama admin place expelled university weakest accusation ['(0, 12.5%)', '(1, 25.0%)', '(2, 22.9%)', '(3, 14.7%)', '(4, 25.0%)']\n",
      "mentioned pretty changed insurance required pay telehealth service COVID started previously hospital providing telehealth support brought money additionally HIPAA security reason order telehealth sometimes drive clinic order use telehealth booth use smartphone heard freakonomics podcast week issue nuanced motion within bill ended signing ['(0, 54.4%)', '(1, 18.1%)', '(2, 5.5%)', '(3, 13.8%)', '(4, 8.2%)']\n",
      "gotten participate political process next step informed participation ['(0, 19.1%)', '(1, 31.9%)', '(2, 11.1%)', '(3, 15.7%)', '(4, 22.2%)']\n",
      "positive impact mind though failure positive outcome sole result utter incompetence attempt take healthcare trans SCOTUS rule LGBT workplace protection ruling protected status previously ruling explicitly mentioned anti discrimination ['(0, 20.7%)', '(1, 45.8%)', '(2, 5.9%)', '(3, 8.7%)', '(4, 18.9%)']\n",
      "decrease tax burden attract 8k millionaire average per stop debt gdp growth obama sent increased deported illegal immigrant obama substantial amount removed fine health insurance effectivelly removing poverty tax removing troop east safe affordable manner executive order unemployment congress playing politics passing cdc eviction deferral december woman employed men US citation google scholar plain google ['(0, 20.0%)', '(1, 4.2%)', '(2, 48.6%)', '(3, 16.2%)', '(4, 11.1%)']\n",
      "actually took china h1 b visa disaster right start love biden win continue tel china shove ['(0, 7.4%)', '(1, 36.9%)', '(2, 7.1%)', '(3, 38.1%)', '(4, 10.5%)']\n",
      "establishing UAE israel count positive stimulus check nice executive order reduce prescription drug price positive process implementing tax small business owner entrepreneur bad encouraged start financial freedom relate hate economy somehow holding pandemic moving forward worse space exploration NASA budget higher excite everyone space blast past coal miner lose job positive imagine job loss large scale devastating though fan coal fan losing job support family ['(0, 25.7%)', '(1, 14.0%)', '(2, 24.4%)', '(3, 25.6%)', '(4, 10.3%)']\n",
      "thread ton accomplishment almost given credit current saying aloooott ['(0, 29.0%)', '(1, 39.8%)', '(2, 14.6%)', '(3, 8.3%)', '(4, 8.3%)']\n",
      "disabled combat vet VA dramatically improved election able local provider received better faster referral ['(0, 27.2%)', '(1, 22.2%)', '(2, 22.2%)', '(3, 11.1%)', '(4, 17.2%)']\n",
      "tripping bar low expectation hate plenty agree find plenty new star war movie total hot garbage tho ['(0, 18.6%)', '(1, 20.5%)', '(2, 16.7%)', '(3, 35.8%)', '(4, 8.3%)']\n",
      "according ultra rich killing ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 33.3%)', '(4, 16.7%)']\n",
      "wrong attrackted daughter ur wife daughter legalized separation child thousand disappear w explanation total theory definetly true likely run sex ring includes immigrant child buy pic ['(0, 33.3%)', '(1, 32.7%)', '(2, 8.9%)', '(3, 8.3%)', '(4, 16.7%)']\n",
      "FedNow system CBDC digital dollar blockchain IoT AI program launched compete ['(0, 30.1%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 27.0%)']\n",
      "rather maestro death thousand cut ['(0, 12.5%)', '(1, 12.6%)', '(2, 24.9%)', '(3, 25.0%)', '(4, 25.0%)']\n",
      "immigration policy largely failure rhetoric public profile anti immigrant rapidly reduced illegal border crossing country couple ['(0, 9.9%)', '(1, 22.1%)', '(2, 32.7%)', '(3, 26.9%)', '(4, 8.3%)']\n",
      "sign executive order TPP call ['(0, 50.0%)', '(1, 10.0%)', '(2, 10.0%)', '(3, 20.0%)', '(4, 10.0%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "opinion positive impact gone hopefully able generate enough momentum create change within political system change focus abuse legally able fix ['(0, 5.9%)', '(1, 38.6%)', '(2, 16.6%)', '(3, 5.6%)', '(4, 33.3%)']\n",
      "yes shown congress corporation ['(0, 15.8%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 27.0%)']\n",
      "point thinking regularly caught hyper partisanship destroying american society difficult credit though point leading cause hyper partisanship symptom symptom firework pier port beirut ammonium nitrate tonnage lit credit following america flying blind ChiMerica partnership china watched chinese action movie upon china jet li china actually west positive grievance scorn contempt humiliation history foreign power including US used military diplomatic influence carve piece china economic goal enormous cause national shame chinese history chinese communist party opened free market reform intention becoming western style democracy human right considered pain CCP considered intellectual property theft problem chinese company lifeblood business none end american administration administration kept ignoring issue manufacturing base dried rust belt rotted enough asshole finally stop enormous policy change deserves great credit killing qasem soleimani low cost high impact foreign policy national security move averted war fell stroke attacking troop iraq iranian regime went hubris told US turn pride fall paid little price killing showed iranian others region force reckoned despite drawing military presence anti war seem counterintuitive genuinely seems major aversion starting military action honest american military industrial complex heard lifetime calling pentagon endless war money military contractor positive major biggest problem bigger personality massive insecurity policy work necessary run country country especially huge country united state everything quick solution photo ops lip service praise seeking bogged detail hack huge problem america played grand scale covid formulate national plan capable thinking macro sense seems focused instant gratification within news cycle instead term goal simply work running sort large organization ['(0, 12.9%)', '(1, 19.5%)', '(2, 28.1%)', '(3, 26.7%)', '(4, 12.9%)']\n",
      "showed saying positive hurt soul lay ['(0, 12.5%)', '(1, 37.5%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 25.0%)']\n",
      "gorsuch pretty great supreme court justice ['(0, 22.2%)', '(1, 22.2%)', '(2, 31.3%)', '(3, 11.1%)', '(4, 13.1%)']\n",
      "strong dislike rid NAFTA originally went effect clinton HUGE problem angry getting rid rid obama praised ['(0, 18.0%)', '(1, 15.3%)', '(2, 22.2%)', '(3, 27.8%)', '(4, 16.7%)']\n",
      "unaware unprecedented peace brokered east nominated nobel peace ['(0, 10.0%)', '(1, 10.0%)', '(2, 10.0%)', '(3, 60.0%)', '(4, 10.0%)']\n",
      "case DJT positive contribution exploited loophole system allows believe level corruption possible america positive government response tossed aside politician disown politics corruption write prevent future hope ['(0, 5.2%)', '(1, 10.0%)', '(2, 5.0%)', '(3, 5.0%)', '(4, 74.8%)']\n",
      "fucking hate deny let real us pr stunt convince others vile ['(0, 11.1%)', '(1, 25.0%)', '(2, 11.1%)', '(3, 30.5%)', '(4, 22.2%)']\n",
      "practical term administration real distinction previous couple else name changed specific shifted around system chug along broken already status quo remains king difference new invasion decade american authorised invasion ['(0, 11.5%)', '(1, 27.2%)', '(2, 18.8%)', '(3, 18.2%)', '(4, 24.3%)']\n",
      "uh completely different approach actually great informative answer totally funnier maybe laugh cry scenario genuinely average level humour gone social remember funnier person feel dependent friend group anyway serious political gotten funnier whole fake reservation rally funnier protest whatever bygone era obama bush ludicrousness entire presidency existed outrageous available maybe little easier laugh genuinely concerned seems defaulting humour rather anger obviously anecdotal maybe aware social nowadays genuinely laughter considering bad tolerance shenanigan risen dramstically insinuated power delay election remain power dangerously suggested cure virus disinfecting inside meh sound tuesday obama wore tan suit bowed lost everloving mind press conference dressed speedo chinese flag talking monday ['(0, 3.2%)', '(1, 45.9%)', '(2, 11.3%)', '(3, 15.4%)', '(4, 24.2%)']\n",
      "best economy modern history stock market incredible high funded black college black unemployment lowest withdrew troop abroad created domestic job opioid epidemic low lowered tax ended cold korea historic peace UAE israel accomplishment list top missed couple ['(0, 12.5%)', '(1, 3.3%)', '(2, 54.2%)', '(3, 23.3%)', '(4, 6.6%)']\n",
      "outside enjoy watching beeing dictator clown amazing watch ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "consider right center take value side worse decided run jaded though right away upon taking TPP signed bill animal abuse felony clean trash pacific signed artist royalty streaming service credit actually greater ['(0, 37.5%)', '(1, 43.4%)', '(2, 4.3%)', '(3, 4.6%)', '(4, 10.2%)']\n",
      "gave new meme least ['(0, 32.4%)', '(1, 25.0%)', '(2, 12.5%)', '(3, 17.6%)', '(4, 12.5%)']\n",
      "putting china microscope US internationally greatest positive impact ['(0, 11.6%)', '(1, 22.2%)', '(2, 12.5%)', '(3, 31.5%)', '(4, 22.2%)']\n",
      "obliterated country gross incompetence ['(0, 16.9%)', '(1, 30.0%)', '(2, 16.7%)', '(3, 19.7%)', '(4, 16.7%)']\n",
      "honestly peaceful repaired relation korea actively pursuing peace east killing solemani baghdadi amazing medicinal drug sooooo affordable paying fraction originally used pay finally afford pay medication ['(0, 15.9%)', '(1, 6.7%)', '(2, 17.4%)', '(3, 46.7%)', '(4, 13.3%)']\n",
      "couple foreign policy domestic foreign actively try decriminalize homosexuality country homosexuality punishable minimum prison deescalated tension communist korea capitalist south korea set foot korean soil action interpreted war exposed assassination spot saving crossed line influential UAE israel aware peaceful relation jew israel surrounding arab state deemed near impossible prior x200b domestic lowest recorded unemployment minority group across age gender anti socialism anti communism economic political theory nation ruin reduction tax regulation business leading increased production employment ['(0, 11.5%)', '(1, 11.0%)', '(2, 37.7%)', '(3, 31.9%)', '(4, 7.9%)']\n",
      "remember OP asking designed offset bad donates salary kennedy set aside gritting least kept tradition pointing angry find decent decent person ['(0, 10.0%)', '(1, 60.0%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 10.0%)']\n",
      "absolutely bizarre post talk unemployment COVID unemployment steadily gone race looked graph without x axis unemployment race impossible tell obama term ended began saying try discredit supporter talk economy inherited absolute mess economy steadily improved COVID ['(0, 9.4%)', '(1, 33.3%)', '(2, 39.1%)', '(3, 5.1%)', '(4, 13.0%)']\n",
      "surprised especially given current racial issue accusation racist mentioned historic funding HBCUs google amp blackenterprise senate bill funding historically black college university support hbcus amp bipartisan bill known FUTURE fostering undergraduate talent unlocking resource education provide HBCUs minimum million annually ['(0, 47.6%)', '(1, 16.2%)', '(2, 6.2%)', '(3, 12.4%)', '(4, 17.6%)']\n",
      "happens let news cycle control mind critical whole simply ignore positive fact alone relation korea improved albeit high low evidence enough positive change feeling kid simply becoming socially aware become young adult understand ten parrot right obama two basically defcon korea nuclear threat saying obama horrible deserves criticism though especially countless innocent killed drone presidency saying span went seriously thinking west coast nuked united state shaking hand trying restore diplomacy nation ['(0, 2.4%)', '(1, 39.0%)', '(2, 17.4%)', '(3, 25.9%)', '(4, 15.3%)']\n",
      "address broad issue foreign policy initially portrayed thoughtless buffoon kickstart WWIII twitter slap fight around ask feel closer WWIII answer let list gotten missile exchange korea opposite facilitated diplomatic talk leader peninsula moon jae recommended nobel peace merely offhand comment quite compliment peace cannot orchestrated US alone certainly POTUS step right direction true diplomatic talk deteriorated primarily due kim stubbornness internal hostility juche hardliner else revisit issue decade seem moving away war peninsula generally disengaged east expending ton blood treasure costly endless war finally starting bring troop home avoided starting new prolonged conflict e syria assume anti war type appreciate heard note peace struck israel UAE ago UAE biggest dog neighborhood move likely draw country peace table contrary notion lapdog putin seriously sanction placed russia took office moved troop eastern europe ought dissuade funny business moscow war russia mindlessly hate NATO militarytimes news military thousand troop coming home germany right tempted headed war china unfortunately true step aggressor china gotten skirmish indian troop conducted drill invading taiwan perhaps perplexingly grumbling china historic claim russian port city vladivostok addition history aggression south china sea crackdown pro democracy demonstrator hong kong recommend checking china uncensored info bottom line china US sideways twitter slap fight decided hit nuke button feeling hurt ['(0, 3.9%)', '(1, 11.5%)', '(2, 10.6%)', '(3, 60.2%)', '(4, 13.9%)']\n",
      "lofty proposition end HIV AID epidemic pumped ton funding HIV AIDS research actually large positive impact side defunding sort important shit extra money coming source parent work public health HIV AIDS research ['(0, 24.5%)', '(1, 36.1%)', '(2, 13.0%)', '(3, 5.4%)', '(4, 21.1%)']\n",
      "measure legacy rather level harm inflicted started new war demonstrated genuine willingness pull troop afghanistan antagonized national intelligence apparatus military industrial complex JFK pause plan launch coup regime change operation adversarial nation state escalate tension russia syria took admirable stand FISA court believe perhaps unconstitutional government institution existence simply virtue incompetent able damage adhered DC foreign policy consensus always case killing soleimani escalation drone war deepening tie israel policy point evidence dove totality administration action FP front safely certain part safer ['(0, 3.0%)', '(1, 5.3%)', '(2, 26.8%)', '(3, 43.3%)', '(4, 21.6%)']\n",
      "economic gift country liberal stepped coronavirus political game pandemic thanks liberal stop bitching til flame ['(0, 9.7%)', '(1, 39.9%)', '(2, 18.5%)', '(3, 23.5%)', '(4, 8.3%)']\n",
      "website list unfortunately covid outbreak dont believe number factual however accomplishment ive physically witnessed past mind tax help tax relief blue collar class family average family four parent child around actually tax return instead owing mother single longer walked away refund helped average family getting hard work ['(0, 10.3%)', '(1, 24.0%)', '(2, 37.3%)', '(3, 19.3%)', '(4, 9.1%)']\n",
      "showed truly deplorable racist conservative republican count idea truly terrible selfish un american relative emboldened admit awfulness treat accordingly worth america collapse single positive impact garbage ['(0, 12.2%)', '(1, 29.0%)', '(2, 8.8%)', '(3, 11.1%)', '(4, 38.9%)']\n",
      "together list PART dozen US hostage freed including obama freed signed music modernization biggest change copyright decade administration promoting second chance hiring former inmate opportunity live crime free find meaningful employment DOJ board prison launched new ready work initiative help connect employer directly former prisoner historic tax cut legislation included new opportunity zone incentive promote investment low income community across country opportunity zone expected spur billion term private capital investment economically distressed community across country directed education secretary end common core signed victim compensation fund signed measure funding prevention program veteran suicide company brought TRILLION dollar overseas TCJA bill signed manufacturing job growing fastest pledge america worker resulted employer committing train million american result republican tax bill small business lowest top marginal tax record number regulation eliminated hurt small business signed welfare reform requiring able bodied adult child work work welfare FDA approved affordable generic drug history reformed medicare program stop hospital overcharging low income senior drug saving senior million alone signed right try legislation allowing terminally ill patient try experimental treatment allowed secured billion new funding fight opioid epidemic signed VA choice VA accountability expanded VA telehealth service walk clinic urgent primary mental health production recently reached high dependent east net natural gas exporter NATO ally increased defense spending pressure campaign circuit court judge nominee confirmed faster new administration moved embassy israel jerusalem imposed tariff china response china forced technology transfer intellectual property theft chronically abusive trade practice agreed part trade china signed legislation improve national suicide hotline signed comprehensive childhood cancer legislation advance childhood cancer research improve treatment tax cut job signed doubled maximum amount child tax credit available parent lifted income limit claim signed billion funding increase child development fund providing total billion state fund child low income family child dependent tax credit CDCTC signed provides tax credit equal child expense per child per family flexible spending account FSAs allow set aside pre tax use child signed autism collaboration accountability research education support CARES allocates billion funding next five help autism spectrum disorder help family signed two funding package providing nearly million new funding lupus specific research education program additional billion funding national institute health NIH lupus funding another upcoming accomplishment add next week two signing major anti robocall decade called TRACED telephone robocall abuse criminal enforcement deterrence TRACED extend period FCC catch punish intentionally break telemarketing restriction bill requires voice service provider develop framework verify call legitimate reach phone ['(0, 61.4%)', '(1, 3.0%)', '(2, 26.1%)', '(3, 4.2%)', '(4, 5.3%)']\n",
      "yeah find single cult absolutely rabid defend die ['(0, 12.6%)', '(1, 37.4%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 25.0%)']\n",
      "allowed real side hidden hatred subtle nazi uniform ['(0, 12.5%)', '(1, 25.0%)', '(2, 25.0%)', '(3, 12.5%)', '(4, 25.0%)']\n",
      "written history book worst worst ['(0, 12.5%)', '(1, 12.5%)', '(2, 25.0%)', '(3, 12.5%)', '(4, 37.5%)']\n",
      "ppl whining five another ['(0, 16.7%)', '(1, 20.3%)', '(2, 16.7%)', '(3, 29.7%)', '(4, 16.7%)']\n",
      "shitty enough move ['(0, 14.3%)', '(1, 34.0%)', '(2, 23.1%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "raised awareness around racism white supremacy police brutality exposed flaw american democracy using power executive branch steamroll two branch help expose GOP cult retaining power expose significant population authoritarianism right USA pretty big list US showing change country ['(0, 14.3%)', '(1, 45.1%)', '(2, 12.1%)', '(3, 6.4%)', '(4, 22.1%)']\n",
      "broken clock right twice incompetence lead positivity especially check balance system depends deem positive positive conservative negative tenure spent putting conservative judge court system conservative positive ['(0, 5.6%)', '(1, 5.8%)', '(2, 12.0%)', '(3, 6.0%)', '(4, 70.6%)']\n",
      "together list PART recently signed bill benefit native compensation spokane tribe loss land mid 1900s fund native language program third federal recognition little shell tribe chippewa indian montana signed cruelty animal federal felony animal abuser face tougher consequence signed bill CBD hemp legal EPA gave million fix water infrastructure problem flint michigan leadership surpassed russia saudi arabia become largest producer crude signed ending gag order pharmacist prevented sharing money saving information signed allow state victim fight online sex trafficking FOSTA includes stop enabling sex trafficker SESTA enforcement victim new tool fight sex trafficking signed bill require airport provide space breastfeeding mom lowest paid american enjoyed income boost november outpaces gain earnings country highest paid worker signed biggest wilderness protection conservation bill decade designated acre protected land signed save sea fund million per clean ton plastic garbage ocean signed bill allowing drug import canada prescription price signed executive order force healthcare provider disclose cost service american comparison shop provider charge insurance company hospital required post standard charge service include discounted price hospital willing accept eight prior inauguration prescription drug price increased average per drug price decline nine ten month drop recent month created white house VA hotline help veteran principally staffed veteran direct family member veteran VA employee held accountable poor performance VA employee removed demoted suspended issued executive order requiring secretary defense homeland security veteran affair submit joint plan provide veteran access access mental health treatment transition civilian bill signed championed federal employee pay increase average largest raise signed week paid parental leave million federal worker administration provide HIV prevention drug free uninsured patient per signed order allowing small business group together buying insurance better price signed groundbreaking step criminal justice bill enacted reform justice system fairer help former inmate successfully return society step reform addressed inequity sentencing disproportionately harmed black american reformed mandatory minimum created unfair outcome step expanded judicial discretion sentencing non violent crime benefiting retroactive sentencing reduction step black american step provides rehabilitative program inmate helping successfully rejoin society return crime increased funding historically black college university HBCUs signed legislation forgiving hurricane katrina debt threatened HBCUs new single family home sale october compared ago HBCUs priority creating position executive director white house initiative HBCUs received bipartisan justice award historically black college criminal justice reform accomplishment poverty african american hispanic american reached lowest level began collecting data signed bill creates five national monument expands several national park add million acre wilderness permanently reauthorizes land water conservation fund USDA committed million rebuild rural water infrastructure appointed openly gay ambassador ordered ric grenell openly gay ambassador germany lead global initiative decriminalize homosexuality across globe anti trafficking coordination team ACTeam initiative federal enforcement doubled conviction human trafficker increased number defendant charged ACTeam district department justice DOJ dismantled organization internet leading source prostitution related advertisement resulting sex trafficking immigration custom enforcement homeland security investigation arrested criminal associated human trafficking department health human service provided funding support national human trafficking hotline identify perpetrator victim help DOJ provided grant organization support human trafficking victim serving nearly case july june called congress pas school choice legislation child trapped failing school zip code signed funding legislation september increased funding school choice million tax cut signed promote school choice allowing family use college saving plan elementary secondary education ISIS leader abu bakr al baghdadi killed signed perkins CTE reauthorization authorizing billion state fund vocational career education program executive order expanding apprenticeship opportunity student worker issued executive order prohibiting government discriminating christian punishing expression faith signed executive order allows government withhold money college campus deemed anti semitic fail combat anti semitism ordered halt tax money international organization fund perform abortion imposed sanction socialist venezuela killed citizen finalized new trade agreement south korea secured billion new trade investment china billion vietnam okay billion aid farmer affected unfair trade retaliation ['(0, 91.8%)', '(2, 4.6%)', '(3, 2.3%)']\n",
      "merry band mobster showing crack democracy fully descended oligarchy republican showing actual traitor USA fixed majority agree broken place brought around country together fight blatant fascism right ['(0, 7.9%)', '(1, 50.3%)', '(2, 6.7%)', '(3, 7.4%)', '(4, 27.7%)']\n",
      "loses november admittedly BIG bad idea elect failed business governing experience watch fox news commiserates tucker carlson policy advice ['(0, 10.1%)', '(1, 24.8%)', '(2, 41.9%)', '(3, 13.0%)', '(4, 10.2%)']\n",
      "helped truth republican scumbag racist liar mind child rape christian used accused christian anti jesus thought exaggerating easy show government employee willing ignore duty republican government essentially criminal welfare believe cop worse criminal easy proved republican enemy country republican lose power positive impact hold true encourages republican voter die covid right winger pestilence become stupid filthy hateful trash decent human never republican republican show top bottom concept integrity shameless liar consider corruption ideal hire republican idiot trust republican idiot expects republican oath idiot ['(0, 7.6%)', '(1, 18.9%)', '(2, 2.4%)', '(3, 8.3%)', '(4, 62.8%)']\n",
      "valuable lesson ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "agreed agent chaos destruction putin china saudi arabia pledged elected enemy US ally knowingly allowed pandemic spread everywhere US ['(0, 10.2%)', '(1, 17.3%)', '(2, 21.6%)', '(3, 41.8%)', '(4, 9.1%)']\n",
      "attempt change current true figure puppet simply add single handedly impact real change millionaire lobbying congress listen wrong dude chance tell face hesitate bet chance meet federal lawmaker tell EXACT snake grass government ['(0, 14.7%)', '(1, 38.2%)', '(2, 5.2%)', '(3, 7.5%)', '(4, 34.3%)']\n",
      "reduced price insulin ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "confirmed plain inadequate protection tyranny US populous believed exist ['(0, 28.6%)', '(1, 14.3%)', '(2, 17.6%)', '(3, 25.3%)', '(4, 14.3%)']\n",
      "yes side teamed tech giant hollywood radical wealthy easy feel odds stacked equipped little intelligence able understand republican national convention regular citizen regular citizen explained impact personally truer ['(0, 11.0%)', '(1, 34.8%)', '(2, 18.4%)', '(3, 15.2%)', '(4, 20.5%)']\n",
      "argue highlighted limit presidential power least conversation started electoral college ['(0, 14.4%)', '(1, 20.0%)', '(2, 15.6%)', '(3, 20.0%)', '(4, 30.0%)']\n",
      "economy actually great coronavirus surprisingly strong account lockdown simultaneously blame coronavirus current economic crisis economic crisis result lockdown solution coronavirus serious effort twarted congress bring troop iraq afganistan defeat ISIS quickly effectively used constant terrorism US western europe especially france stoped ISIS defeated america became biggest producer gaining energy independence east stuff partisan cultural stuff delivered base classify objectively massively slowed cultural demographic change country reinvigorated american cultural nationalism across class line white working class ex obama voter american identitarianism reduced immigration massively legal illegal travel ban majority muslim country banned chinese infiltrator place replaced old fencing new improved original fencing joke compared new taller panel ['(0, 3.2%)', '(1, 19.8%)', '(2, 29.9%)', '(3, 34.7%)', '(4, 12.2%)']\n",
      "EDIT barf undecided somehow enough information news adult american pretty strong informed fishy swayed unless easily swayed ['(0, 11.9%)', '(1, 35.8%)', '(2, 23.7%)', '(3, 17.2%)', '(4, 11.3%)']\n",
      "shit stain history america america laughing stock ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 10.0%)', '(4, 30.0%)']\n",
      "appointed excellent SCOTUS nominee actually filled record number court vacancy passed massive tax cut passed executive order limiting regulation helped overthrow net neutrality general right police tried pas forced shitty single payer health major gun control legislation reparation payment required ect ['(0, 21.2%)', '(1, 15.0%)', '(2, 37.0%)', '(3, 16.0%)', '(4, 10.8%)']\n",
      "chicken nugget golden tasty full cheap shitty ingridients puke sh video chicken nugget ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "tremendous impact successful tearing foundation upon democracy founded yay ['(0, 14.3%)', '(1, 42.9%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "kept dems awful change exactly support opposition ['(0, 20.8%)', '(1, 22.1%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "china trade recognition jerusalem capitol real israeli peace UAE stopping NAFTA ['(0, 26.0%)', '(1, 8.3%)', '(2, 16.6%)', '(3, 32.3%)', '(4, 16.7%)']\n",
      "list accomplished term goal built improving pull troop afghanistan source google amp amp cnn cnn politics troop afghanistan index html negotiating peace east source google amp washingtonpost politics announces historic peace agreement israel united arab emirate 363f3c54 dd76 11ea d5f887d73381_story html 3foutputtype amp sanction china source google amp nytimes asia china hong kong sanction amp html standing human trafficking strongest economy american history source google amp amp cnn cnn economy economy recession index html historic low african american unemployment source google amp cnbc amp black hispanic unemployment record low html condem rioting looting beginning achievement black hispanic approval beginning sky rocket source google amp thehill hilltv america thinking poll approval rise among black hispanic voter 3famp recent news saw saying downplayed always wanted downplay create panic scavenged toilet paper roll sight CALM version imagine yup bad gonna die shit gone nut closed travel china country early backlash claim racist chinese democrat job state local government source1 google amp nytimes business china travel coronavirus amp html source2 google amp nbcbayarea news local nancy pelosi visit san franciscos chinatown 3famp incredibly aggressive human trafficking google amp abcnews amp politics anti human trafficking group boycotting ivanka white story 3fid fact main reason build keeping mexican fleeing border huge issue human trafficking drug trade kid kidnapped border taken across raped single attempting stop alone greatest achievement begin talk capturing ghilaine maxwell informant inside epstein human trafficking source coincidence maxwell arrested protected month later found truck kidnapped child asshole hothead racist nowhere near bad ['(0, 15.2%)', '(1, 14.7%)', '(2, 24.7%)', '(3, 29.2%)', '(4, 16.3%)']\n",
      "arent gonna legit response mostly full ignorant leftist kid ability pro right pro statement immediately removed braindead fascist mod ['(0, 11.8%)', '(1, 13.1%)', '(2, 22.2%)', '(3, 11.6%)', '(4, 41.3%)']\n",
      "try absolutist stand though absolutism attractive especially arguing internet point almost never lead ['(0, 16.7%)', '(1, 22.8%)', '(2, 10.5%)', '(3, 21.5%)', '(4, 28.5%)']\n",
      "rascist nasty body shaming git trash cheated vote ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "asktrumpsupporters biased info ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "banned bump stock although pardon used opposition great question btw learning ['(0, 25.0%)', '(1, 12.5%)', '(2, 25.0%)', '(3, 12.5%)', '(4, 25.0%)']\n",
      "true manage ban tik tok ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "covfefe voting supposedly ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "disagree single handedly spotlighted voter apathy hurt vote motivated younger generation politics ['(0, 9.1%)', '(1, 45.4%)', '(2, 9.1%)', '(3, 9.1%)', '(4, 27.3%)']\n",
      "kept everyone fearful answer pacified america becoming shitty always enough stick sand ignore small kept adding occasionally big pop folk pissy change voicing everyone sand america functioning born worse worse occasionally given cookie appease everyone everyone pacified cookie served distraction happening moreso nearly always constant threat cookie taken away distraction today moderate centralist progressive vote nonsense honestly scary fear called normal truth everyday normal working place rich getting richer poor getting poorer everyone keeping scary maddening today monster cannot ignored establishment empowers working never apparent result ordinary citizen fellow american engaged unable sleep participating became active current affair putting sand progressive movement die elected number ideal never mainstream brought light fascist conservative fear god road boiling frog sand mindset caused harm nonsense problem took madman fellow american wake sleep work ['(0, 2.6%)', '(1, 57.2%)', '(2, 5.6%)', '(3, 2.2%)', '(4, 32.5%)']\n",
      "warmonger obama bush ['(0, 14.3%)', '(1, 14.3%)', '(2, 22.9%)', '(3, 34.2%)', '(4, 14.3%)']\n",
      "challenge define positive change impact post result using standard applied ['(0, 10.4%)', '(1, 39.5%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 30.0%)']\n",
      "prez away regs deemed positive negative depending stand reduction regs tends stimulate economy needed economically depressed area regardless stand positive negative regs took multiple admins enact went away prez signature depending stand decreased trade deficit supply chain reliance china bringing manufacturing job process viewed positive prez brokered israel UAE nominated noble peace ['(0, 7.8%)', '(1, 8.5%)', '(2, 15.4%)', '(3, 51.4%)', '(4, 17.0%)']\n",
      "record short list administration achievement coming economy economic growth averaged administration accounting unemployment recently hit lowest mark administration policy foremost signature tax cut helped economy add seven million job half million manufacturing alone notably job economically inept predecessor barack obama insisted barometer consumer business confidence stock market record provide greater net worth broad swath american equity holder either directly indirectly close p NASDAQ composite heavily loaded dow jones industrial average prospect forward wage american worker rising fastest rise low income worker addition poverty african american hispanic american reached low street journal note wage rank file worker rising quickest pace decade faster boss average hourly earnings production nonsupervisory worker private sector november earlier seeing hourly earnings stumble along barack obama best looking income earner consumer spending surged reflection consumer confidence reflection administration policy cancerous recession seeded democrat policy clearly recession trade decade nation worker implementing trade protect job house approved united state mexico canada agreement trade pact estimated provide significant benefit worker farmer manufacturer hardline trade stance china politically risky among certain key constituency balancing trade relationship overdue needed protect american job economy term national security brash brawn take china according hill new dawn america nation manufacturing sector experiencing aggressive growth steel industry particular offer ample evidence america steel company investing billion new steelmaking mill across nation economist predicted however frustrated flow positive news economics profession looking wage war tariff regulatory state rolled impressive government regulation new implemented saving american taxpayer billion spurring additional economic growth according washington federal register dec published final rule page lowest number record began thus broke previous record low administration cut almost oppressive environmental regulation air breathable water drinkable court senate confirmed nominated judge meaning federal bench occupied nominee includes two outstanding supreme court justice neil gorsuch brett kavanaugh reelected conservative revitalization federal court continue including possibly two SCOTUS appointee gratitude former democrat senate majority leader harry reid nuked senate filibuster rule judge thereby paved republican appointee healthcare administration continues implement policy advance patient right slow healthcare cost increase roll obama called affordable disastrous impact medical cost success include largest decline drug price recorded energy administration energy policy united state net exporter product including refined petroleum crude decade resulted reduced dependence eastern weakening russia export revenue domestic security nation safer reached new agreement mexico central american country help stem flood illegal immigrant across southern border border apprehension fallen administration replaced catch release catch return sending phony asylum seeker mexico national security america enormous national security challenge unlike predecessor appeasing tyrant administration authorized military squash islamic state east unlike prior administration policy allowed jihadi terror flourish additionally end NATO ally increased defense spending billion start withdrew UN arm trade treaty terrible nuke iran clearly imposed new east terrorist including significant state sponsor terrorism iran finally perhaps worst news democrat despite impeachment charade popularity growing choice among voter democrat contender hope january affirm oath support defend according article II section clause constitution united state solemnly swear faithfully execute office united state best ability preserve protect defend constitution united state unlike congressional democrat abided oath great benefit liberty american serf semper vigilans fortis paratus et fidelis pro deo et libertate ['(0, 24.7%)', '(1, 4.8%)', '(2, 52.5%)', '(3, 10.8%)', '(4, 7.2%)']\n",
      "deleted ['(0, 33.3%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "answer simple question legacy treated unfairly history mention completely ['(0, 11.1%)', '(1, 11.1%)', '(2, 24.2%)', '(3, 31.4%)', '(4, 22.2%)']\n",
      "talking obviously history corrupt ['(0, 12.5%)', '(1, 12.5%)', '(2, 25.0%)', '(3, 25.0%)', '(4, 25.0%)']\n",
      "easy opened others eye fact america racist corrupt country built brutality positive right ['(0, 7.2%)', '(1, 38.8%)', '(2, 7.1%)', '(3, 7.6%)', '(4, 39.2%)']\n",
      "uhhh space force cause idea space force kinda cool ['(0, 45.5%)', '(1, 15.4%)', '(2, 11.8%)', '(3, 18.2%)', '(4, 9.1%)']\n",
      "promiseskept politifact truth meter promise trumpometer ruling promise kept ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "increased voter turnout ['(0, 26.7%)', '(1, 28.6%)', '(2, 16.1%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "easier tell low key racist ['(0, 12.5%)', '(1, 25.0%)', '(2, 25.0%)', '(3, 12.5%)', '(4, 25.0%)']\n",
      "worst country elect lose faith democracy ['(0, 12.6%)', '(1, 36.1%)', '(2, 12.5%)', '(3, 13.8%)', '(4, 25.0%)']\n",
      "fucking waste trash removed qe vote blue house blue elected impeached second imagine impeachment cliud twice donnie real asshole term arent serving constitution termw wont thwt arent fucking dictator usa fucked ['(0, 10.8%)', '(1, 49.3%)', '(2, 14.9%)', '(3, 8.3%)', '(4, 16.7%)']\n",
      "transient positive impact ['(0, 14.3%)', '(1, 28.6%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 28.6%)']\n",
      "set record game golf ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "stop calling liberal ['(0, 18.6%)', '(1, 28.6%)', '(2, 16.6%)', '(3, 21.9%)', '(4, 14.3%)']\n",
      " ['(0, 20.0%)', '(1, 20.0%)', '(2, 20.0%)', '(3, 20.0%)', '(4, 20.0%)']\n",
      "fully exposed moral bankruptcy republican party worth ['(0, 11.1%)', '(1, 11.1%)', '(2, 11.1%)', '(3, 22.2%)', '(4, 44.5%)']\n",
      "showed whole true face america true heart america changed brought open ['(0, 7.5%)', '(1, 26.0%)', '(2, 6.7%)', '(3, 20.0%)', '(4, 39.9%)']\n",
      "accelerated decline america depending point great achievement ['(0, 11.1%)', '(1, 11.1%)', '(2, 22.2%)', '(3, 22.2%)', '(4, 33.3%)']\n",
      "leaf positive impact US murderer fertilizes forest burying body ['(0, 12.5%)', '(1, 25.0%)', '(2, 15.4%)', '(3, 22.1%)', '(4, 25.0%)']\n",
      "handful positive prison reform trying unsuccessfully medicare drug price tied germany couple positive influence cliche positive hitler administration non jewish german better stalin russia employment suffer economic crash almost ALWAYS positive administration achievement weighs decent prison reform bill administration america worst COVID response nice labor right mexico tried ban muslim literally interview open muslim registry used racist sexiest fascistic rhetoric real economic improvement simply road economic progress obama administration administration suing remove preexisting condition coverage affordable banned trans military asked supreme court firing gay legal paris climate accord conscious effort fight science climate change used police break peaceful protest lafayette square ordered unmarked DHS officer kidnap random protestors guy fascist fringe issue mexican labor right mexican lying fascist stupid ['(0, 12.4%)', '(1, 2.2%)', '(2, 24.8%)', '(3, 13.7%)', '(4, 46.9%)']\n",
      "easier tell goddamn idiot red hat ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "impact meteor destructuve ['(0, 16.7%)', '(1, 33.3%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "fart sometimes positive impact doubt shite sort positive impact ['(0, 10.0%)', '(1, 40.0%)', '(2, 10.0%)', '(3, 10.0%)', '(4, 30.0%)']\n",
      "gotten banned leaving sinking ship pressured succeed die better result damn wanna leave ['(0, 13.9%)', '(1, 25.0%)', '(2, 12.5%)', '(3, 12.5%)', '(4, 36.1%)']\n",
      "exposed american dumb racist piece shit ['(0, 12.2%)', '(1, 24.3%)', '(2, 19.0%)', '(3, 11.1%)', '(4, 33.3%)']\n",
      "prattle list list accomplishment question substance sign thousand bill pointing inconsequential bill matter context leading powerful nation earth saying interesting question part test instrumental achieving happened either space force happen without bad employment basically trajectory obama pandemic material context overall federal budget structure organization government society writ large tax reform multi trillion dollar decision bad increasing school choice million literally rounding error department education budget positive depends list potentially pas three find pretty loathsome engaging america frank direct via twitter throwing old dogma aside motif always suspect rightly shifted strategic focus countering china incredibly repressive authoritarian state helped changed public business question business love method right point stolen IP posing challenge western order tax reform corporate earnings boosted share price bit actually rich democrat rich person deduction smaller prevalent killing suleimani let real obama foreign policy particularly assertive scared shadow foreign policy expert side agree obama huge foreign policy success course iran responded highly measured US escalation dominance v iran suicidal aggressive US posture likely order ['(0, 20.0%)', '(1, 21.3%)', '(2, 37.7%)', '(3, 11.8%)', '(4, 9.2%)']\n",
      "hitler created autobhan super positive employment number due big highway idea pioneer animal right piece shit piece shit ['(0, 18.7%)', '(1, 33.9%)', '(2, 20.4%)', '(3, 12.9%)', '(4, 14.0%)']\n",
      "realize ignorant selfish conservative credit ['(0, 25.0%)', '(1, 12.5%)', '(2, 12.5%)', '(3, 25.0%)', '(4, 25.0%)']\n",
      "item simply happened ie falling crime falling decade job creation started obama black employment whole thread read fucking propaganda sheet ['(0, 16.7%)', '(1, 24.6%)', '(2, 31.1%)', '(3, 20.9%)', '(4, 6.7%)']\n",
      "stack SCOTUS debt continues exponential growth fiscal responsibility republican supposed ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "woke asleep reagan goal positive outcome presidency result potential pendulum swing reverse decade rightward drift ['(0, 13.5%)', '(1, 22.2%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 42.1%)']\n",
      "love space force real netflix ['(0, 33.3%)', '(1, 22.2%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 22.2%)']\n",
      "squashed ISIS within matter month extra week paycheck via tax reform spurred US populace political action positive personal large amount political interest activism necessary welcome functional democracy ['(0, 21.3%)', '(1, 28.8%)', '(2, 23.4%)', '(3, 15.3%)', '(4, 11.2%)']\n",
      "hospital pricing transparent cut tax tax revenue went despite tax cut ['(0, 15.4%)', '(1, 7.7%)', '(2, 53.8%)', '(3, 15.4%)', '(4, 7.7%)']\n",
      "clearly karma farming brain hatred towards human race hatred towards certain implimented sytestems control built fell laughable amount wind area impact anywhere korea america weak dumb vulnerable stupid open investment yanke flocking EU america hit fan cause eu russia china umbrella waiting thankfully american happen stupidity ['(0, 5.4%)', '(1, 9.8%)', '(2, 30.0%)', '(3, 40.6%)', '(4, 14.3%)']\n",
      "best comment old yeah nice try russian ['(0, 22.2%)', '(1, 11.1%)', '(2, 22.2%)', '(3, 33.3%)', '(4, 11.1%)']\n",
      "defeated isi half term talk alone blow mind saying guy jesus christ thats huge win book ['(0, 7.5%)', '(1, 48.3%)', '(2, 22.0%)', '(3, 8.1%)', '(4, 14.1%)']\n",
      "positive contribution let lowered tax clobbered ISIS deregulated rebuilt military CLINTON OBAMA destroyed stopped MUSLIMS immigrating stopped central american peon crashing country armed ukraine JAVELIN fight putin killing russian syria job available brought unemployment BLACKS employed obama betrayed rebuilding military NATO partner pay mueller COLLUSION economy rockin rollin libs talk sex melania shoe undoing damage obama wrought army beat navy ['(0, 9.9%)', '(1, 5.3%)', '(2, 30.1%)', '(3, 41.8%)', '(4, 13.0%)']\n",
      "accomplishment hard list thme try category economic created economic opportunity zone major new trade greatly increased energy production provided billion aid farmer affected unfair trade retaliation brought trillion dollar overseas TCJA bill major trade mexico canada imposed tariff china response china intellectual property theft abusive trade practice criminal social justice step reform criminal justice system help former inmate return successfully society signed three important bill benefit native signed fight online sex trafficking signed tax cut job doubling maximum amount child tax credit available parent e nvironmental signed biggest wilderness protection bill decade designated acre protected land signed save sea funding million per clean ton garbage plastic ocean signed bill expands several national park adding million acre wilderness medical ended gag order pharmacist prevented sharing money saving info customer signed bill allowing prescription drug import canada reduce prescription price provided HIV orevention drug free uninsured patient administration FDA approved affordable generic drug accomplishment spite continuous unrelenting opposition attack political opponent ['(0, 84.6%)', '(1, 1.2%)', '(2, 11.5%)', '(3, 1.3%)', '(4, 1.3%)']\n",
      "true impact presidency molded federal judiciary image two generation exploded debt deficit repercussion everyone irritate cynical died covid watch reversed climate change rule regulation period stave drastic climate crisis ['(0, 12.3%)', '(1, 43.2%)', '(2, 13.2%)', '(3, 6.3%)', '(4, 25.0%)']\n",
      "firstly secondly legalized hemp nation wide ['(0, 28.6%)', '(1, 14.3%)', '(2, 28.6%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "support white supremacy best decade matter perspective ['(0, 21.6%)', '(1, 35.4%)', '(2, 20.0%)', '(3, 10.0%)', '(4, 13.0%)']\n",
      "proved check balance limitation ['(0, 16.7%)', '(1, 16.7%)', '(2, 33.3%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "wrong ensured whole voting republican ['(0, 11.1%)', '(1, 44.4%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 22.2%)']\n",
      "fraud league wizard oz supporter basically dorothy toto foolish naivete arrives forced confront truth today ['(0, 11.1%)', '(1, 33.3%)', '(2, 11.1%)', '(3, 11.1%)', '(4, 33.3%)']\n",
      "thank god stuck shit obama obama phone ['(0, 12.5%)', '(1, 25.0%)', '(2, 34.6%)', '(3, 15.4%)', '(4, 12.5%)']\n",
      "yes finally opened white eye racial divide country open racism em gone systemic open racism ['(0, 6.8%)', '(1, 52.0%)', '(2, 6.7%)', '(3, 27.8%)', '(4, 6.7%)']\n",
      "staff handed thought easily executable pandemic plan outgoing obama administration quite literally dumped saying useless cut funding department handle epidemic pandemic three later feckless loser currently squatting white house useless failure draft dodging loser traitor country defends complicit action therefore traitor TRAITORS ['(0, 12.8%)', '(1, 20.0%)', '(2, 23.2%)', '(3, 32.0%)', '(4, 11.9%)']\n",
      "cost golfing trip outweighs benefit donating salary ['(0, 42.8%)', '(1, 14.3%)', '(2, 14.3%)', '(3, 14.3%)', '(4, 14.3%)']\n",
      "ridiculous kinda wonder news WEEK nominated norwegian nobel peace moon south korea win noble peace publicly attacked military complex live v major pressure china largerst contribution hate kill agree disagree china stubborn let main stream dictate action lack empathy especially latin decent ask understand news reverse role looked global pandemic caused china changed read horrible x ask police brutality foreigner truth ive never told exist hand account either privileged live take granted ['(0, 2.8%)', '(1, 4.1%)', '(2, 2.8%)', '(3, 78.6%)', '(4, 11.8%)']\n",
      "lover odds everything favor considered right wing propaganda point deny presidency sparked change america whether positive optimist belief presidency worst necessary evil fight country freedom eroded unprecedented pace global sex trafficking whole shit load criminal activity washington fully understand congress politician single shit maintaining power blatantly corrupt forcing america seriously government least getting grilled corruption getting exposed McConnell republican disregard duty maintain power nancy dems factual sentiment change hope america matter happens office take foot gas continue zero tolerance corruption washington ['(0, 7.5%)', '(1, 27.8%)', '(2, 2.2%)', '(3, 2.6%)', '(4, 59.9%)']\n",
      "judge presidency based personally effect generally approve US without screwing honestly presidency decent adult tax went saw advancement field graduating early industry pandemic hit global issue fault story short pay tax personal complaint service obama screwed entire health insurance situation plan switched ACA cost significantly plan family obamacare idea terrible practice plan rushed thought screwed already health insurance bush blame housing market crash recession huge dent college fund use pay school job market awful graduated college fault bush jumping war war fought wasted tax dollar american ['(0, 14.3%)', '(1, 2.2%)', '(2, 41.1%)', '(3, 28.1%)', '(4, 14.3%)']\n",
      "counting dead american ['(0, 18.4%)', '(1, 17.9%)', '(2, 30.4%)', '(3, 16.7%)', '(4, 16.7%)']\n",
      "easier ignorant racist ['(0, 16.7%)', '(1, 16.7%)', '(2, 16.7%)', '(3, 16.7%)', '(4, 33.3%)']\n",
      "comedy never admittedly short politics meme took power top brexit handled ESPECIALLY entrance boris johnson prime minter gotta alive SURELY disagree ['(0, 9.1%)', '(1, 9.1%)', '(2, 9.1%)', '(3, 9.5%)', '(4, 63.2%)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x7ff1e3e5ed90>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA using priors\n",
    "\n",
    "def create_eta(priors, etadict, ntopics):\n",
    "    eta = np.full(shape=(ntopics, len(etadict)), fill_value=1) # create a (ntopics, nterms) matrix and fill with 1\n",
    "    for word, topic in priors.items(): # for each word in the list of priors\n",
    "        keyindex = [index for index,term in etadict.items() if term==word] # look up the word in the dictionary\n",
    "        if (len(keyindex)>0): # if it's in the dictionary\n",
    "            eta[topic,keyindex[0]] = 1e7  # put a large number in there\n",
    "    eta = np.divide(eta, eta.sum(axis=0)) # normalize so that the probabilities sum to 1 over all topics\n",
    "    return eta\n",
    "\n",
    "apriori_original = {\n",
    "    'war':0,'peace':0,'military':0,\n",
    "    'tax':1,'cut':1,'business':1, \n",
    "    'economy':2, 'employment':2, 'growth':2, 'unemployment':2,\n",
    "    'virus':3, 'pandemic':3, 'virus':3,'coronavirus':3,\n",
    "    'media':4, 'news':4\n",
    "}\n",
    "\n",
    "eta = create_eta(apriori_original, dictionary, 5)\n",
    "test_eta(eta, dictionary, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d858593",
   "metadata": {},
   "source": [
    "### 4B) SENTIMENT ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "b716197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "# instructions\n",
    "# pip install spacytextblob\n",
    "# python3 -m textblob.download_corpora\n",
    "# python3 -m spacy download en_core_web_sm\n",
    "# pip install spacytextblob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "texts = df['text_preproc']\n",
    "polarities = []\n",
    "subjectivities = []\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    polarity = doc._.blob.polarity\n",
    "    polarities.append(polarity)\n",
    "    subjectivity = doc._.blob.subjectivity\n",
    "    subjectivities.append(subjectivity)\n",
    "\n",
    "df['sentiment'] = polarities\n",
    "df['subjectivity'] = subjectivities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "cbb1e401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0380952380952381,\n",
       " -0.10208333333333333,\n",
       " 0.028860028860028853,\n",
       " 0.0,\n",
       " 0.09913419913419914,\n",
       " 0.00781370656370656,\n",
       " 0.20545454545454547,\n",
       " 0.15,\n",
       " 0.0,\n",
       " -0.06016955266955265,\n",
       " 0.04833333333333332,\n",
       " -0.04808286951144093,\n",
       " -0.10469047619047615,\n",
       " -0.19090909090909092,\n",
       " 0.23129251700680273,\n",
       " -0.10811287477954143,\n",
       " 0.0,\n",
       " -0.07242630385487528,\n",
       " -0.039285714285714285,\n",
       " -0.15555555555555556,\n",
       " 0.1537037037037037,\n",
       " -0.09531250000000001,\n",
       " -0.03333333333333335,\n",
       " -0.03000000000000001,\n",
       " -0.013219246031746021,\n",
       " 0.16353174603174603,\n",
       " 0.18181818181818182,\n",
       " 0.009555137844611533,\n",
       " 0.0,\n",
       " 0.025958994708994702,\n",
       " 0.07638483965014577,\n",
       " -0.07385213744588748,\n",
       " 0.0011904761904761739,\n",
       " -0.0035714285714285865,\n",
       " -0.5,\n",
       " -0.5638888888888888,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.08168590668590668,\n",
       " -0.007395833333333331,\n",
       " 0.0,\n",
       " 0.01821106821106822,\n",
       " 0.0,\n",
       " 0.2161616161616162,\n",
       " 0.018035714285714287,\n",
       " 0.17215909090909093,\n",
       " 0.125,\n",
       " 0.4,\n",
       " -0.15000000000000002,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.033333333333333326,\n",
       " 0.5,\n",
       " -0.16666666666666666,\n",
       " -0.6999999999999998,\n",
       " -0.05,\n",
       " 0.08333333333333333,\n",
       " -0.125,\n",
       " 0.0,\n",
       " -0.2125,\n",
       " -0.025,\n",
       " -0.04999999999999998,\n",
       " -0.8,\n",
       " 0.22727272727272727,\n",
       " 0.03571428571428571,\n",
       " 0.07575757575757575,\n",
       " -0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.31249999999999994,\n",
       " -0.5,\n",
       " -0.04999999999999999,\n",
       " 0.375,\n",
       " -0.03979591836734694,\n",
       " 0.17320936639118462,\n",
       " -0.16666666666666666,\n",
       " 0.14166666666666666,\n",
       " -0.16666666666666666,\n",
       " 0.0,\n",
       " 0.22727272727272727,\n",
       " -0.25833333333333336,\n",
       " 0.014492753623188413,\n",
       " 0.1,\n",
       " 0.21000000000000002,\n",
       " -0.4625,\n",
       " 0.0,\n",
       " 0.16,\n",
       " 0.018571428571428572,\n",
       " 0.2,\n",
       " 0.0,\n",
       " -0.051515151515151514,\n",
       " -0.0944642857142857,\n",
       " 0.014154704944178633,\n",
       " 0.0,\n",
       " -0.6999999999999998,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.10909090909090909,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.12045454545454545,\n",
       " -0.35,\n",
       " 0.0,\n",
       " 0.2683333333333333,\n",
       " 0.0,\n",
       " 0.45000000000000007,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " -0.25,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.10340909090909091,\n",
       " 0.05,\n",
       " -0.15000000000000002,\n",
       " 0.0,\n",
       " -0.057727272727272724,\n",
       " 0.16666666666666669,\n",
       " 0.07829184704184705,\n",
       " -0.3104761904761905,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.22181337181337182,\n",
       " 0.010433884297520684,\n",
       " 0.375,\n",
       " -0.15757575757575756,\n",
       " 0.8,\n",
       " 0.375,\n",
       " 0.21428571428571427,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4,\n",
       " 0.296969696969697,\n",
       " 0.3125,\n",
       " 0.0,\n",
       " 0.375,\n",
       " -0.0773809523809524,\n",
       " 0.0,\n",
       " 0.22727272727272727,\n",
       " -0.047333333333333324,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.14375,\n",
       " -0.15,\n",
       " -0.1,\n",
       " 0.11363636363636363,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.08333333333333333,\n",
       " -0.056666666666666685,\n",
       " 0.0,\n",
       " 0.14242424242424243,\n",
       " -0.058987389422172035,\n",
       " 0.0,\n",
       " -0.09916666666666667,\n",
       " 0.0,\n",
       " -0.2333333333333333,\n",
       " 0.04259740259740259,\n",
       " 0.209375,\n",
       " 0.5,\n",
       " -0.16666666666666666,\n",
       " 0.0,\n",
       " -0.1875,\n",
       " 0.3,\n",
       " 0.05900793650793651,\n",
       " -0.09166666666666667,\n",
       " 0.25,\n",
       " 0.31363636363636366,\n",
       " -0.05696969696969696,\n",
       " -0.05378787878787875,\n",
       " 0.0965909090909091,\n",
       " -0.25,\n",
       " 0.15416666666666667,\n",
       " 0.4,\n",
       " -0.25,\n",
       " -0.4005952380952381,\n",
       " 0.3125,\n",
       " -0.04126984126984126,\n",
       " -0.25,\n",
       " -0.35,\n",
       " 0.03076923076923079,\n",
       " 0.13636363636363635,\n",
       " 0.0,\n",
       " -0.2666666666666666,\n",
       " -0.08068181818181819,\n",
       " 0.18333333333333335,\n",
       " -0.3,\n",
       " 0.1538095238095238,\n",
       " 0.3,\n",
       " 0.0,\n",
       " 0.016666666666666663,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.9,\n",
       " -0.07333333333333335,\n",
       " 0.09499999999999999,\n",
       " 0.16581632653061226,\n",
       " -0.23446969696969697,\n",
       " 0.4,\n",
       " 0.4,\n",
       " -0.6999999999999998,\n",
       " 0.35,\n",
       " -0.04999999999999999,\n",
       " 0.04166666666666666,\n",
       " 0.04362244897959183,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.15,\n",
       " -0.062049062049062034,\n",
       " 0.0,\n",
       " 0.3416666666666667,\n",
       " -0.026799242424242434,\n",
       " 1.0,\n",
       " 0.08000000000000002,\n",
       " 0.11363636363636363,\n",
       " 0.0,\n",
       " 0.30113636363636365,\n",
       " 0.0,\n",
       " 0.09999999999999998,\n",
       " -0.20714285714285707,\n",
       " -0.12142857142857137,\n",
       " 0.3646464646464646,\n",
       " -0.24285714285714288,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.8,\n",
       " -0.05000000000000001,\n",
       " 0.03954545454545458,\n",
       " -0.16666666666666666,\n",
       " -0.1,\n",
       " -0.24999999999999992,\n",
       " -0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.016666666666666663,\n",
       " 0.2857142857142857,\n",
       " 0.13750000000000004,\n",
       " 0.009090909090909085,\n",
       " 0.0,\n",
       " -0.03333333333333333,\n",
       " -0.46296296296296297,\n",
       " 0.0,\n",
       " 0.07777777777777777,\n",
       " -0.27083333333333337,\n",
       " 0.4,\n",
       " 0.06428571428571428,\n",
       " 0.0,\n",
       " 0.23541666666666666,\n",
       " -0.06296296296296296,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.062142857142857146,\n",
       " 0.0,\n",
       " 0.4,\n",
       " -0.08333333333333333,\n",
       " -0.05,\n",
       " 0.06592261904761904,\n",
       " 0.09333333333333334,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.4583333333333333,\n",
       " -0.16666666666666666,\n",
       " 0.22727272727272727,\n",
       " 0.0,\n",
       " -0.75,\n",
       " 0.05,\n",
       " -0.25,\n",
       " -0.04857142857142858,\n",
       " -0.09999999999999992,\n",
       " 0.15152597402597404,\n",
       " 0.0,\n",
       " 0.20454545454545456,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.5833333333333334,\n",
       " 0.1875,\n",
       " 0.012857142857142855,\n",
       " 0.0,\n",
       " 0.27777777777777773,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.019318181818181825,\n",
       " -0.2550925925925926,\n",
       " 0.16,\n",
       " -0.14444444444444446,\n",
       " 0.19375000000000003,\n",
       " 0.5,\n",
       " 0.1371212121212121,\n",
       " 0.28863636363636364,\n",
       " 0.22727272727272727,\n",
       " -0.3666666666666667,\n",
       " -0.1,\n",
       " 0.12962962962962965,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.04675324675324671,\n",
       " 0.35119047619047616,\n",
       " -0.5833333333333333,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.31875000000000003,\n",
       " 0.09444444444444443,\n",
       " -0.08636363636363638,\n",
       " -0.13333333333333336,\n",
       " -0.3499999999999999,\n",
       " 0.2636363636363636,\n",
       " 0.1125,\n",
       " 0.0,\n",
       " -0.05,\n",
       " 0.0,\n",
       " 0.12761904761904763,\n",
       " 0.014285714285714287,\n",
       " 0.0,\n",
       " -0.2119047619047619,\n",
       " -0.04903581267217625,\n",
       " 0.4,\n",
       " 0.0,\n",
       " 0.06590909090909092,\n",
       " -0.024242424242424242,\n",
       " 0.3266666666666667,\n",
       " -0.26666666666666666,\n",
       " 0.0,\n",
       " 0.1,\n",
       " 0.01777777777777779,\n",
       " 0.175,\n",
       " 0.0,\n",
       " 0.15151515151515152,\n",
       " 0.0,\n",
       " 0.08896103896103896,\n",
       " 0.1,\n",
       " 0.0125,\n",
       " -0.12499999999999996,\n",
       " -0.04848484848484848,\n",
       " -0.4,\n",
       " 0.10000000000000002,\n",
       " 0.0,\n",
       " -0.3,\n",
       " 0.06666666666666667,\n",
       " 0.11249999999999999,\n",
       " -0.061111111111111116,\n",
       " 0.08666666666666667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.40238095238095234,\n",
       " 0.16626984126984126,\n",
       " 1.0,\n",
       " 0.056818181818181816,\n",
       " 0.08779761904761905,\n",
       " 0.011111111111111105,\n",
       " -0.13333333333333333,\n",
       " 0.4166666666666667,\n",
       " 0.18571428571428572,\n",
       " 0.2833333333333333,\n",
       " 0.41666666666666663,\n",
       " 0.10000000000000002,\n",
       " 0.20357142857142857,\n",
       " -0.22678571428571428,\n",
       " -0.02777777777777777,\n",
       " 0.25,\n",
       " 0.14285714285714285,\n",
       " 0.0,\n",
       " 0.4000000000000001,\n",
       " 0.14488636363636365,\n",
       " 0.1590909090909091,\n",
       " -0.5,\n",
       " 0.2654545454545455,\n",
       " 0.2857142857142857,\n",
       " -0.8,\n",
       " 0.1,\n",
       " -0.6999999999999998,\n",
       " 0.13392857142857142,\n",
       " 0.0,\n",
       " 0.10416666666666666,\n",
       " 0.2846153846153846,\n",
       " -0.06666666666666667,\n",
       " 0.19974025974025972,\n",
       " 0.001973684210526309,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1333333333333333,\n",
       " -0.6999999999999998,\n",
       " 0.0,\n",
       " -0.15,\n",
       " -0.3537037037037037,\n",
       " -0.25,\n",
       " 0.10909090909090909,\n",
       " 0.0,\n",
       " -0.096875,\n",
       " 0.225,\n",
       " 0.25,\n",
       " -0.15833333333333333,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.21428571428571427,\n",
       " -0.125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.037142857142857165,\n",
       " 0.03333333333333333,\n",
       " -0.8,\n",
       " 0.03939393939393941,\n",
       " 0.007773109243697477,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.43333333333333335,\n",
       " -0.16666666666666666,\n",
       " 0.4,\n",
       " -0.007142857142857141,\n",
       " -0.10285714285714287,\n",
       " -0.32962962962962966,\n",
       " -0.26666666666666666,\n",
       " 0.375,\n",
       " 0.0,\n",
       " 0.4,\n",
       " 0.0,\n",
       " -0.12393939393939393,\n",
       " 0.17545454545454547,\n",
       " -0.04999999999999999,\n",
       " -0.3,\n",
       " 0.10000000000000002,\n",
       " 0.22727272727272727,\n",
       " 0.5,\n",
       " 0.25,\n",
       " -0.09999999999999995,\n",
       " -0.3575757575757576,\n",
       " 0.10132575757575758,\n",
       " -0.11666666666666668,\n",
       " 0.08700000000000001,\n",
       " 0.06714285714285714,\n",
       " -0.0380952380952381,\n",
       " -0.5,\n",
       " -0.2486111111111111,\n",
       " 0.19999999999999998,\n",
       " 0.3,\n",
       " 0.005729166666666674,\n",
       " -0.15,\n",
       " 0.0,\n",
       " 0.1,\n",
       " -0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.29285714285714287,\n",
       " -0.2545454545454545,\n",
       " -0.006249999999999999,\n",
       " 0.28437500000000004,\n",
       " 0.4666666666666666,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.03509090909090908,\n",
       " -0.25,\n",
       " 0.25,\n",
       " 0.23863636363636365,\n",
       " 0.16,\n",
       " 0.05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.16666666666666669,\n",
       " 0.0,\n",
       " -0.08215488215488213,\n",
       " 0.029393939393939396,\n",
       " 0.3125,\n",
       " 0.4166666666666667,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.33333333333333337,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.025,\n",
       " 0.1,\n",
       " 0.055454545454545444,\n",
       " -0.37023809523809526,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.05,\n",
       " 0.4666666666666666,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.25865800865800864,\n",
       " 0.2222222222222222,\n",
       " 0.36363636363636365,\n",
       " -0.35,\n",
       " 0.1285714285714286,\n",
       " -0.0466848940533151,\n",
       " 0.07500000000000001,\n",
       " -0.09999999999999998,\n",
       " 0.0,\n",
       " 0.16833333333333333,\n",
       " 0.4,\n",
       " 0.11499999999999999,\n",
       " -0.08333333333333333,\n",
       " 0.25897727272727267,\n",
       " 0.3,\n",
       " -0.4,\n",
       " 0.06979166666666667,\n",
       " -0.0884297520661157,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.21714285714285717,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.19444444444444445,\n",
       " -0.08333333333333333,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.16666666666666666,\n",
       " 0.0,\n",
       " 0.1375,\n",
       " 0.22575757575757574,\n",
       " -0.26041666666666663,\n",
       " 0.45,\n",
       " 0.0,\n",
       " -0.7999999999999999,\n",
       " 0.2709375,\n",
       " 0.0,\n",
       " 0.5214285714285715,\n",
       " 0.0,\n",
       " -0.32739898989898986,\n",
       " 0.5,\n",
       " -0.04999999999999993,\n",
       " 0.0,\n",
       " -0.3,\n",
       " -0.16666666666666666,\n",
       " -0.08793650793650795,\n",
       " 0.0,\n",
       " 0.1721938775510204,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 0.2833333333333334,\n",
       " 0.10607142857142857,\n",
       " 0.13166666666666665,\n",
       " -0.05416666666666666,\n",
       " -0.25,\n",
       " -0.1499999999999999,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.125,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.15,\n",
       " -0.6,\n",
       " 0.36363636363636365,\n",
       " -0.024242424242424242,\n",
       " -0.0009920634920634979,\n",
       " 0.4375,\n",
       " 0.23863636363636365,\n",
       " -0.0875,\n",
       " -0.2777777777777778,\n",
       " -0.2571428571428572,\n",
       " 0.22727272727272727,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.325,\n",
       " -0.004629629629629632,\n",
       " 0.07142857142857142,\n",
       " 0.10833333333333334,\n",
       " 0.0,\n",
       " 0.41363636363636364,\n",
       " -0.29583333333333334,\n",
       " 0.0,\n",
       " 0.14488636363636365,\n",
       " 0.0,\n",
       " -0.07410714285714286,\n",
       " -0.24999999999999997,\n",
       " -0.4607142857142857,\n",
       " -0.03251748251748251,\n",
       " -0.19166666666666662,\n",
       " -0.18636363636363634,\n",
       " -1.0,\n",
       " 0.04166666666666667,\n",
       " 0.0,\n",
       " -0.0047979797979798055,\n",
       " 0.010476190476190477,\n",
       " 0.5285714285714286,\n",
       " -0.12722277722277722,\n",
       " 0.0,\n",
       " 0.2,\n",
       " -0.1375,\n",
       " 0.375,\n",
       " -0.037500000000000006,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.2722222222222222,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.24545454545454545,\n",
       " 0.0,\n",
       " 0.051870826913199795,\n",
       " 0.22727272727272727,\n",
       " 0.525,\n",
       " 0.17708333333333337,\n",
       " 0.3,\n",
       " 0.11363636363636363,\n",
       " -0.30000000000000004,\n",
       " -0.07333333333333333,\n",
       " -0.035590277777777755,\n",
       " 0.1660606060606061,\n",
       " 0.3333333333333333,\n",
       " 0.15634920634920635,\n",
       " -0.3,\n",
       " 0.6136363636363636,\n",
       " 0.0,\n",
       " 0.21833333333333335,\n",
       " -0.011538461538461536,\n",
       " -0.23333333333333325,\n",
       " 0.015277777777777784,\n",
       " -0.011111111111111108,\n",
       " 0.042607022607022614,\n",
       " -0.011309523809523813,\n",
       " 0.16831168831168833,\n",
       " 0.0376984126984127,\n",
       " 0.0,\n",
       " -0.19166666666666668,\n",
       " -0.22467532467532467,\n",
       " 0.05932395382395383,\n",
       " 0.2,\n",
       " -0.29166666666666663,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.15178571428571427,\n",
       " 0.020941558441558435,\n",
       " -0.0196509009009009,\n",
       " -0.10285714285714287,\n",
       " -0.13999999999999996,\n",
       " -0.08268398268398269,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.05000000000000001,\n",
       " 0.0,\n",
       " 0.09285714285714287,\n",
       " 0.15572916666666667,\n",
       " -0.3,\n",
       " 0.06847826086956522,\n",
       " 0.20277777777777775,\n",
       " 0.0,\n",
       " 0.18727678571428572,\n",
       " -0.029999999999999992,\n",
       " 0.5416666666666666,\n",
       " -0.375,\n",
       " 0.2,\n",
       " 0.03333333333333335,\n",
       " 0.1964285714285714,\n",
       " 0.4,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.8,\n",
       " 0.35,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.06882716049382719,\n",
       " 0.0,\n",
       " 0.11363636363636363,\n",
       " 0.06464646464646465,\n",
       " 0.030769653052261748,\n",
       " 0.0,\n",
       " -0.13333333333333333,\n",
       " -0.25,\n",
       " 0.11158008658008658,\n",
       " 0.35,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.09999999999999998,\n",
       " -0.17142857142857143,\n",
       " 0.22727272727272727,\n",
       " -0.4,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.15,\n",
       " 0.2333333333333333,\n",
       " 0.8,\n",
       " 0.22727272727272727,\n",
       " 0.07745587745587744,\n",
       " -0.4,\n",
       " 0.0,\n",
       " 0.22727272727272727,\n",
       " 0.5,\n",
       " -0.1875,\n",
       " 0.1375694735372155,\n",
       " 0.14426406926406926,\n",
       " -0.5,\n",
       " -0.08888888888888889,\n",
       " 0.0,\n",
       " 0.11363636363636363,\n",
       " 0.35,\n",
       " 0.14906204906204906,\n",
       " 0.0,\n",
       " -0.2577922077922078,\n",
       " 0.42500000000000004,\n",
       " 0.3444444444444445,\n",
       " 0.06103896103896105,\n",
       " 0.11349206349206349,\n",
       " -0.125,\n",
       " -0.05,\n",
       " 0.5,\n",
       " 0.0,\n",
       " -0.5,\n",
       " -0.30000000000000004,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.09791666666666667,\n",
       " 0.0,\n",
       " -0.021457219251336895,\n",
       " -0.21002886002886,\n",
       " -0.041666666666666664,\n",
       " -0.1,\n",
       " 0.0,\n",
       " 0.22000000000000003]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "a816a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.124815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.472604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.575759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  736.000000\n",
       "mean     0.513025\n",
       "std      0.124815\n",
       "min      0.000000\n",
       "25%      0.472604\n",
       "50%      0.500000\n",
       "75%      0.575759\n",
       "max      1.000000"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities = [(polarity + 1) / 2 for polarity in polarities]\n",
    "polarities_df = pd.DataFrame(polarities)\n",
    "polarities_df.iloc[50:60,:]\n",
    "polarities_df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "97cb9433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 20: administration assisted normalizing relations UAE Israel, historical event celebrated Nobel Peace US history. administration lowered cost prescription drugs. Republicans Democrats pockets pharmaceutical companies decades. started fixing effects Biden-Clinton crime bill destroyed black communities. Regardless COVID vaccine arrives, unprecedented steps taken administration buy, at-risk, hundreds millions doses instrumental 3 different entities Stage 3 trials right now. Without federal government's assistance, nearly close. turned tide manufacturing jobs pouring China. recent times ignored money large corporations ensuring offshore manufacturing jobs. progress opioid crisis, ignored federal level took office.\n",
      "Topic polarities: [0.5768518518518518]\n",
      "Document 21: 39 years us war. lmao lowest unemployment blacks hispanics history, small businesses owned blacks increased 400% 2017 2018 tax cuts,He forgave debt HBCUs affected Katrinahttps://www.washingtonpost.com/news/grade-point/wp/2018/03/15/education-department-forgives-322-million-in-loans-to-help-historically-black-colleges-recover-from-hurricanes/Program puts 800 billion minoritiy retirements.https://www.whitehouse.gov/briefings-statements/remarks-president-trump-signing-executive-order-establishing-white-house-opportunity-revitalizatioCompensation native Americans lost land 1900.https://thehill.com/changing-america/respect/diversity-inclusion/476049-trump-signed-three-bills-affecting-nativeSet legislation fight sex trafficking appointed former victim (black woman) newest member U.S. Advisory Council Human Trafficking.https://m.theepochtimes.com/trump-creates-new-position-dedicated-to-fighting-human-trafficking_3223105.htmlLowering penalty none violent crimes.https://www.nytimes.com/2018/11/14/us/politics/prison-sentencing-trump.htmlBillions help urban development led Ben Carson!https://www.politico.com/states/new-york/albany/story/2019/01/31/trump-administration-imposes-monitor-on-nycha-city-pledges-22b-over-10-years-831349Trump RESTORES funding HBCU (Historically Black Colleges Universities)https://apnews.com/c4834e48841d97c5a93312b1bf75302aHe awards Jesse Jackson work black community.\n",
      "Topic polarities: [0.45234375]\n",
      "Document 22: wars armed conflicts. started conflicts, him. succeeded bringing peace Korea east, let's honest, things worse, least Bill Clinton did.\n",
      "Topic polarities: [0.48333333333333334]\n",
      "Document 23: Biggest impact talk avoiding war Iran. US drone shot down, military planned bombing attack response. personally stopped realized strike killed dozens Iranians. rhetoric hear career politicians parties, pretty else office let military proceed strike.\n",
      "Topic polarities: [0.485]\n",
      "Document 24: Disclosure - he's idiot social policy generally can't stand deplorable ethical standards. achievements worth noting. helped broker fully normalized relations UAE Israel. big east. BBC.com/news/world-us-canada-54092960 big enough Norwegian politician nominated Nobel peace role normalized relations stated judged facts action \"on behaves sometimes.\" likely win one, I'd love leftist heads explode did. handle righteous right gloating though... Reducing dependence China matching tarrifs Chinese government increasingly expansionist flouting human rights agree with. stupid calling Xi Xinping great leader, he's maintained military pivot Asia offering assurance allied Asian nations. actions line verbal praise Chinese leadership. \"accomplishments\" bad depending political views right. instance, religious freedom policies steps backward US domestic social issues (he's anti-abortion). \"religion\" US currently synonymous Christian. needs change helped domestic side. But, international stage publicly called Nigeria killing Christians conference call Nigeria's criticized China persecution Uighur Muslims. He's consistently strong backing religious freedoms international front. https://www.reuters.com/article/us-usa-religion-un/at-un-trump-pushes-religious-freedom-at-event-slamming-china-over-uighurs-idUSKBN1W82BJ domestic social policies suck. He's divisive need. biggest weakness he's knee-jerk combative childish de-escalate. However, foreign policy gets mentioned US media unless stupid bad.\n",
      "Topic polarities: [0.49339037698412697]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,25):\n",
    "    print(f\"Document {i}: {df.body[i]}\")\n",
    "    polarities_ = polarities_df.iloc[i].tolist()\n",
    "    print(f\"Topic polarities: {polarities_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "c7351413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>733.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.756498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.062529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.735833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.787881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  733.000000\n",
       "mean     0.756498\n",
       "std      0.062529\n",
       "min      0.500000\n",
       "25%      0.735833\n",
       "50%      0.750000\n",
       "75%      0.787881\n",
       "max      1.000000"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities_df.describe()\n",
    "\n",
    "#len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ddd919",
   "metadata": {},
   "source": [
    "### 5) LOGISTIC REGRESSION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "9eb3e325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.511387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.122879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.464237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.575762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  586.000000\n",
       "mean     0.511387\n",
       "std      0.122879\n",
       "min      0.000000\n",
       "25%      0.464237\n",
       "50%      0.500000\n",
       "75%      0.575762\n",
       "max      1.000000"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# get the list of index labels to drop from df_reg\n",
    "drop_index = df_reg[df_reg.isna().any(axis=1)].index.tolist() + polarities_df[polarities_df.isna().any(axis=1)].index.tolist()\n",
    "\n",
    "# drop the same index labels from subjectivities\n",
    "polarities_df.drop(drop_index, inplace=True)\n",
    "df_reg.drop(drop_index, inplace=True)\n",
    "\n",
    "# define X and y variables\n",
    "X = pd.DataFrame(df_reg.iloc[:, 1:].values)\n",
    "X = X.rename(columns={0: \"topic 1\", 1: \"topic 2\", 2: \"topic 3\", 3: \"topic 4\", 4: \"topic 5\", 5: \"topic 6\", 6: \"topic 7\",7:\"topic 8\"})\n",
    "y = pd.DataFrame(polarities_df.values)\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "443cb063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690596\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      0   No. Observations:                  586\n",
      "Model:                          Logit   Df Residuals:                      580\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 20 Feb 2023   Pseudo R-squ.:               -0.002538\n",
      "Time:                        16:22:38   Log-Likelihood:                -404.69\n",
      "converged:                       True   LL-Null:                       -403.66\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "topic 1        0.4310      0.789      0.547      0.585      -1.114       1.976\n",
      "topic 2        0.1234      0.579      0.213      0.831      -1.011       1.258\n",
      "topic 3        0.5377      0.734      0.732      0.464      -0.902       1.977\n",
      "topic 4       -0.1967      0.629     -0.313      0.755      -1.430       1.036\n",
      "topic 5       -0.3660      0.608     -0.602      0.547      -1.558       0.826\n",
      "topic 6       -0.1342      0.613     -0.219      0.827      -1.335       1.067\n",
      "==============================================================================\n",
      "Pseudo R-squared value: -0.002538140375217157\n",
      "Mean absolute error: 0.0883\n",
      "Mean squared error: 0.0180\n"
     ]
    }
   ],
   "source": [
    "# fit logistic regression model on the training set\n",
    "model = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "# print model summary\n",
    "print(model.summary())\n",
    "\n",
    "# predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the Pseudo R-squared value using pandas\n",
    "df = pd.DataFrame({'y_true': y_test.iloc[:,0], 'y_pred': y_pred})\n",
    "#df['resid'] = df['y_true'] - df['y_pred']\n",
    "#df['resid_sq'] = df['resid'] ** 2\n",
    "\n",
    "#null_deviance = sum((y_test - y_test.mean()) ** 2)\n",
    "##print(null_deviance)\n",
    "#model_deviance = sum((y_test - y_pred) ** 2)\n",
    "#pseudo_r2 = 1 - (model_deviance / null_deviance)\n",
    "\n",
    "pseudo_r2 = 1 - (model.llf/ model.llnull)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# print performance metrics\n",
    "print(\"Pseudo R-squared value:\", pseudo_r2)\n",
    "print('Mean absolute error: {:.4f}'.format(mae))\n",
    "print('Mean squared error: {:.4f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "bc5efe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:910: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/var/folders/09/2tcgbyys1xg463jzt7ddwy2m0000gn/T/ipykernel_68892/2497914088.py:45: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_best.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.0448\n",
      "Mean squared error: 0.0045\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# get the list of index labels to drop from df_reg\n",
    "drop_index = df_reg[df_reg.isna().any(axis=1)].index.tolist()\n",
    "\n",
    "# drop the same index labels from subjectivities\n",
    "polarities_df.drop(drop_index, inplace=True)\n",
    "df_reg.drop(drop_index, inplace=True)\n",
    "\n",
    "# define X and y variables\n",
    "X = pd.DataFrame(df_reg.iloc[:, 1:].values)\n",
    "X = X.rename(columns={0: \"topic 1\", 1: \"topic 2\", 2: \"topic 3\", 3: \"topic 4\", 4: \"topic 5\", 5: \"topic 6\"})\n",
    "y = pd.DataFrame(polarities_df.values)\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# initialize random forest regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# get best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# initialize random forest regressor with best hyperparameters\n",
    "rf_best = RandomForestRegressor(**best_params, random_state=42)\n",
    "\n",
    "# fit the model to the training data\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = rf_best.predict(X_test)\n",
    "\n",
    "# calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# print performance metrics\n",
    "print('Mean absolute error: {:.4f}'.format(mae))\n",
    "print('Mean squared error: {:.4f}'.format(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2e44a3",
   "metadata": {},
   "source": [
    "### 6) POSSIBLE EXTENSIONS "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
